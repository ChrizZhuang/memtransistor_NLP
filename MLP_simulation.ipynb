{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "MLP simulation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrizZhuang/memtransistor_NLP/blob/main/MLP_simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-J1VNb700rX",
        "outputId": "a281800b-1353-4bac-f3d9-3b1570e3228b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports data from single column CSV file with possible current/conductance states\n",
        "# return numpy array of approximate states possible using this hardware\n",
        "# this import method is not generalized, but fine-tuned to Vinod's devices\n",
        "def import_data_from_csv(filename):\n",
        "  # import data\n",
        "  imported_device_states = np.genfromtxt(filename, delimiter=',')[1:]\n",
        "\n",
        "  # since data is in ~1 nA, assume maximum precision is ~1 pA\n",
        "  # this will make some states redundant\n",
        "  imported_device_states = np.unique(np.round(np.sort(imported_device_states), decimals=3))\n",
        "\n",
        "  # calculate device states possible\n",
        "  device_states = np.array([])\n",
        "  for i, value in enumerate(imported_device_states):\n",
        "      if i+1 > len(imported_device_states):\n",
        "          break\n",
        "      temp_ls = value - imported_device_states\n",
        "      device_states = np.append(device_states, temp_ls)\n",
        "\n",
        "\n",
        "  # normalize to -1 to 1\n",
        "  device_states = np.unique(np.sort(device_states))\n",
        "  device_states = device_states / np.abs(device_states).max()\n",
        "\n",
        "  # given the large number of states, we can assume some states are almost equivalent\n",
        "  # moreover, once the number of states is > 100, the discreteness doesnt matter\n",
        "  # for simplicity in the simulations, we will simply  round to 2 digits of the calculated states\n",
        "  device_states = np.round(device_states, decimals = 2)\n",
        "  device_states = np.unique(np.sort(device_states))\n",
        "  \n",
        "  return device_states"
      ],
      "metadata": {
        "id": "-Xx6QGjhsa5i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################### USER DEFINED PARAMETERS FOR SIMULATION\n",
        "# number of epochs to test\n",
        "NUM_EPOCHS = 100\n",
        "# parameter set by user that gives all the possible normalized weight states\n",
        "# assumes (1) discrete number of states that are normalized \n",
        "#         (2) states are set by two synaptic devices such that weight = weight_p - weight_m\n",
        "#         (3) because of (2), weights can vary from [-1,1]\n",
        "# user input = a 1D numpy array with values from [-1, 1]\n",
        "DEVICE_STATES = import_data_from_csv('learning_curve_vinod.csv')\n",
        "# print(len(DEVICE_STATES))\n",
        "\n",
        "# parameters for simulating read noise\n",
        "# user input = read noise mean and standard dev assuming a normal noise function\n",
        "READ_NOISE_MEAN = 0\n",
        "READ_NOISE_STDDEV = 0.1\n",
        "\n",
        "# parameter for simulating device-to-device variation\n",
        "# user input =  standard deviation of conductances\n",
        "DEVICE_VARIATION_STDDEV = 0.1\n",
        "\n",
        "# parameter for simulating devices that get stuck on Gmax or Gmin states from the start\n",
        "# user input = probability for a device to get stuck\n",
        "DEVICE_STUCK_ON_PROB = 0.1\n",
        "DEVICE_STUCK_OFF_PROB = 0.1\n",
        "\n",
        "###################### SIM PARAMETERS\n",
        "n_inputs = 28*28  # MNIST\n",
        "n_hidden1 = 300 # neurons in 1st hidden layers\n",
        "n_outputs = 10 # neurons in output layer\n",
        "learning_rate = 0.1#0.01 # grad descent\n",
        "initializer_stddev = 0.2 # standar deviation of initialized random weights\n",
        "n_epochs = 10 # number of epochs to test\n",
        "batch_size = 50 # batch size before tuning weights in grad descent\n",
        "\n",
        "g_min_value = np.min(np.abs(DEVICE_STATES))\n",
        "g_max_value = np.max(np.abs(DEVICE_STATES))\n",
        "\n",
        "# define weight update ops\n",
        "var_stuck_mat = [False, False, False, False] # if each device is stucked\n",
        "weights = [0,0,0,0]\n",
        "new_weights = [0,0,0,0]\n",
        "weight_update_op = [0,0,0,0]"
      ],
      "metadata": {
        "id": "tQVg-LNXIuzI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# will create matrix to simulate device-to-device variation by creating clipping the weights\n",
        "# will also simulate devices being stuck-on-open and stuck-on-close \n",
        "def initialize_variation_stuck_mat(shape):\n",
        "\n",
        "    # VARIATION\n",
        "    wp_max = np.ones(shape=shape) - np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape))\n",
        "    wp_min = np.zeros(shape=shape) + np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape))\n",
        "\n",
        "    wm_max = np.ones(shape=shape) - np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape))\n",
        "    wm_min = np.zeros(shape=shape) + np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape))\n",
        "\n",
        "    # STUCK\n",
        "    stuck_prob = [DEVICE_STUCK_OFF_PROB, 1 - DEVICE_STUCK_ON_PROB - DEVICE_STUCK_OFF_PROB, DEVICE_STUCK_ON_PROB]\n",
        "    w_p_stuck = np.random.choice([-1, 0, 1], size=shape, p=stuck_prob) # choose from [-1, 0, 1] with probability of [DEVICE_STUCK_OFF_PROB, 1 - DEVICE_STUCK_ON_PROB - DEVICE_STUCK_OFF_PROB, DEVICE_STUCK_ON_PROB]\n",
        "    w_m_stuck = np.random.choice([-1, 0, 1], size=shape, p=stuck_prob)\n",
        "\n",
        "    # if device is stuck OFF\n",
        "    wp_max = wp_max + (w_p_stuck == -1) * (wp_min - wp_max)\n",
        "    wm_max = wm_max + (w_m_stuck == -1) * (wm_min - wm_max)\n",
        "\n",
        "    # if device is stuck ON\n",
        "    wp_min = wp_min + (w_p_stuck == 1) * (wp_max - wp_min)\n",
        "    wm_min = wm_min + (w_m_stuck == 1) * (wm_max - wm_min)\n",
        "\n",
        "\n",
        "    # PUTTING TOGETHER CLIPPING MATRIX\n",
        "    lower_lim = np.clip(wp_min - wm_max, -g_max_value, -g_min_value)\n",
        "    upper_lim = np.clip(wp_max - wm_min, g_min_value, g_max_value)\n",
        "\n",
        "    # 2 matrices with shape = shape that contains the variation of weights\n",
        "    return [lower_lim, upper_lim]"
      ],
      "metadata": {
        "id": "Y9EKw4n_I7pG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shape = np.array(np.array(weights).shape)\n",
        "mat = initialize_variation_stuck_mat(shape)\n",
        "#mat"
      ],
      "metadata": {
        "id": "vpPp-iItJG4a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weight update with a discrete number of states and (optional) add read noise\n",
        "def discrete_weight_update(value, read_noise_mean=0, read_noise_stddev=0):\n",
        "    if read_noise_stddev != 0:\n",
        "        value += np.random.normal(read_noise_mean, read_noise_stddev)\n",
        "    absolute_difference_function = lambda list_value : abs(list_value - value)\n",
        "    return min(DEVICE_STATES, key=absolute_difference_function)\n",
        "v_discrete_weight_update = np.vectorize(discrete_weight_update)"
      ],
      "metadata": {
        "id": "322lDOO-KCxN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_weights_mat = v_discrete_weight_update(weights, read_noise_mean = READ_NOISE_MEAN,\n",
        "              read_noise_stddev = READ_NOISE_STDDEV)\n",
        "new_weights_mat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-Rj6_PaKPVC",
        "outputId": "3a5b871e-f2e9-4b38-9c88-2d8fa24ead69"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.11,  0.08, -0.03,  0.02])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_hardware_weight_update(weights_mat, var_stuck_mat):\n",
        "\n",
        "    # initialize variation and stuck matrix if not initialized\n",
        "    if type(var_stuck_mat) is not np.ndarray:\n",
        "        var_stuck_mat = initialize_variation_stuck_mat(weights_mat.shape)\n",
        "\n",
        "    # simulate weight variation and stuck on open/close\n",
        "    weights_mat = weights_mat.clip(var_stuck_mat[0], var_stuck_mat[1])\n",
        "\n",
        "    # simulate discrete states\n",
        "    weights_mat = v_discrete_weight_update(weights_mat, read_noise_mean = READ_NOISE_MEAN,\n",
        "                                read_noise_stddev = READ_NOISE_STDDEV)\n",
        "\n",
        "    return weights_mat"
      ],
      "metadata": {
        "id": "j74SsX3HMSzC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simulate_hardware_weight_update(np.array(weights), var_stuck_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9gsBDlCMuct",
        "outputId": "d2e19299-27e9-4c97-8c0a-e6dc5a6d0617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0087554 , -0.0087554 ,  0.12154736,  0.10809185])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simulate_hardware_weight_update(new_weights_mat, var_stuck_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6DtSxq5M3wG",
        "outputId": "a3f60740-99f8-470c-91b5-33d982ffb31a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.15373901, -0.04164841, -0.0087554 , -0.0087554 ])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reset default tf graph before running sim\n",
        "reset_graph()\n",
        "# get MNIST data, format\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "#X_valid, X_train = X_train[:5000], X_train[5000:]\n",
        "#y_valid, y_train = y_train[:5000], y_train[5000:]\n",
        "\n",
        "\n",
        "# define input and output placeholder variables\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\") # input\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\") # output\n",
        "\n",
        "\n",
        "#with tf.name_scope(\"dnn\"):\n",
        "initiliazer = tf.truncated_normal_initializer(stddev = initializer_stddev)\n",
        "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu, \n",
        "                          kernel_initializer=initiliazer, bias_initializer=initiliazer)\n",
        "logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\",\n",
        "                          kernel_initializer=initiliazer, bias_initializer=initiliazer)\n",
        "y_proba = tf.nn.softmax(logits)\n",
        "\n",
        "tf.trainable_variables()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWu3TUZ41cbz",
        "outputId": "8a8e3281-fb09-4193-f462-20e0db57a5bf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From <ipython-input-12-73fe66be5c05>:21: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'hidden1/kernel:0' shape=(784, 300) dtype=float32_ref>,\n",
              " <tf.Variable 'hidden1/bias:0' shape=(300,) dtype=float32_ref>,\n",
              " <tf.Variable 'outputs/kernel:0' shape=(300, 10) dtype=float32_ref>,\n",
              " <tf.Variable 'outputs/bias:0' shape=(10,) dtype=float32_ref>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "training_op = optimizer.minimize(loss)\n",
        "\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
      ],
      "metadata": {
        "id": "TreHT2gb2E8G"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_layers = [\"hidden1/kernel:0\", \"hidden1/bias:0\", \"outputs/kernel:0\", \"outputs/bias:0\"]\n",
        "for i, name in enumerate(weight_layers):\n",
        "  #print(\"i = \" + str(i))\n",
        "  #print(\"name = \" + str(name))\n",
        "  weights[i] = [v for v in tf.trainable_variables() if v.name == name][0]\n",
        "  #print(\"weights = \" + str(weights))\n",
        "  new_weights[i] = tf.placeholder(tf.float32, name=\"new_weights\"+name.replace(\"/\",\"-\").replace(\":\",\"-\"))\n",
        "  print(\"new_weights = \" + str(new_weights))\n",
        "  weight_update_op[i] = tf.assign(weights[i], new_weights[i])\n",
        "  print(\"weight_update_op = \" + str(weight_update_op))"
      ],
      "metadata": {
        "id": "G-ckc9_OO0YS",
        "outputId": "bf359e5a-467a-4b9c-fb35-cb3035068c2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new_weights = [<tf.Tensor 'new_weightshidden1-kernel-0:0' shape=<unknown> dtype=float32>, 0, 0, 0]\n",
            "weight_update_op = [<tf.Tensor 'Assign:0' shape=(784, 300) dtype=float32_ref>, 0, 0, 0]\n",
            "new_weights = [<tf.Tensor 'new_weightshidden1-kernel-0:0' shape=<unknown> dtype=float32>, <tf.Tensor 'new_weightshidden1-bias-0:0' shape=<unknown> dtype=float32>, 0, 0]\n",
            "weight_update_op = [<tf.Tensor 'Assign:0' shape=(784, 300) dtype=float32_ref>, <tf.Tensor 'Assign_1:0' shape=(300,) dtype=float32_ref>, 0, 0]\n",
            "new_weights = [<tf.Tensor 'new_weightshidden1-kernel-0:0' shape=<unknown> dtype=float32>, <tf.Tensor 'new_weightshidden1-bias-0:0' shape=<unknown> dtype=float32>, <tf.Tensor 'new_weightsoutputs-kernel-0:0' shape=<unknown> dtype=float32>, 0]\n",
            "weight_update_op = [<tf.Tensor 'Assign:0' shape=(784, 300) dtype=float32_ref>, <tf.Tensor 'Assign_1:0' shape=(300,) dtype=float32_ref>, <tf.Tensor 'Assign_2:0' shape=(300, 10) dtype=float32_ref>, 0]\n",
            "new_weights = [<tf.Tensor 'new_weightshidden1-kernel-0:0' shape=<unknown> dtype=float32>, <tf.Tensor 'new_weightshidden1-bias-0:0' shape=<unknown> dtype=float32>, <tf.Tensor 'new_weightsoutputs-kernel-0:0' shape=<unknown> dtype=float32>, <tf.Tensor 'new_weightsoutputs-bias-0:0' shape=<unknown> dtype=float32>]\n",
            "weight_update_op = [<tf.Tensor 'Assign:0' shape=(784, 300) dtype=float32_ref>, <tf.Tensor 'Assign_1:0' shape=(300,) dtype=float32_ref>, <tf.Tensor 'Assign_2:0' shape=(300, 10) dtype=float32_ref>, <tf.Tensor 'Assign_3:0' shape=(10,) dtype=float32_ref>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "id": "pTqFAzlMs7A7",
        "outputId": "b9cd20a2-8ce8-4299-e26e-6af273992bb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'hidden1/kernel:0' shape=(784, 300) dtype=float32_ref>,\n",
              " <tf.Variable 'hidden1/bias:0' shape=(300,) dtype=float32_ref>,\n",
              " <tf.Variable 'outputs/kernel:0' shape=(300, 10) dtype=float32_ref>,\n",
              " <tf.Variable 'outputs/bias:0' shape=(10,) dtype=float32_ref>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_weights"
      ],
      "metadata": {
        "id": "ulcQgj5us8jA",
        "outputId": "08df92d9-7a12-4bac-d04f-8e43fcdad230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'new_weightshidden1-kernel-0:0' shape=<unknown> dtype=float32>,\n",
              " <tf.Tensor 'new_weightshidden1-bias-0:0' shape=<unknown> dtype=float32>,\n",
              " <tf.Tensor 'new_weightsoutputs-kernel-0:0' shape=<unknown> dtype=float32>,\n",
              " <tf.Tensor 'new_weightsoutputs-bias-0:0' shape=<unknown> dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight_update_op"
      ],
      "metadata": {
        "id": "Xg4qnYNns-5y",
        "outputId": "424768dd-56bc-49c1-98a1-7f9ff4fa06a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'Assign:0' shape=(784, 300) dtype=float32_ref>,\n",
              " <tf.Tensor 'Assign_1:0' shape=(300,) dtype=float32_ref>,\n",
              " <tf.Tensor 'Assign_2:0' shape=(300, 10) dtype=float32_ref>,\n",
              " <tf.Tensor 'Assign_3:0' shape=(10,) dtype=float32_ref>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_ls = []\n",
        "recognition_rate_ls = []\n",
        "start_time = time.time()\n",
        "start_datetime  = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "weights_before = False\n",
        "weights_after = False"
      ],
      "metadata": {
        "id": "BnITN3SQ2k-y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_batch(X, y, batch_size):\n",
        "    rnd_idx = np.random.permutation(len(X))\n",
        "    n_batches = len(X) // batch_size\n",
        "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
        "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
        "        yield X_batch, y_batch"
      ],
      "metadata": {
        "id": "iJ1ohEIO2ti4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HARDWARE_SIMULATION = True\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "          sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "\n",
        "      if HARDWARE_SIMULATION:\n",
        "          ###### WEIGHT UPDATE  \n",
        "          # simulate hardware by updating weights\n",
        "          # includes discrete number of weight states\n",
        "\n",
        "          # the code below only updates hidden1/kernel:0 weights\n",
        "\n",
        "          # get weights\n",
        "          #weights_temp = [v for v in tf.trainable_variables() if v.name == \"hidden1/bias:0\"][0]\n",
        "          #weights_before = weights_temp.eval(session=sess)\n",
        "\n",
        "\n",
        "          # simulate hardware weight update\n",
        "          #new_weights_mat = simulate_hardware_weight_update(weights_mat, var_stuck_mat)\n",
        "\n",
        "          # update weights to hardware simulated weights\n",
        "\n",
        "          for i, weight in enumerate(weights):\n",
        "              print(\"i = \" + str(i))\n",
        "              weight = weight.eval(session=sess)\n",
        "              print(weight.shape)\n",
        "              new_weights_mat = simulate_hardware_weight_update(weight, var_stuck_mat[i])\n",
        "              print(new_weights_mat.shape)\n",
        "              weight_update_op[i].eval(feed_dict={new_weights[i]: new_weights_mat})\n",
        "\n",
        "\n",
        "          ###### end of WEIGHT UPDATE\n",
        "\n",
        "\n",
        "\n",
        "      # test accuracy\n",
        "      acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "      acc_valid = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "      print(epoch, \"Batch accuracy:\", acc_batch, \"Test accuracy:\", acc_valid)\n",
        "      \n",
        "      # save to list\n",
        "      epoch_ls.append(epoch)\n",
        "      recognition_rate_ls.append(acc_valid)"
      ],
      "metadata": {
        "id": "bqbPx4bO0F3n",
        "outputId": "433c27ce-97a3-4b4a-f3bd-ebf940f2e7e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "(784, 300)\n",
            "(784, 300)\n",
            "i = 1\n",
            "(300,)\n",
            "(300,)\n",
            "i = 2\n",
            "(300, 10)\n",
            "(300, 10)\n",
            "i = 3\n",
            "(10,)\n",
            "(10,)\n",
            "0 Batch accuracy: 0.76 Test accuracy: 0.7274\n",
            "i = 0\n",
            "(784, 300)\n",
            "(784, 300)\n",
            "i = 1\n",
            "(300,)\n",
            "(300,)\n",
            "i = 2\n",
            "(300, 10)\n",
            "(300, 10)\n",
            "i = 3\n",
            "(10,)\n",
            "(10,)\n",
            "1 Batch accuracy: 0.84 Test accuracy: 0.7122\n",
            "i = 0\n",
            "(784, 300)\n",
            "(784, 300)\n",
            "i = 1\n",
            "(300,)\n",
            "(300,)\n",
            "i = 2\n",
            "(300, 10)\n",
            "(300, 10)\n",
            "i = 3\n",
            "(10,)\n",
            "(10,)\n",
            "2 Batch accuracy: 0.54 Test accuracy: 0.6534\n",
            "i = 0\n",
            "(784, 300)\n",
            "(784, 300)\n",
            "i = 1\n",
            "(300,)\n",
            "(300,)\n",
            "i = 2\n",
            "(300, 10)\n",
            "(300, 10)\n",
            "i = 3\n",
            "(10,)\n",
            "(10,)\n",
            "3 Batch accuracy: 0.8 Test accuracy: 0.7726\n",
            "i = 0\n",
            "(784, 300)\n",
            "(784, 300)\n",
            "i = 1\n",
            "(300,)\n",
            "(300,)\n",
            "i = 2\n",
            "(300, 10)\n",
            "(300, 10)\n",
            "i = 3\n",
            "(10,)\n",
            "(10,)\n",
            "4 Batch accuracy: 0.78 Test accuracy: 0.6961\n",
            "i = 0\n",
            "(784, 300)\n",
            "(784, 300)\n",
            "i = 1\n",
            "(300,)\n",
            "(300,)\n",
            "i = 2\n",
            "(300, 10)\n",
            "(300, 10)\n",
            "i = 3\n",
            "(10,)\n",
            "(10,)\n",
            "5 Batch accuracy: 0.64 Test accuracy: 0.6928\n",
            "i = 0\n",
            "(784, 300)\n",
            "(784, 300)\n",
            "i = 1\n",
            "(300,)\n",
            "(300,)\n",
            "i = 2\n",
            "(300, 10)\n",
            "(300, 10)\n",
            "i = 3\n",
            "(10,)\n",
            "(10,)\n",
            "6 Batch accuracy: 0.6 Test accuracy: 0.6384\n",
            "i = 0\n",
            "(784, 300)\n",
            "(784, 300)\n",
            "i = 1\n",
            "(300,)\n",
            "(300,)\n",
            "i = 2\n",
            "(300, 10)\n",
            "(300, 10)\n",
            "i = 3\n",
            "(10,)\n",
            "(10,)\n",
            "7 Batch accuracy: 0.66 Test accuracy: 0.7028\n",
            "i = 0\n",
            "(784, 300)\n",
            "(784, 300)\n",
            "i = 1\n",
            "(300,)\n",
            "(300,)\n",
            "i = 2\n",
            "(300, 10)\n",
            "(300, 10)\n",
            "i = 3\n",
            "(10,)\n",
            "(10,)\n",
            "8 Batch accuracy: 0.68 Test accuracy: 0.7282\n",
            "i = 0\n",
            "(784, 300)\n",
            "(784, 300)\n",
            "i = 1\n",
            "(300,)\n",
            "(300,)\n",
            "i = 2\n",
            "(300, 10)\n",
            "(300, 10)\n",
            "i = 3\n",
            "(10,)\n",
            "(10,)\n",
            "9 Batch accuracy: 0.6 Test accuracy: 0.6908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zVATdsYA0RRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJp1d7do-pMf"
      },
      "source": [
        "def run_MLP_simulation(save_results_input = False,\n",
        "                       num_epochs_input=50, \n",
        "                       hardware_simulation_input=False, \n",
        "                       device_states_input=False,\n",
        "                       read_noise_mean_input=0,\n",
        "                       read_noise_stddev_input=0,\n",
        "                       device_variation_stddev_input=0,\n",
        "                       device_stuck_on_prob_input=0,\n",
        "                       device_stuck_off_prob_input=0):\n",
        "    \n",
        "    \n",
        "    \n",
        "    ###################### USER DEFINED PARAMETERS FOR SIMULATION\n",
        "    # whether or not to save results\n",
        "    SAVE_RESULTS = save_results_input\n",
        "    \n",
        "    # number of epochs to test\n",
        "    NUM_EPOCHS = num_epochs_input\n",
        "\n",
        "    # flag which determines whether this is a hardware simulation or purely software\n",
        "    HARDWARE_SIMULATION = hardware_simulation_input\n",
        "\n",
        "    # parameter set by user that gives all the possible normalized weight states\n",
        "    # assumes (1) discrete number of states that are normalized \n",
        "    #         (2) states are set by two synaptic devices such that weight = weight_p - weight_m\n",
        "    #         (3) because of (2), weights can vary from [-1,1]\n",
        "    # user input = a 1D numpy array with values from [-1, 1]\n",
        "    DEVICE_STATES = device_states_input\n",
        "\n",
        "\n",
        "    # parameters for simulating read noise\n",
        "    # user input = read noise mean and standard dev assuming a normal noise function\n",
        "    READ_NOISE_MEAN = read_noise_mean_input\n",
        "    READ_NOISE_STDDEV = read_noise_stddev_input\n",
        "\n",
        "    # parameter for simulating device-to-device variation\n",
        "    # user input =  standard deviation of conductances\n",
        "    DEVICE_VARIATION_STDDEV = device_variation_stddev_input\n",
        "\n",
        "    # parameter for simulating devices that get stuck on Gmax or Gmin states from the start\n",
        "    # user input = probability for a device to get stuck\n",
        "    DEVICE_STUCK_ON_PROB = device_stuck_on_prob_input\n",
        "    DEVICE_STUCK_OFF_PROB = device_stuck_off_prob_input\n",
        "\n",
        "    \n",
        "    \n",
        "    ###################### SIM PARAMETERS\n",
        "    n_inputs = 28*28  # MNIST\n",
        "    n_hidden1 = 300 # neurons in 1st hidden layers\n",
        "    n_outputs = 10 # neurons in output layer\n",
        "    learning_rate = 0.1#0.01 # grad descent\n",
        "    initializer_stddev = 0.2 # standar deviation of initialized random weights\n",
        "    n_epochs = NUM_EPOCHS # number of epochs to test\n",
        "    batch_size = 50 # batch size before tuning weights in grad descent\n",
        "\n",
        "    g_min_value = np.min(np.abs(DEVICE_STATES))\n",
        "    g_max_value = np.max(np.abs(DEVICE_STATES))\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    ###################### FUNCTIONS\n",
        "\n",
        "    # to make this notebook's output stable across runs\n",
        "    def reset_graph(seed=42):\n",
        "        tf.reset_default_graph()\n",
        "        tf.set_random_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    # will create matrix to simulate device-to-device variation by creating clipping the weights\n",
        "    # will also simulate devices being stuck-on-open and stuck-on-close \n",
        "    def initialize_variation_stuck_mat(shape):\n",
        "\n",
        "        # VARIATION\n",
        "        wp_max = np.ones(shape=shape) - np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape))\n",
        "        wp_min = np.zeros(shape=shape) + np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape))\n",
        "\n",
        "        wm_max = np.ones(shape=shape) - np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape))\n",
        "        wm_min = np.zeros(shape=shape) + np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape))\n",
        "\n",
        "        # STUCK\n",
        "        stuck_prob = [DEVICE_STUCK_OFF_PROB, 1 - DEVICE_STUCK_ON_PROB - DEVICE_STUCK_OFF_PROB, DEVICE_STUCK_ON_PROB]\n",
        "        w_p_stuck = np.random.choice([-1, 0, 1], size=shape, p=stuck_prob) # choose from [-1, 0, 1] with probability of [DEVICE_STUCK_OFF_PROB, 1 - DEVICE_STUCK_ON_PROB - DEVICE_STUCK_OFF_PROB, DEVICE_STUCK_ON_PROB]\n",
        "        w_m_stuck = np.random.choice([-1, 0, 1], size=shape, p=stuck_prob)\n",
        "\n",
        "        # if device is stuck OFF\n",
        "        wp_max = wp_max + (w_p_stuck == -1) * (wp_min - wp_max)\n",
        "        wm_max = wm_max + (w_m_stuck == -1) * (wm_min - wm_max)\n",
        "\n",
        "        # if device is stuck ON\n",
        "        wp_min = wp_min + (w_p_stuck == 1) * (wp_max - wp_min)\n",
        "        wm_min = wm_min + (w_m_stuck == 1) * (wm_max - wm_min)\n",
        "\n",
        "\n",
        "        # PUTTING TOGETHER CLIPPING MATRIX\n",
        "        lower_lim = np.clip(wp_min - wm_max, -g_max_value, -g_min_value)\n",
        "        upper_lim = np.clip(wp_max - wm_min, g_min_value, g_max_value)\n",
        "\n",
        "        return [lower_lim, upper_lim]\n",
        "\n",
        "\n",
        "    # weight update with a discrete number of states and (optional) add read noise\n",
        "    def discrete_weight_update(value, read_noise_mean=0, read_noise_stddev=0):\n",
        "        if read_noise_stddev != 0:\n",
        "            value += np.random.normal(read_noise_mean, read_noise_stddev)\n",
        "        absolute_difference_function = lambda list_value : abs(list_value - value)\n",
        "        return min(DEVICE_STATES, key=absolute_difference_function)\n",
        "    v_discrete_weight_update = np.vectorize(discrete_weight_update)\n",
        "\n",
        "\n",
        "\n",
        "    # function puts together all the parts\n",
        "    # 1. Device variation\n",
        "    # 2. Stuck-on/off \n",
        "    # 3. Discrete number of weight states\n",
        "    # Input = software weights matrix, Output = hardware weights matrix\n",
        "    def simulate_hardware_weight_update(weights_mat, var_stuck_mat):\n",
        "\n",
        "        # initialize variation and stuck matrix if not initialized\n",
        "        if type(var_stuck_mat) is not np.ndarray:\n",
        "            var_stuck_mat = initialize_variation_stuck_mat(weights_mat.shape)\n",
        "\n",
        "        # simulate weight variation and stuck on open/close\n",
        "        weights_mat = weights_mat.clip(var_stuck_mat[0], var_stuck_mat[1])\n",
        "\n",
        "        # simulate discrete states\n",
        "        weights_mat = v_discrete_weight_update(weights_mat, read_noise_mean = READ_NOISE_MEAN,\n",
        "                                                 read_noise_stddev = READ_NOISE_STDDEV)\n",
        "\n",
        "        return weights_mat\n",
        "    \n",
        "    \n",
        "    ###################### MLP SIM SETUP\n",
        "    # reset default tf graph before running sim\n",
        "    reset_graph()\n",
        "\n",
        "    # get MNIST data, format\n",
        "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "    X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "    y_train = y_train.astype(np.int32)\n",
        "    y_test = y_test.astype(np.int32)\n",
        "    #X_valid, X_train = X_train[:5000], X_train[5000:]\n",
        "    #y_valid, y_train = y_train[:5000], y_train[5000:]\n",
        "\n",
        "\n",
        "    # define input and output placeholder variables\n",
        "    X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\") # input\n",
        "    y = tf.placeholder(tf.int32, shape=(None), name=\"y\") # output\n",
        "\n",
        "    # define NN layers\n",
        "    #with tf.name_scope(\"dnn\"):\n",
        "    initiliazer = tf.truncated_normal_initializer(stddev = initializer_stddev)\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu, \n",
        "                              kernel_initializer=initiliazer, bias_initializer=initiliazer)\n",
        "    logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\",\n",
        "                              kernel_initializer=initiliazer, bias_initializer=initiliazer)\n",
        "    y_proba = tf.nn.softmax(logits)\n",
        "\n",
        "    # define loss\n",
        "    #with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "\n",
        "    # define training\n",
        "    #with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss)\n",
        "\n",
        "    # define recognition rate eval op\n",
        "    #with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "    # define weight update ops\n",
        "    var_stuck_mat = [False, False, False, False]\n",
        "    weights = [0,0,0,0]\n",
        "    new_weights = [0,0,0,0]\n",
        "    weight_update_op = [0,0,0,0]\n",
        "    with tf.name_scope(\"weight_update\"):\n",
        "        weight_layers = [\"hidden1/kernel:0\", \"hidden1/bias:0\", \"outputs/kernel:0\", \"outputs/bias:0\"]\n",
        "        for i, name in enumerate(weight_layers):\n",
        "            weights[i] = [v for v in tf.trainable_variables() if v.name == name][0]\n",
        "            new_weights[i] = tf.placeholder(tf.float32, name=\"new_weights\"+name.replace(\"/\",\"-\").replace(\":\",\"-\"))\n",
        "            weight_update_op[i] = tf.assign(weights[i], new_weights[i])\n",
        "    # len(weights) = 4\n",
        "    # weights[i].shape = (784, 300), (300,), (300, 10), (10,)    \n",
        "    \n",
        "    \n",
        "    ###################### MLP SIM RUN\n",
        "    epoch_ls = []\n",
        "    recognition_rate_ls = []\n",
        "    start_time = time.time()\n",
        "    start_datetime  = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    weights_before = False\n",
        "    weights_after = False\n",
        "\n",
        "    def shuffle_batch(X, y, batch_size):\n",
        "        rnd_idx = np.random.permutation(len(X))\n",
        "        n_batches = len(X) // batch_size\n",
        "        for batch_idx in np.array_split(rnd_idx, n_batches):\n",
        "            X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
        "            yield X_batch, y_batch\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        init.run()\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "            for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "\n",
        "            if HARDWARE_SIMULATION:\n",
        "                ###### WEIGHT UPDATE  \n",
        "                # simulate hardware by updating weights\n",
        "                # includes discrete number of weight states\n",
        "\n",
        "                # the code below only updates hidden1/kernel:0 weights\n",
        "\n",
        "                # get weights\n",
        "                #weights_temp = [v for v in tf.trainable_variables() if v.name == \"hidden1/bias:0\"][0]\n",
        "                #weights_before = weights_temp.eval(session=sess)\n",
        "\n",
        "\n",
        "                # simulate hardware weight update\n",
        "                #new_weights_mat = simulate_hardware_weight_update(weights_mat, var_stuck_mat)\n",
        "\n",
        "                # update weights to hardware simulated weights\n",
        "\n",
        "                for i, weight in enumerate(weights):\n",
        "\n",
        "                    weight = weight.eval(session=sess)\n",
        "                    new_weights_mat = simulate_hardware_weight_update(weight, var_stuck_mat[i])\n",
        "                    weight_update_op[i].eval(feed_dict={new_weights[i]: new_weights_mat})\n",
        "\n",
        "\n",
        "                ###### end of WEIGHT UPDATE\n",
        "\n",
        "\n",
        "\n",
        "            # test accuracy\n",
        "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "            acc_valid = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "            print(epoch, \"Batch accuracy:\", acc_batch, \"Test accuracy:\", acc_valid)\n",
        "            \n",
        "            # save to list\n",
        "            epoch_ls.append(epoch)\n",
        "            recognition_rate_ls.append(acc_valid)\n",
        "\n",
        "            #weights_temp = [v for v in tf.trainable_variables() if v.name == \"hidden1/bias:0\"][0]\n",
        "            #weights_after = weights_temp.eval(session=sess)    \n",
        "\n",
        "\n",
        "        # save results\n",
        "        if SAVE_RESULTS:\n",
        "            save_path = \"./MLP_sim_results/MLP_sim_\" + start_datetime + \"/model_\" + start_datetime\n",
        "            save_path = saver.save(sess, save_path + \".ckpt\")\n",
        "    \n",
        "    # print out duration\n",
        "    print(\"--- %0.2f seconds ---\" % (time.time() - start_time))\n",
        "    \n",
        "    # save all results, including testing parameters and data\n",
        "    if SAVE_RESULTS:\n",
        "        save_path = \"./MLP_sim_results/MLP_sim_\" + start_datetime + \"/model_\" + start_datetime\n",
        "\n",
        "        data_df = pd.DataFrame({\"Epoch\": epoch_ls, \"Recognition Rate\": recognition_rate_ls})\n",
        "        data_df.to_csv(save_path + \"_data.csv\", index=False,)\n",
        "\n",
        "        with open(save_path + \"_meta.txt\", \"w\") as text_file:\n",
        "            print(\"---------- User input parameters -------------\", file=text_file)\n",
        "            print(\"Simulation start time: {}\".format(start_datetime), file=text_file)\n",
        "            print(\"Duration: {}\".format(time.time() - start_time), file=text_file)\n",
        "            print(\"Epochs: {}\".format(num_epochs_input), file=text_file)\n",
        "            print(\"Hardware simulation?: {}\".format(hardware_simulation_input), file=text_file)\n",
        "            print(\"Read noise - mean: {}\".format(read_noise_mean_input), file=text_file)\n",
        "            print(\"Read noise - standard deviation: {}\".format(read_noise_stddev_input), file=text_file)\n",
        "            print(\"Device variation - standard deviation: {}\".format(device_variation_stddev_input), file=text_file)\n",
        "            print(\"Device stuck on probability: {}\".format(device_stuck_on_prob_input), file=text_file)\n",
        "            print(\"Device stuck off probability: {}\".format(device_stuck_off_prob_input), file=text_file)\n",
        "            print(\"Device states used: {}\".format(device_states_input), file=text_file)\n",
        "\n",
        "            print(\"---------- Simulation parameters -------------\", file=text_file)\n",
        "            print(\"Number of inputs: {}\".format(n_inputs), file=text_file)\n",
        "            print(\"Layers: {}\".format(weight_layers), file=text_file)\n",
        "            print(\"Hidden1 # of neurons: {}\".format(n_hidden1), file=text_file)\n",
        "            print(\"Outputs # of neurons: {}\".format(n_outputs), file=text_file)\n",
        "            print(\"Learning rate: {}\".format(learning_rate), file=text_file)\n",
        "            print(\"Initializer standad dev: {}\".format(initializer_stddev), file=text_file)\n",
        "            print(\"Batch size: {}\".format(batch_size), file=text_file)\n",
        "\n",
        "\n",
        "# imports data from single column CSV file with possible current/conductance states\n",
        "# return numpy array of approximate states possible using this hardware\n",
        "# this import method is not generalized, but fine-tuned to Vinod's devices\n",
        "def import_data_from_csv(filename):\n",
        "    # import data\n",
        "    imported_device_states = np.genfromtxt(filename, delimiter=',')[1:]\n",
        "\n",
        "    # since data is in ~1 nA, assume maximum precision is ~1 pA\n",
        "    # this will make some states redundant\n",
        "    imported_device_states = np.unique(np.round(np.sort(imported_device_states), decimals=3))\n",
        "    #print(len(imported_device_states))\n",
        "    # calculate device states possible\n",
        "    device_states = np.array([])\n",
        "    for i, value in enumerate(imported_device_states):\n",
        "      #print(i)\n",
        "      temp_ls = value - imported_device_states\n",
        "      device_states = np.append(device_states, temp_ls)\n",
        "\n",
        "    #print(len(device_states))\n",
        "    # normalize to -1 to 1\n",
        "    device_states = np.unique(np.sort(device_states))\n",
        "    device_states = device_states / np.abs(device_states).max()\n",
        "    #print(len(device_states))\n",
        "    # given the large number of states, we can assume some states are almost equivalent\n",
        "    # moreover, once the number of states is > 100, the discreteness doesnt matter\n",
        "    # for simplicity in the simulations, we will simply  round to 2 digits of the calculated states\n",
        "    device_states = np.round(device_states, decimals = 2)\n",
        "    device_states = np.unique(np.sort(device_states))\n",
        "    #print(len(device_states))\n",
        "    return device_states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "u8cD0K-M-pMw",
        "outputId": "5e9d7b66-282a-41d1-920d-a23d66158eb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(1):\n",
        "  imported_device_states = import_data_from_csv(filename='learning_curve_vinod.csv')\n",
        "  run_MLP_simulation(num_epochs_input = 2, \n",
        "            hardware_simulation_input = True, \n",
        "            device_states_input = imported_device_states,\n",
        "            read_noise_mean_input = 0.0,\n",
        "            read_noise_stddev_input = 0.0,\n",
        "            device_variation_stddev_input = 0.0,\n",
        "            device_stuck_on_prob_input = 0.0,\n",
        "            device_stuck_off_prob_input = 0.0,\n",
        "            save_results_input = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 300)\n",
            "(300,)\n",
            "(300, 10)\n",
            "(10,)\n",
            "0 Batch accuracy: 0.94 Test accuracy: 0.9442\n",
            "1 Batch accuracy: 0.96 Test accuracy: 0.9567\n",
            "--- 55.24 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rchKubR2-pMy",
        "outputId": "271df512-103c-4a55-c5e0-d8303c4f4e6f"
      },
      "source": [
        "# run hardware sim 4 times\n",
        "for i in range(4):\n",
        "    imported_device_states = import_data_from_csv(filename='learning_curve_vinod.csv')\n",
        "    run_MLP_simulation(num_epochs_input = 100, \n",
        "                       hardware_simulation_input = True, \n",
        "                       device_states_input = imported_device_states,\n",
        "                       read_noise_mean_input = 0.0,\n",
        "                       read_noise_stddev_input = 0.1,\n",
        "                       device_variation_stddev_input = 0.0,\n",
        "                       device_stuck_on_prob_input = 0.00,\n",
        "                       device_stuck_off_prob_input = 0.00,\n",
        "                       save_results_input = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Batch accuracy: 0.72 Test accuracy: 0.6556\n",
            "1 Batch accuracy: 0.6 Test accuracy: 0.5914\n",
            "2 Batch accuracy: 0.7 Test accuracy: 0.7075\n",
            "3 Batch accuracy: 0.5 Test accuracy: 0.5555\n",
            "4 Batch accuracy: 0.82 Test accuracy: 0.7896\n",
            "5 Batch accuracy: 0.76 Test accuracy: 0.7968\n",
            "6 Batch accuracy: 0.8 Test accuracy: 0.776\n",
            "7 Batch accuracy: 0.82 Test accuracy: 0.7581\n",
            "8 Batch accuracy: 0.9 Test accuracy: 0.8142\n",
            "9 Batch accuracy: 0.6 Test accuracy: 0.6915\n",
            "10 Batch accuracy: 0.78 Test accuracy: 0.8267\n",
            "11 Batch accuracy: 0.9 Test accuracy: 0.8334\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.8398\n",
            "13 Batch accuracy: 0.82 Test accuracy: 0.8183\n",
            "14 Batch accuracy: 0.8 Test accuracy: 0.843\n",
            "15 Batch accuracy: 0.92 Test accuracy: 0.846\n",
            "16 Batch accuracy: 0.78 Test accuracy: 0.826\n",
            "17 Batch accuracy: 0.82 Test accuracy: 0.8299\n",
            "18 Batch accuracy: 0.84 Test accuracy: 0.8476\n",
            "19 Batch accuracy: 0.86 Test accuracy: 0.8514\n",
            "20 Batch accuracy: 0.84 Test accuracy: 0.8119\n",
            "21 Batch accuracy: 0.88 Test accuracy: 0.829\n",
            "22 Batch accuracy: 0.78 Test accuracy: 0.8402\n",
            "23 Batch accuracy: 0.86 Test accuracy: 0.8478\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.8553\n",
            "25 Batch accuracy: 0.76 Test accuracy: 0.8315\n",
            "26 Batch accuracy: 0.88 Test accuracy: 0.8339\n",
            "27 Batch accuracy: 0.88 Test accuracy: 0.8776\n",
            "28 Batch accuracy: 0.84 Test accuracy: 0.8667\n",
            "29 Batch accuracy: 0.86 Test accuracy: 0.8583\n",
            "30 Batch accuracy: 0.86 Test accuracy: 0.874\n",
            "31 Batch accuracy: 0.92 Test accuracy: 0.8726\n",
            "32 Batch accuracy: 0.88 Test accuracy: 0.8804\n",
            "33 Batch accuracy: 0.88 Test accuracy: 0.8656\n",
            "34 Batch accuracy: 0.86 Test accuracy: 0.8395\n",
            "35 Batch accuracy: 0.88 Test accuracy: 0.865\n",
            "36 Batch accuracy: 0.88 Test accuracy: 0.8673\n",
            "37 Batch accuracy: 0.82 Test accuracy: 0.8524\n",
            "38 Batch accuracy: 0.8 Test accuracy: 0.8347\n",
            "39 Batch accuracy: 0.82 Test accuracy: 0.877\n",
            "40 Batch accuracy: 0.92 Test accuracy: 0.8657\n",
            "41 Batch accuracy: 0.82 Test accuracy: 0.881\n",
            "42 Batch accuracy: 0.84 Test accuracy: 0.8589\n",
            "43 Batch accuracy: 0.88 Test accuracy: 0.8753\n",
            "44 Batch accuracy: 0.84 Test accuracy: 0.8859\n",
            "45 Batch accuracy: 0.9 Test accuracy: 0.8712\n",
            "46 Batch accuracy: 0.86 Test accuracy: 0.869\n",
            "47 Batch accuracy: 0.82 Test accuracy: 0.8643\n",
            "48 Batch accuracy: 0.9 Test accuracy: 0.8693\n",
            "49 Batch accuracy: 0.92 Test accuracy: 0.8565\n",
            "50 Batch accuracy: 0.8 Test accuracy: 0.8866\n",
            "51 Batch accuracy: 0.96 Test accuracy: 0.8775\n",
            "52 Batch accuracy: 0.9 Test accuracy: 0.8685\n",
            "53 Batch accuracy: 0.74 Test accuracy: 0.8609\n",
            "54 Batch accuracy: 0.86 Test accuracy: 0.8633\n",
            "55 Batch accuracy: 0.92 Test accuracy: 0.8693\n",
            "56 Batch accuracy: 0.82 Test accuracy: 0.871\n",
            "57 Batch accuracy: 0.9 Test accuracy: 0.881\n",
            "58 Batch accuracy: 0.84 Test accuracy: 0.8849\n",
            "59 Batch accuracy: 0.9 Test accuracy: 0.8547\n",
            "60 Batch accuracy: 0.88 Test accuracy: 0.8763\n",
            "61 Batch accuracy: 0.88 Test accuracy: 0.8825\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.8704\n",
            "63 Batch accuracy: 0.88 Test accuracy: 0.8854\n",
            "64 Batch accuracy: 0.84 Test accuracy: 0.8656\n",
            "65 Batch accuracy: 0.9 Test accuracy: 0.8631\n",
            "66 Batch accuracy: 0.92 Test accuracy: 0.8702\n",
            "67 Batch accuracy: 0.92 Test accuracy: 0.8812\n",
            "68 Batch accuracy: 0.9 Test accuracy: 0.8789\n",
            "69 Batch accuracy: 0.9 Test accuracy: 0.8849\n",
            "70 Batch accuracy: 0.88 Test accuracy: 0.8887\n",
            "71 Batch accuracy: 0.88 Test accuracy: 0.8795\n",
            "72 Batch accuracy: 0.9 Test accuracy: 0.8821\n",
            "73 Batch accuracy: 0.94 Test accuracy: 0.8834\n",
            "74 Batch accuracy: 0.9 Test accuracy: 0.8834\n",
            "75 Batch accuracy: 0.94 Test accuracy: 0.884\n",
            "76 Batch accuracy: 0.92 Test accuracy: 0.8814\n",
            "77 Batch accuracy: 0.9 Test accuracy: 0.8798\n",
            "78 Batch accuracy: 0.92 Test accuracy: 0.8825\n",
            "79 Batch accuracy: 0.92 Test accuracy: 0.886\n",
            "80 Batch accuracy: 0.9 Test accuracy: 0.8741\n",
            "81 Batch accuracy: 0.8 Test accuracy: 0.8845\n",
            "82 Batch accuracy: 0.94 Test accuracy: 0.8958\n",
            "83 Batch accuracy: 0.88 Test accuracy: 0.9004\n",
            "84 Batch accuracy: 0.9 Test accuracy: 0.8872\n",
            "85 Batch accuracy: 0.82 Test accuracy: 0.8762\n",
            "86 Batch accuracy: 0.9 Test accuracy: 0.885\n",
            "87 Batch accuracy: 0.84 Test accuracy: 0.8654\n",
            "88 Batch accuracy: 0.94 Test accuracy: 0.8849\n",
            "89 Batch accuracy: 0.86 Test accuracy: 0.8693\n",
            "90 Batch accuracy: 0.94 Test accuracy: 0.8902\n",
            "91 Batch accuracy: 0.9 Test accuracy: 0.9053\n",
            "92 Batch accuracy: 0.84 Test accuracy: 0.8824\n",
            "93 Batch accuracy: 0.88 Test accuracy: 0.8821\n",
            "94 Batch accuracy: 0.86 Test accuracy: 0.875\n",
            "95 Batch accuracy: 0.98 Test accuracy: 0.8869\n",
            "96 Batch accuracy: 0.92 Test accuracy: 0.8769\n",
            "97 Batch accuracy: 0.82 Test accuracy: 0.8863\n",
            "98 Batch accuracy: 0.88 Test accuracy: 0.8889\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.8792\n",
            "--- 3070.01 seconds ---\n",
            "0 Batch accuracy: 0.72 Test accuracy: 0.6556\n",
            "1 Batch accuracy: 0.6 Test accuracy: 0.5914\n",
            "2 Batch accuracy: 0.7 Test accuracy: 0.7075\n",
            "3 Batch accuracy: 0.5 Test accuracy: 0.5555\n",
            "4 Batch accuracy: 0.82 Test accuracy: 0.7896\n",
            "5 Batch accuracy: 0.76 Test accuracy: 0.7968\n",
            "6 Batch accuracy: 0.8 Test accuracy: 0.776\n",
            "7 Batch accuracy: 0.82 Test accuracy: 0.7581\n",
            "8 Batch accuracy: 0.9 Test accuracy: 0.8142\n",
            "9 Batch accuracy: 0.6 Test accuracy: 0.6915\n",
            "10 Batch accuracy: 0.78 Test accuracy: 0.8267\n",
            "11 Batch accuracy: 0.9 Test accuracy: 0.8334\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.8398\n",
            "13 Batch accuracy: 0.82 Test accuracy: 0.8183\n",
            "14 Batch accuracy: 0.8 Test accuracy: 0.843\n",
            "15 Batch accuracy: 0.92 Test accuracy: 0.846\n",
            "16 Batch accuracy: 0.78 Test accuracy: 0.826\n",
            "17 Batch accuracy: 0.82 Test accuracy: 0.8299\n",
            "18 Batch accuracy: 0.84 Test accuracy: 0.8476\n",
            "19 Batch accuracy: 0.86 Test accuracy: 0.8514\n",
            "20 Batch accuracy: 0.84 Test accuracy: 0.8119\n",
            "21 Batch accuracy: 0.88 Test accuracy: 0.829\n",
            "22 Batch accuracy: 0.78 Test accuracy: 0.8402\n",
            "23 Batch accuracy: 0.86 Test accuracy: 0.8478\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.8553\n",
            "25 Batch accuracy: 0.76 Test accuracy: 0.8315\n",
            "26 Batch accuracy: 0.88 Test accuracy: 0.8339\n",
            "27 Batch accuracy: 0.88 Test accuracy: 0.8776\n",
            "28 Batch accuracy: 0.84 Test accuracy: 0.8667\n",
            "29 Batch accuracy: 0.86 Test accuracy: 0.8583\n",
            "30 Batch accuracy: 0.86 Test accuracy: 0.874\n",
            "31 Batch accuracy: 0.92 Test accuracy: 0.8726\n",
            "32 Batch accuracy: 0.88 Test accuracy: 0.8804\n",
            "33 Batch accuracy: 0.88 Test accuracy: 0.8656\n",
            "34 Batch accuracy: 0.86 Test accuracy: 0.8395\n",
            "35 Batch accuracy: 0.88 Test accuracy: 0.865\n",
            "36 Batch accuracy: 0.88 Test accuracy: 0.8673\n",
            "37 Batch accuracy: 0.82 Test accuracy: 0.8524\n",
            "38 Batch accuracy: 0.8 Test accuracy: 0.8347\n",
            "39 Batch accuracy: 0.82 Test accuracy: 0.877\n",
            "40 Batch accuracy: 0.92 Test accuracy: 0.8657\n",
            "41 Batch accuracy: 0.82 Test accuracy: 0.881\n",
            "42 Batch accuracy: 0.84 Test accuracy: 0.8589\n",
            "43 Batch accuracy: 0.88 Test accuracy: 0.8753\n",
            "44 Batch accuracy: 0.84 Test accuracy: 0.8859\n",
            "45 Batch accuracy: 0.9 Test accuracy: 0.8712\n",
            "46 Batch accuracy: 0.86 Test accuracy: 0.869\n",
            "47 Batch accuracy: 0.82 Test accuracy: 0.8643\n",
            "48 Batch accuracy: 0.9 Test accuracy: 0.8693\n",
            "49 Batch accuracy: 0.92 Test accuracy: 0.8565\n",
            "50 Batch accuracy: 0.8 Test accuracy: 0.8866\n",
            "51 Batch accuracy: 0.96 Test accuracy: 0.8775\n",
            "52 Batch accuracy: 0.9 Test accuracy: 0.8685\n",
            "53 Batch accuracy: 0.74 Test accuracy: 0.8609\n",
            "54 Batch accuracy: 0.86 Test accuracy: 0.8633\n",
            "55 Batch accuracy: 0.92 Test accuracy: 0.8693\n",
            "56 Batch accuracy: 0.82 Test accuracy: 0.871\n",
            "57 Batch accuracy: 0.9 Test accuracy: 0.881\n",
            "58 Batch accuracy: 0.84 Test accuracy: 0.8849\n",
            "59 Batch accuracy: 0.9 Test accuracy: 0.8547\n",
            "60 Batch accuracy: 0.88 Test accuracy: 0.8763\n",
            "61 Batch accuracy: 0.88 Test accuracy: 0.8825\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.8704\n",
            "63 Batch accuracy: 0.88 Test accuracy: 0.8854\n",
            "64 Batch accuracy: 0.84 Test accuracy: 0.8656\n",
            "65 Batch accuracy: 0.9 Test accuracy: 0.8631\n",
            "66 Batch accuracy: 0.92 Test accuracy: 0.8702\n",
            "67 Batch accuracy: 0.92 Test accuracy: 0.8812\n",
            "68 Batch accuracy: 0.9 Test accuracy: 0.8789\n",
            "69 Batch accuracy: 0.9 Test accuracy: 0.8849\n",
            "70 Batch accuracy: 0.88 Test accuracy: 0.8887\n",
            "71 Batch accuracy: 0.88 Test accuracy: 0.8795\n",
            "72 Batch accuracy: 0.9 Test accuracy: 0.8821\n",
            "73 Batch accuracy: 0.94 Test accuracy: 0.8834\n",
            "74 Batch accuracy: 0.9 Test accuracy: 0.8834\n",
            "75 Batch accuracy: 0.94 Test accuracy: 0.884\n",
            "76 Batch accuracy: 0.92 Test accuracy: 0.8814\n",
            "77 Batch accuracy: 0.9 Test accuracy: 0.8798\n",
            "78 Batch accuracy: 0.92 Test accuracy: 0.8825\n",
            "79 Batch accuracy: 0.92 Test accuracy: 0.886\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "80 Batch accuracy: 0.9 Test accuracy: 0.8741\n",
            "81 Batch accuracy: 0.8 Test accuracy: 0.8845\n",
            "82 Batch accuracy: 0.94 Test accuracy: 0.8958\n",
            "83 Batch accuracy: 0.88 Test accuracy: 0.9004\n",
            "84 Batch accuracy: 0.9 Test accuracy: 0.8872\n",
            "85 Batch accuracy: 0.82 Test accuracy: 0.8762\n",
            "86 Batch accuracy: 0.9 Test accuracy: 0.885\n",
            "87 Batch accuracy: 0.84 Test accuracy: 0.8654\n",
            "88 Batch accuracy: 0.94 Test accuracy: 0.8849\n",
            "89 Batch accuracy: 0.86 Test accuracy: 0.8693\n",
            "90 Batch accuracy: 0.94 Test accuracy: 0.8902\n",
            "91 Batch accuracy: 0.9 Test accuracy: 0.9053\n",
            "92 Batch accuracy: 0.84 Test accuracy: 0.8824\n",
            "93 Batch accuracy: 0.88 Test accuracy: 0.8821\n",
            "94 Batch accuracy: 0.86 Test accuracy: 0.875\n",
            "95 Batch accuracy: 0.98 Test accuracy: 0.8869\n",
            "96 Batch accuracy: 0.92 Test accuracy: 0.8769\n",
            "97 Batch accuracy: 0.82 Test accuracy: 0.8863\n",
            "98 Batch accuracy: 0.88 Test accuracy: 0.8889\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.8792\n",
            "--- 3072.75 seconds ---\n",
            "0 Batch accuracy: 0.72 Test accuracy: 0.6556\n",
            "1 Batch accuracy: 0.6 Test accuracy: 0.5914\n",
            "2 Batch accuracy: 0.7 Test accuracy: 0.7075\n",
            "3 Batch accuracy: 0.5 Test accuracy: 0.5555\n",
            "4 Batch accuracy: 0.82 Test accuracy: 0.7896\n",
            "5 Batch accuracy: 0.76 Test accuracy: 0.7968\n",
            "6 Batch accuracy: 0.8 Test accuracy: 0.776\n",
            "7 Batch accuracy: 0.82 Test accuracy: 0.7581\n",
            "8 Batch accuracy: 0.9 Test accuracy: 0.8142\n",
            "9 Batch accuracy: 0.6 Test accuracy: 0.6915\n",
            "10 Batch accuracy: 0.78 Test accuracy: 0.8267\n",
            "11 Batch accuracy: 0.9 Test accuracy: 0.8334\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.8398\n",
            "13 Batch accuracy: 0.82 Test accuracy: 0.8183\n",
            "14 Batch accuracy: 0.8 Test accuracy: 0.843\n",
            "15 Batch accuracy: 0.92 Test accuracy: 0.846\n",
            "16 Batch accuracy: 0.78 Test accuracy: 0.826\n",
            "17 Batch accuracy: 0.82 Test accuracy: 0.8299\n",
            "18 Batch accuracy: 0.84 Test accuracy: 0.8476\n",
            "19 Batch accuracy: 0.86 Test accuracy: 0.8514\n",
            "20 Batch accuracy: 0.84 Test accuracy: 0.8119\n",
            "21 Batch accuracy: 0.88 Test accuracy: 0.829\n",
            "22 Batch accuracy: 0.78 Test accuracy: 0.8402\n",
            "23 Batch accuracy: 0.86 Test accuracy: 0.8478\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.8553\n",
            "25 Batch accuracy: 0.76 Test accuracy: 0.8315\n",
            "26 Batch accuracy: 0.88 Test accuracy: 0.8339\n",
            "27 Batch accuracy: 0.88 Test accuracy: 0.8776\n",
            "28 Batch accuracy: 0.84 Test accuracy: 0.8667\n",
            "29 Batch accuracy: 0.86 Test accuracy: 0.8583\n",
            "30 Batch accuracy: 0.86 Test accuracy: 0.874\n",
            "31 Batch accuracy: 0.92 Test accuracy: 0.8726\n",
            "32 Batch accuracy: 0.88 Test accuracy: 0.8804\n",
            "33 Batch accuracy: 0.88 Test accuracy: 0.8656\n",
            "34 Batch accuracy: 0.86 Test accuracy: 0.8395\n",
            "35 Batch accuracy: 0.88 Test accuracy: 0.865\n",
            "36 Batch accuracy: 0.88 Test accuracy: 0.8673\n",
            "37 Batch accuracy: 0.82 Test accuracy: 0.8524\n",
            "38 Batch accuracy: 0.8 Test accuracy: 0.8347\n",
            "39 Batch accuracy: 0.82 Test accuracy: 0.877\n",
            "40 Batch accuracy: 0.92 Test accuracy: 0.8657\n",
            "41 Batch accuracy: 0.82 Test accuracy: 0.881\n",
            "42 Batch accuracy: 0.84 Test accuracy: 0.8589\n",
            "43 Batch accuracy: 0.88 Test accuracy: 0.8753\n",
            "44 Batch accuracy: 0.84 Test accuracy: 0.8859\n",
            "45 Batch accuracy: 0.9 Test accuracy: 0.8712\n",
            "46 Batch accuracy: 0.86 Test accuracy: 0.869\n",
            "47 Batch accuracy: 0.82 Test accuracy: 0.8643\n",
            "48 Batch accuracy: 0.9 Test accuracy: 0.8693\n",
            "49 Batch accuracy: 0.92 Test accuracy: 0.8565\n",
            "50 Batch accuracy: 0.8 Test accuracy: 0.8866\n",
            "51 Batch accuracy: 0.96 Test accuracy: 0.8775\n",
            "52 Batch accuracy: 0.9 Test accuracy: 0.8685\n",
            "53 Batch accuracy: 0.74 Test accuracy: 0.8609\n",
            "54 Batch accuracy: 0.86 Test accuracy: 0.8633\n",
            "55 Batch accuracy: 0.92 Test accuracy: 0.8693\n",
            "56 Batch accuracy: 0.82 Test accuracy: 0.871\n",
            "57 Batch accuracy: 0.9 Test accuracy: 0.881\n",
            "58 Batch accuracy: 0.84 Test accuracy: 0.8849\n",
            "59 Batch accuracy: 0.9 Test accuracy: 0.8547\n",
            "60 Batch accuracy: 0.88 Test accuracy: 0.8763\n",
            "61 Batch accuracy: 0.88 Test accuracy: 0.8825\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.8704\n",
            "63 Batch accuracy: 0.88 Test accuracy: 0.8854\n",
            "64 Batch accuracy: 0.84 Test accuracy: 0.8656\n",
            "65 Batch accuracy: 0.9 Test accuracy: 0.8631\n",
            "66 Batch accuracy: 0.92 Test accuracy: 0.8702\n",
            "67 Batch accuracy: 0.92 Test accuracy: 0.8812\n",
            "68 Batch accuracy: 0.9 Test accuracy: 0.8789\n",
            "69 Batch accuracy: 0.9 Test accuracy: 0.8849\n",
            "70 Batch accuracy: 0.88 Test accuracy: 0.8887\n",
            "71 Batch accuracy: 0.88 Test accuracy: 0.8795\n",
            "72 Batch accuracy: 0.9 Test accuracy: 0.8821\n",
            "73 Batch accuracy: 0.94 Test accuracy: 0.8834\n",
            "74 Batch accuracy: 0.9 Test accuracy: 0.8834\n",
            "75 Batch accuracy: 0.94 Test accuracy: 0.884\n",
            "76 Batch accuracy: 0.92 Test accuracy: 0.8814\n",
            "77 Batch accuracy: 0.9 Test accuracy: 0.8798\n",
            "78 Batch accuracy: 0.92 Test accuracy: 0.8825\n",
            "79 Batch accuracy: 0.92 Test accuracy: 0.886\n",
            "80 Batch accuracy: 0.9 Test accuracy: 0.8741\n",
            "81 Batch accuracy: 0.8 Test accuracy: 0.8845\n",
            "82 Batch accuracy: 0.94 Test accuracy: 0.8958\n",
            "83 Batch accuracy: 0.88 Test accuracy: 0.9004\n",
            "84 Batch accuracy: 0.9 Test accuracy: 0.8872\n",
            "85 Batch accuracy: 0.82 Test accuracy: 0.8762\n",
            "86 Batch accuracy: 0.9 Test accuracy: 0.885\n",
            "87 Batch accuracy: 0.84 Test accuracy: 0.8654\n",
            "88 Batch accuracy: 0.94 Test accuracy: 0.8849\n",
            "89 Batch accuracy: 0.86 Test accuracy: 0.8693\n",
            "90 Batch accuracy: 0.94 Test accuracy: 0.8902\n",
            "91 Batch accuracy: 0.9 Test accuracy: 0.9053\n",
            "92 Batch accuracy: 0.84 Test accuracy: 0.8824\n",
            "93 Batch accuracy: 0.88 Test accuracy: 0.8821\n",
            "94 Batch accuracy: 0.86 Test accuracy: 0.875\n",
            "95 Batch accuracy: 0.98 Test accuracy: 0.8869\n",
            "96 Batch accuracy: 0.92 Test accuracy: 0.8769\n",
            "97 Batch accuracy: 0.82 Test accuracy: 0.8863\n",
            "98 Batch accuracy: 0.88 Test accuracy: 0.8889\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.8792\n",
            "--- 3070.62 seconds ---\n",
            "0 Batch accuracy: 0.72 Test accuracy: 0.6556\n",
            "1 Batch accuracy: 0.6 Test accuracy: 0.5914\n",
            "2 Batch accuracy: 0.7 Test accuracy: 0.7075\n",
            "3 Batch accuracy: 0.5 Test accuracy: 0.5555\n",
            "4 Batch accuracy: 0.82 Test accuracy: 0.7896\n",
            "5 Batch accuracy: 0.76 Test accuracy: 0.7968\n",
            "6 Batch accuracy: 0.8 Test accuracy: 0.776\n",
            "7 Batch accuracy: 0.82 Test accuracy: 0.7581\n",
            "8 Batch accuracy: 0.9 Test accuracy: 0.8142\n",
            "9 Batch accuracy: 0.6 Test accuracy: 0.6915\n",
            "10 Batch accuracy: 0.78 Test accuracy: 0.8267\n",
            "11 Batch accuracy: 0.9 Test accuracy: 0.8334\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.8398\n",
            "13 Batch accuracy: 0.82 Test accuracy: 0.8183\n",
            "14 Batch accuracy: 0.8 Test accuracy: 0.843\n",
            "15 Batch accuracy: 0.92 Test accuracy: 0.846\n",
            "16 Batch accuracy: 0.78 Test accuracy: 0.826\n",
            "17 Batch accuracy: 0.82 Test accuracy: 0.8299\n",
            "18 Batch accuracy: 0.84 Test accuracy: 0.8476\n",
            "19 Batch accuracy: 0.86 Test accuracy: 0.8514\n",
            "20 Batch accuracy: 0.84 Test accuracy: 0.8119\n",
            "21 Batch accuracy: 0.88 Test accuracy: 0.829\n",
            "22 Batch accuracy: 0.78 Test accuracy: 0.8402\n",
            "23 Batch accuracy: 0.86 Test accuracy: 0.8478\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.8553\n",
            "25 Batch accuracy: 0.76 Test accuracy: 0.8315\n",
            "26 Batch accuracy: 0.88 Test accuracy: 0.8339\n",
            "27 Batch accuracy: 0.88 Test accuracy: 0.8776\n",
            "28 Batch accuracy: 0.84 Test accuracy: 0.8667\n",
            "29 Batch accuracy: 0.86 Test accuracy: 0.8583\n",
            "30 Batch accuracy: 0.86 Test accuracy: 0.874\n",
            "31 Batch accuracy: 0.92 Test accuracy: 0.8726\n",
            "32 Batch accuracy: 0.88 Test accuracy: 0.8804\n",
            "33 Batch accuracy: 0.88 Test accuracy: 0.8656\n",
            "34 Batch accuracy: 0.86 Test accuracy: 0.8395\n",
            "35 Batch accuracy: 0.88 Test accuracy: 0.865\n",
            "36 Batch accuracy: 0.88 Test accuracy: 0.8673\n",
            "37 Batch accuracy: 0.82 Test accuracy: 0.8524\n",
            "38 Batch accuracy: 0.8 Test accuracy: 0.8347\n",
            "39 Batch accuracy: 0.82 Test accuracy: 0.877\n",
            "40 Batch accuracy: 0.92 Test accuracy: 0.8657\n",
            "41 Batch accuracy: 0.82 Test accuracy: 0.881\n",
            "42 Batch accuracy: 0.84 Test accuracy: 0.8589\n",
            "43 Batch accuracy: 0.88 Test accuracy: 0.8753\n",
            "44 Batch accuracy: 0.84 Test accuracy: 0.8859\n",
            "45 Batch accuracy: 0.9 Test accuracy: 0.8712\n",
            "46 Batch accuracy: 0.86 Test accuracy: 0.869\n",
            "47 Batch accuracy: 0.82 Test accuracy: 0.8643\n",
            "48 Batch accuracy: 0.9 Test accuracy: 0.8693\n",
            "49 Batch accuracy: 0.92 Test accuracy: 0.8565\n",
            "50 Batch accuracy: 0.8 Test accuracy: 0.8866\n",
            "51 Batch accuracy: 0.96 Test accuracy: 0.8775\n",
            "52 Batch accuracy: 0.9 Test accuracy: 0.8685\n",
            "53 Batch accuracy: 0.74 Test accuracy: 0.8609\n",
            "54 Batch accuracy: 0.86 Test accuracy: 0.8633\n",
            "55 Batch accuracy: 0.92 Test accuracy: 0.8693\n",
            "56 Batch accuracy: 0.82 Test accuracy: 0.871\n",
            "57 Batch accuracy: 0.9 Test accuracy: 0.881\n",
            "58 Batch accuracy: 0.84 Test accuracy: 0.8849\n",
            "59 Batch accuracy: 0.9 Test accuracy: 0.8547\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60 Batch accuracy: 0.88 Test accuracy: 0.8763\n",
            "61 Batch accuracy: 0.88 Test accuracy: 0.8825\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.8704\n",
            "63 Batch accuracy: 0.88 Test accuracy: 0.8854\n",
            "64 Batch accuracy: 0.84 Test accuracy: 0.8656\n",
            "65 Batch accuracy: 0.9 Test accuracy: 0.8631\n",
            "66 Batch accuracy: 0.92 Test accuracy: 0.8702\n",
            "67 Batch accuracy: 0.92 Test accuracy: 0.8812\n",
            "68 Batch accuracy: 0.9 Test accuracy: 0.8789\n",
            "69 Batch accuracy: 0.9 Test accuracy: 0.8849\n",
            "70 Batch accuracy: 0.88 Test accuracy: 0.8887\n",
            "71 Batch accuracy: 0.88 Test accuracy: 0.8795\n",
            "72 Batch accuracy: 0.9 Test accuracy: 0.8821\n",
            "73 Batch accuracy: 0.94 Test accuracy: 0.8834\n",
            "74 Batch accuracy: 0.9 Test accuracy: 0.8834\n",
            "75 Batch accuracy: 0.94 Test accuracy: 0.884\n",
            "76 Batch accuracy: 0.92 Test accuracy: 0.8814\n",
            "77 Batch accuracy: 0.9 Test accuracy: 0.8798\n",
            "78 Batch accuracy: 0.92 Test accuracy: 0.8825\n",
            "79 Batch accuracy: 0.92 Test accuracy: 0.886\n",
            "80 Batch accuracy: 0.9 Test accuracy: 0.8741\n",
            "81 Batch accuracy: 0.8 Test accuracy: 0.8845\n",
            "82 Batch accuracy: 0.94 Test accuracy: 0.8958\n",
            "83 Batch accuracy: 0.88 Test accuracy: 0.9004\n",
            "84 Batch accuracy: 0.9 Test accuracy: 0.8872\n",
            "85 Batch accuracy: 0.82 Test accuracy: 0.8762\n",
            "86 Batch accuracy: 0.9 Test accuracy: 0.885\n",
            "87 Batch accuracy: 0.84 Test accuracy: 0.8654\n",
            "88 Batch accuracy: 0.94 Test accuracy: 0.8849\n",
            "89 Batch accuracy: 0.86 Test accuracy: 0.8693\n",
            "90 Batch accuracy: 0.94 Test accuracy: 0.8902\n",
            "91 Batch accuracy: 0.9 Test accuracy: 0.9053\n",
            "92 Batch accuracy: 0.84 Test accuracy: 0.8824\n",
            "93 Batch accuracy: 0.88 Test accuracy: 0.8821\n",
            "94 Batch accuracy: 0.86 Test accuracy: 0.875\n",
            "95 Batch accuracy: 0.98 Test accuracy: 0.8869\n",
            "96 Batch accuracy: 0.92 Test accuracy: 0.8769\n",
            "97 Batch accuracy: 0.82 Test accuracy: 0.8863\n",
            "98 Batch accuracy: 0.88 Test accuracy: 0.8889\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.8792\n",
            "--- 3052.23 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U20Mg0qp-pMz",
        "outputId": "d6293b16-3922-4486-c341-8b7d8d5441bd"
      },
      "source": [
        "# run hardware sim 4 times\n",
        "for i in range(4):\n",
        "    imported_device_states = import_data_from_csv(filename='learning_curve_vinod.csv')\n",
        "    run_MLP_simulation(num_epochs_input = 100, \n",
        "                       hardware_simulation_input = True, \n",
        "                       device_states_input = imported_device_states,\n",
        "                       read_noise_mean_input = 0.0,\n",
        "                       read_noise_stddev_input = 0.1,\n",
        "                       device_variation_stddev_input = 0.0,\n",
        "                       device_stuck_on_prob_input = 0.00,\n",
        "                       device_stuck_off_prob_input = 0.00,\n",
        "                       save_results_input = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Batch accuracy: 0.84 Test accuracy: 0.761\n",
            "1 Batch accuracy: 0.86 Test accuracy: 0.8079\n",
            "2 Batch accuracy: 0.88 Test accuracy: 0.8493\n",
            "3 Batch accuracy: 0.84 Test accuracy: 0.823\n",
            "4 Batch accuracy: 0.92 Test accuracy: 0.9038\n",
            "5 Batch accuracy: 0.86 Test accuracy: 0.9098\n",
            "6 Batch accuracy: 0.96 Test accuracy: 0.9185\n",
            "7 Batch accuracy: 0.92 Test accuracy: 0.8956\n",
            "8 Batch accuracy: 0.94 Test accuracy: 0.9088\n",
            "9 Batch accuracy: 0.86 Test accuracy: 0.8886\n",
            "10 Batch accuracy: 0.92 Test accuracy: 0.9233\n",
            "11 Batch accuracy: 0.94 Test accuracy: 0.919\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.917\n",
            "13 Batch accuracy: 0.96 Test accuracy: 0.9239\n",
            "14 Batch accuracy: 0.9 Test accuracy: 0.9272\n",
            "15 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "16 Batch accuracy: 0.94 Test accuracy: 0.9288\n",
            "17 Batch accuracy: 0.96 Test accuracy: 0.9197\n",
            "18 Batch accuracy: 0.9 Test accuracy: 0.9308\n",
            "19 Batch accuracy: 0.88 Test accuracy: 0.9271\n",
            "20 Batch accuracy: 0.96 Test accuracy: 0.9229\n",
            "21 Batch accuracy: 0.92 Test accuracy: 0.9356\n",
            "22 Batch accuracy: 0.94 Test accuracy: 0.9279\n",
            "23 Batch accuracy: 0.96 Test accuracy: 0.9297\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.9353\n",
            "25 Batch accuracy: 0.96 Test accuracy: 0.9387\n",
            "26 Batch accuracy: 1.0 Test accuracy: 0.9218\n",
            "27 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "28 Batch accuracy: 0.94 Test accuracy: 0.9349\n",
            "29 Batch accuracy: 0.96 Test accuracy: 0.9364\n",
            "30 Batch accuracy: 0.98 Test accuracy: 0.9324\n",
            "31 Batch accuracy: 0.94 Test accuracy: 0.935\n",
            "32 Batch accuracy: 1.0 Test accuracy: 0.9399\n",
            "33 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "34 Batch accuracy: 0.98 Test accuracy: 0.935\n",
            "35 Batch accuracy: 0.94 Test accuracy: 0.9466\n",
            "36 Batch accuracy: 0.9 Test accuracy: 0.944\n",
            "37 Batch accuracy: 0.94 Test accuracy: 0.9444\n",
            "38 Batch accuracy: 0.96 Test accuracy: 0.9407\n",
            "39 Batch accuracy: 0.94 Test accuracy: 0.9463\n",
            "40 Batch accuracy: 0.98 Test accuracy: 0.9426\n",
            "41 Batch accuracy: 0.94 Test accuracy: 0.9435\n",
            "42 Batch accuracy: 1.0 Test accuracy: 0.9382\n",
            "43 Batch accuracy: 0.96 Test accuracy: 0.9384\n",
            "44 Batch accuracy: 0.98 Test accuracy: 0.9435\n",
            "45 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "46 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "47 Batch accuracy: 0.94 Test accuracy: 0.9443\n",
            "48 Batch accuracy: 1.0 Test accuracy: 0.9482\n",
            "49 Batch accuracy: 0.96 Test accuracy: 0.9454\n",
            "50 Batch accuracy: 0.98 Test accuracy: 0.9465\n",
            "51 Batch accuracy: 0.98 Test accuracy: 0.946\n",
            "52 Batch accuracy: 0.94 Test accuracy: 0.9357\n",
            "53 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "54 Batch accuracy: 0.98 Test accuracy: 0.9372\n",
            "55 Batch accuracy: 0.96 Test accuracy: 0.9424\n",
            "56 Batch accuracy: 1.0 Test accuracy: 0.9368\n",
            "57 Batch accuracy: 0.94 Test accuracy: 0.9358\n",
            "58 Batch accuracy: 1.0 Test accuracy: 0.9432\n",
            "59 Batch accuracy: 0.96 Test accuracy: 0.9416\n",
            "60 Batch accuracy: 0.9 Test accuracy: 0.9444\n",
            "61 Batch accuracy: 0.98 Test accuracy: 0.9438\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.9366\n",
            "63 Batch accuracy: 0.96 Test accuracy: 0.9392\n",
            "64 Batch accuracy: 0.98 Test accuracy: 0.9374\n",
            "65 Batch accuracy: 0.98 Test accuracy: 0.947\n",
            "66 Batch accuracy: 0.98 Test accuracy: 0.9456\n",
            "67 Batch accuracy: 0.98 Test accuracy: 0.9416\n",
            "68 Batch accuracy: 0.94 Test accuracy: 0.9412\n",
            "69 Batch accuracy: 0.92 Test accuracy: 0.9447\n",
            "70 Batch accuracy: 0.94 Test accuracy: 0.9425\n",
            "71 Batch accuracy: 0.96 Test accuracy: 0.9431\n",
            "72 Batch accuracy: 0.96 Test accuracy: 0.9421\n",
            "73 Batch accuracy: 0.96 Test accuracy: 0.9363\n",
            "74 Batch accuracy: 0.96 Test accuracy: 0.9467\n",
            "75 Batch accuracy: 0.98 Test accuracy: 0.9457\n",
            "76 Batch accuracy: 0.94 Test accuracy: 0.9445\n",
            "77 Batch accuracy: 0.98 Test accuracy: 0.9473\n",
            "78 Batch accuracy: 0.96 Test accuracy: 0.9428\n",
            "79 Batch accuracy: 0.98 Test accuracy: 0.9432\n",
            "80 Batch accuracy: 0.96 Test accuracy: 0.9453\n",
            "81 Batch accuracy: 0.98 Test accuracy: 0.9485\n",
            "82 Batch accuracy: 0.96 Test accuracy: 0.9482\n",
            "83 Batch accuracy: 0.96 Test accuracy: 0.9417\n",
            "84 Batch accuracy: 0.96 Test accuracy: 0.9472\n",
            "85 Batch accuracy: 0.94 Test accuracy: 0.9449\n",
            "86 Batch accuracy: 0.98 Test accuracy: 0.9481\n",
            "87 Batch accuracy: 0.98 Test accuracy: 0.9496\n",
            "88 Batch accuracy: 0.96 Test accuracy: 0.9505\n",
            "89 Batch accuracy: 0.94 Test accuracy: 0.9453\n",
            "90 Batch accuracy: 0.98 Test accuracy: 0.9494\n",
            "91 Batch accuracy: 1.0 Test accuracy: 0.952\n",
            "92 Batch accuracy: 0.96 Test accuracy: 0.9466\n",
            "93 Batch accuracy: 0.94 Test accuracy: 0.9496\n",
            "94 Batch accuracy: 0.94 Test accuracy: 0.944\n",
            "95 Batch accuracy: 1.0 Test accuracy: 0.9475\n",
            "96 Batch accuracy: 0.96 Test accuracy: 0.9516\n",
            "97 Batch accuracy: 0.96 Test accuracy: 0.9425\n",
            "98 Batch accuracy: 0.96 Test accuracy: 0.9457\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.9451\n",
            "--- 3061.78 seconds ---\n",
            "0 Batch accuracy: 0.84 Test accuracy: 0.761\n",
            "1 Batch accuracy: 0.86 Test accuracy: 0.8079\n",
            "2 Batch accuracy: 0.88 Test accuracy: 0.8493\n",
            "3 Batch accuracy: 0.84 Test accuracy: 0.823\n",
            "4 Batch accuracy: 0.92 Test accuracy: 0.9038\n",
            "5 Batch accuracy: 0.86 Test accuracy: 0.9098\n",
            "6 Batch accuracy: 0.96 Test accuracy: 0.9185\n",
            "7 Batch accuracy: 0.92 Test accuracy: 0.8956\n",
            "8 Batch accuracy: 0.94 Test accuracy: 0.9088\n",
            "9 Batch accuracy: 0.86 Test accuracy: 0.8886\n",
            "10 Batch accuracy: 0.92 Test accuracy: 0.9233\n",
            "11 Batch accuracy: 0.94 Test accuracy: 0.919\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.917\n",
            "13 Batch accuracy: 0.96 Test accuracy: 0.9239\n",
            "14 Batch accuracy: 0.9 Test accuracy: 0.9272\n",
            "15 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "16 Batch accuracy: 0.94 Test accuracy: 0.9288\n",
            "17 Batch accuracy: 0.96 Test accuracy: 0.9197\n",
            "18 Batch accuracy: 0.9 Test accuracy: 0.9308\n",
            "19 Batch accuracy: 0.88 Test accuracy: 0.9271\n",
            "20 Batch accuracy: 0.96 Test accuracy: 0.9229\n",
            "21 Batch accuracy: 0.92 Test accuracy: 0.9356\n",
            "22 Batch accuracy: 0.94 Test accuracy: 0.9279\n",
            "23 Batch accuracy: 0.96 Test accuracy: 0.9297\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.9353\n",
            "25 Batch accuracy: 0.96 Test accuracy: 0.9387\n",
            "26 Batch accuracy: 1.0 Test accuracy: 0.9218\n",
            "27 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "28 Batch accuracy: 0.94 Test accuracy: 0.9349\n",
            "29 Batch accuracy: 0.96 Test accuracy: 0.9364\n",
            "30 Batch accuracy: 0.98 Test accuracy: 0.9324\n",
            "31 Batch accuracy: 0.94 Test accuracy: 0.935\n",
            "32 Batch accuracy: 1.0 Test accuracy: 0.9399\n",
            "33 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "34 Batch accuracy: 0.98 Test accuracy: 0.935\n",
            "35 Batch accuracy: 0.94 Test accuracy: 0.9466\n",
            "36 Batch accuracy: 0.9 Test accuracy: 0.944\n",
            "37 Batch accuracy: 0.94 Test accuracy: 0.9444\n",
            "38 Batch accuracy: 0.96 Test accuracy: 0.9407\n",
            "39 Batch accuracy: 0.94 Test accuracy: 0.9463\n",
            "40 Batch accuracy: 0.98 Test accuracy: 0.9426\n",
            "41 Batch accuracy: 0.94 Test accuracy: 0.9435\n",
            "42 Batch accuracy: 1.0 Test accuracy: 0.9382\n",
            "43 Batch accuracy: 0.96 Test accuracy: 0.9384\n",
            "44 Batch accuracy: 0.98 Test accuracy: 0.9435\n",
            "45 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "46 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "47 Batch accuracy: 0.94 Test accuracy: 0.9443\n",
            "48 Batch accuracy: 1.0 Test accuracy: 0.9482\n",
            "49 Batch accuracy: 0.96 Test accuracy: 0.9454\n",
            "50 Batch accuracy: 0.98 Test accuracy: 0.9465\n",
            "51 Batch accuracy: 0.98 Test accuracy: 0.946\n",
            "52 Batch accuracy: 0.94 Test accuracy: 0.9357\n",
            "53 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "54 Batch accuracy: 0.98 Test accuracy: 0.9372\n",
            "55 Batch accuracy: 0.96 Test accuracy: 0.9424\n",
            "56 Batch accuracy: 1.0 Test accuracy: 0.9368\n",
            "57 Batch accuracy: 0.94 Test accuracy: 0.9358\n",
            "58 Batch accuracy: 1.0 Test accuracy: 0.9432\n",
            "59 Batch accuracy: 0.96 Test accuracy: 0.9416\n",
            "60 Batch accuracy: 0.9 Test accuracy: 0.9444\n",
            "61 Batch accuracy: 0.98 Test accuracy: 0.9438\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.9366\n",
            "63 Batch accuracy: 0.96 Test accuracy: 0.9392\n",
            "64 Batch accuracy: 0.98 Test accuracy: 0.9374\n",
            "65 Batch accuracy: 0.98 Test accuracy: 0.947\n",
            "66 Batch accuracy: 0.98 Test accuracy: 0.9456\n",
            "67 Batch accuracy: 0.98 Test accuracy: 0.9416\n",
            "68 Batch accuracy: 0.94 Test accuracy: 0.9412\n",
            "69 Batch accuracy: 0.92 Test accuracy: 0.9447\n",
            "70 Batch accuracy: 0.94 Test accuracy: 0.9425\n",
            "71 Batch accuracy: 0.96 Test accuracy: 0.9431\n",
            "72 Batch accuracy: 0.96 Test accuracy: 0.9421\n",
            "73 Batch accuracy: 0.96 Test accuracy: 0.9363\n",
            "74 Batch accuracy: 0.96 Test accuracy: 0.9467\n",
            "75 Batch accuracy: 0.98 Test accuracy: 0.9457\n",
            "76 Batch accuracy: 0.94 Test accuracy: 0.9445\n",
            "77 Batch accuracy: 0.98 Test accuracy: 0.9473\n",
            "78 Batch accuracy: 0.96 Test accuracy: 0.9428\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79 Batch accuracy: 0.98 Test accuracy: 0.9432\n",
            "80 Batch accuracy: 0.96 Test accuracy: 0.9453\n",
            "81 Batch accuracy: 0.98 Test accuracy: 0.9485\n",
            "82 Batch accuracy: 0.96 Test accuracy: 0.9482\n",
            "83 Batch accuracy: 0.96 Test accuracy: 0.9417\n",
            "84 Batch accuracy: 0.96 Test accuracy: 0.9472\n",
            "85 Batch accuracy: 0.94 Test accuracy: 0.9449\n",
            "86 Batch accuracy: 0.98 Test accuracy: 0.9481\n",
            "87 Batch accuracy: 0.98 Test accuracy: 0.9496\n",
            "88 Batch accuracy: 0.96 Test accuracy: 0.9505\n",
            "89 Batch accuracy: 0.94 Test accuracy: 0.9453\n",
            "90 Batch accuracy: 0.98 Test accuracy: 0.9494\n",
            "91 Batch accuracy: 1.0 Test accuracy: 0.952\n",
            "92 Batch accuracy: 0.96 Test accuracy: 0.9466\n",
            "93 Batch accuracy: 0.94 Test accuracy: 0.9496\n",
            "94 Batch accuracy: 0.94 Test accuracy: 0.944\n",
            "95 Batch accuracy: 1.0 Test accuracy: 0.9475\n",
            "96 Batch accuracy: 0.96 Test accuracy: 0.9516\n",
            "97 Batch accuracy: 0.96 Test accuracy: 0.9425\n",
            "98 Batch accuracy: 0.96 Test accuracy: 0.9457\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.9451\n",
            "--- 3079.70 seconds ---\n",
            "0 Batch accuracy: 0.84 Test accuracy: 0.761\n",
            "1 Batch accuracy: 0.86 Test accuracy: 0.8079\n",
            "2 Batch accuracy: 0.88 Test accuracy: 0.8493\n",
            "3 Batch accuracy: 0.84 Test accuracy: 0.823\n",
            "4 Batch accuracy: 0.92 Test accuracy: 0.9038\n",
            "5 Batch accuracy: 0.86 Test accuracy: 0.9098\n",
            "6 Batch accuracy: 0.96 Test accuracy: 0.9185\n",
            "7 Batch accuracy: 0.92 Test accuracy: 0.8956\n",
            "8 Batch accuracy: 0.94 Test accuracy: 0.9088\n",
            "9 Batch accuracy: 0.86 Test accuracy: 0.8886\n",
            "10 Batch accuracy: 0.92 Test accuracy: 0.9233\n",
            "11 Batch accuracy: 0.94 Test accuracy: 0.919\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.917\n",
            "13 Batch accuracy: 0.96 Test accuracy: 0.9239\n",
            "14 Batch accuracy: 0.9 Test accuracy: 0.9272\n",
            "15 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "16 Batch accuracy: 0.94 Test accuracy: 0.9288\n",
            "17 Batch accuracy: 0.96 Test accuracy: 0.9197\n",
            "18 Batch accuracy: 0.9 Test accuracy: 0.9308\n",
            "19 Batch accuracy: 0.88 Test accuracy: 0.9271\n",
            "20 Batch accuracy: 0.96 Test accuracy: 0.9229\n",
            "21 Batch accuracy: 0.92 Test accuracy: 0.9356\n",
            "22 Batch accuracy: 0.94 Test accuracy: 0.9279\n",
            "23 Batch accuracy: 0.96 Test accuracy: 0.9297\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.9353\n",
            "25 Batch accuracy: 0.96 Test accuracy: 0.9387\n",
            "26 Batch accuracy: 1.0 Test accuracy: 0.9218\n",
            "27 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "28 Batch accuracy: 0.94 Test accuracy: 0.9349\n",
            "29 Batch accuracy: 0.96 Test accuracy: 0.9364\n",
            "30 Batch accuracy: 0.98 Test accuracy: 0.9324\n",
            "31 Batch accuracy: 0.94 Test accuracy: 0.935\n",
            "32 Batch accuracy: 1.0 Test accuracy: 0.9399\n",
            "33 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "34 Batch accuracy: 0.98 Test accuracy: 0.935\n",
            "35 Batch accuracy: 0.94 Test accuracy: 0.9466\n",
            "36 Batch accuracy: 0.9 Test accuracy: 0.944\n",
            "37 Batch accuracy: 0.94 Test accuracy: 0.9444\n",
            "38 Batch accuracy: 0.96 Test accuracy: 0.9407\n",
            "39 Batch accuracy: 0.94 Test accuracy: 0.9463\n",
            "40 Batch accuracy: 0.98 Test accuracy: 0.9426\n",
            "41 Batch accuracy: 0.94 Test accuracy: 0.9435\n",
            "42 Batch accuracy: 1.0 Test accuracy: 0.9382\n",
            "43 Batch accuracy: 0.96 Test accuracy: 0.9384\n",
            "44 Batch accuracy: 0.98 Test accuracy: 0.9435\n",
            "45 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "46 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "47 Batch accuracy: 0.94 Test accuracy: 0.9443\n",
            "48 Batch accuracy: 1.0 Test accuracy: 0.9482\n",
            "49 Batch accuracy: 0.96 Test accuracy: 0.9454\n",
            "50 Batch accuracy: 0.98 Test accuracy: 0.9465\n",
            "51 Batch accuracy: 0.98 Test accuracy: 0.946\n",
            "52 Batch accuracy: 0.94 Test accuracy: 0.9357\n",
            "53 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "54 Batch accuracy: 0.98 Test accuracy: 0.9372\n",
            "55 Batch accuracy: 0.96 Test accuracy: 0.9424\n",
            "56 Batch accuracy: 1.0 Test accuracy: 0.9368\n",
            "57 Batch accuracy: 0.94 Test accuracy: 0.9358\n",
            "58 Batch accuracy: 1.0 Test accuracy: 0.9432\n",
            "59 Batch accuracy: 0.96 Test accuracy: 0.9416\n",
            "60 Batch accuracy: 0.9 Test accuracy: 0.9444\n",
            "61 Batch accuracy: 0.98 Test accuracy: 0.9438\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.9366\n",
            "63 Batch accuracy: 0.96 Test accuracy: 0.9392\n",
            "64 Batch accuracy: 0.98 Test accuracy: 0.9374\n",
            "65 Batch accuracy: 0.98 Test accuracy: 0.947\n",
            "66 Batch accuracy: 0.98 Test accuracy: 0.9456\n",
            "67 Batch accuracy: 0.98 Test accuracy: 0.9416\n",
            "68 Batch accuracy: 0.94 Test accuracy: 0.9412\n",
            "69 Batch accuracy: 0.92 Test accuracy: 0.9447\n",
            "70 Batch accuracy: 0.94 Test accuracy: 0.9425\n",
            "71 Batch accuracy: 0.96 Test accuracy: 0.9431\n",
            "72 Batch accuracy: 0.96 Test accuracy: 0.9421\n",
            "73 Batch accuracy: 0.96 Test accuracy: 0.9363\n",
            "74 Batch accuracy: 0.96 Test accuracy: 0.9467\n",
            "75 Batch accuracy: 0.98 Test accuracy: 0.9457\n",
            "76 Batch accuracy: 0.94 Test accuracy: 0.9445\n",
            "77 Batch accuracy: 0.98 Test accuracy: 0.9473\n",
            "78 Batch accuracy: 0.96 Test accuracy: 0.9428\n",
            "79 Batch accuracy: 0.98 Test accuracy: 0.9432\n",
            "80 Batch accuracy: 0.96 Test accuracy: 0.9453\n",
            "81 Batch accuracy: 0.98 Test accuracy: 0.9485\n",
            "82 Batch accuracy: 0.96 Test accuracy: 0.9482\n",
            "83 Batch accuracy: 0.96 Test accuracy: 0.9417\n",
            "84 Batch accuracy: 0.96 Test accuracy: 0.9472\n",
            "85 Batch accuracy: 0.94 Test accuracy: 0.9449\n",
            "86 Batch accuracy: 0.98 Test accuracy: 0.9481\n",
            "87 Batch accuracy: 0.98 Test accuracy: 0.9496\n",
            "88 Batch accuracy: 0.96 Test accuracy: 0.9505\n",
            "89 Batch accuracy: 0.94 Test accuracy: 0.9453\n",
            "90 Batch accuracy: 0.98 Test accuracy: 0.9494\n",
            "91 Batch accuracy: 1.0 Test accuracy: 0.952\n",
            "92 Batch accuracy: 0.96 Test accuracy: 0.9466\n",
            "93 Batch accuracy: 0.94 Test accuracy: 0.9496\n",
            "94 Batch accuracy: 0.94 Test accuracy: 0.944\n",
            "95 Batch accuracy: 1.0 Test accuracy: 0.9475\n",
            "96 Batch accuracy: 0.96 Test accuracy: 0.9516\n",
            "97 Batch accuracy: 0.96 Test accuracy: 0.9425\n",
            "98 Batch accuracy: 0.96 Test accuracy: 0.9457\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.9451\n",
            "--- 3077.87 seconds ---\n",
            "0 Batch accuracy: 0.84 Test accuracy: 0.761\n",
            "1 Batch accuracy: 0.86 Test accuracy: 0.8079\n",
            "2 Batch accuracy: 0.88 Test accuracy: 0.8493\n",
            "3 Batch accuracy: 0.84 Test accuracy: 0.823\n",
            "4 Batch accuracy: 0.92 Test accuracy: 0.9038\n",
            "5 Batch accuracy: 0.86 Test accuracy: 0.9098\n",
            "6 Batch accuracy: 0.96 Test accuracy: 0.9185\n",
            "7 Batch accuracy: 0.92 Test accuracy: 0.8956\n",
            "8 Batch accuracy: 0.94 Test accuracy: 0.9088\n",
            "9 Batch accuracy: 0.86 Test accuracy: 0.8886\n",
            "10 Batch accuracy: 0.92 Test accuracy: 0.9233\n",
            "11 Batch accuracy: 0.94 Test accuracy: 0.919\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.917\n",
            "13 Batch accuracy: 0.96 Test accuracy: 0.9239\n",
            "14 Batch accuracy: 0.9 Test accuracy: 0.9272\n",
            "15 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "16 Batch accuracy: 0.94 Test accuracy: 0.9288\n",
            "17 Batch accuracy: 0.96 Test accuracy: 0.9197\n",
            "18 Batch accuracy: 0.9 Test accuracy: 0.9308\n",
            "19 Batch accuracy: 0.88 Test accuracy: 0.9271\n",
            "20 Batch accuracy: 0.96 Test accuracy: 0.9229\n",
            "21 Batch accuracy: 0.92 Test accuracy: 0.9356\n",
            "22 Batch accuracy: 0.94 Test accuracy: 0.9279\n",
            "23 Batch accuracy: 0.96 Test accuracy: 0.9297\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.9353\n",
            "25 Batch accuracy: 0.96 Test accuracy: 0.9387\n",
            "26 Batch accuracy: 1.0 Test accuracy: 0.9218\n",
            "27 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "28 Batch accuracy: 0.94 Test accuracy: 0.9349\n",
            "29 Batch accuracy: 0.96 Test accuracy: 0.9364\n",
            "30 Batch accuracy: 0.98 Test accuracy: 0.9324\n",
            "31 Batch accuracy: 0.94 Test accuracy: 0.935\n",
            "32 Batch accuracy: 1.0 Test accuracy: 0.9399\n",
            "33 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "34 Batch accuracy: 0.98 Test accuracy: 0.935\n",
            "35 Batch accuracy: 0.94 Test accuracy: 0.9466\n",
            "36 Batch accuracy: 0.9 Test accuracy: 0.944\n",
            "37 Batch accuracy: 0.94 Test accuracy: 0.9444\n",
            "38 Batch accuracy: 0.96 Test accuracy: 0.9407\n",
            "39 Batch accuracy: 0.94 Test accuracy: 0.9463\n",
            "40 Batch accuracy: 0.98 Test accuracy: 0.9426\n",
            "41 Batch accuracy: 0.94 Test accuracy: 0.9435\n",
            "42 Batch accuracy: 1.0 Test accuracy: 0.9382\n",
            "43 Batch accuracy: 0.96 Test accuracy: 0.9384\n",
            "44 Batch accuracy: 0.98 Test accuracy: 0.9435\n",
            "45 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "46 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "47 Batch accuracy: 0.94 Test accuracy: 0.9443\n",
            "48 Batch accuracy: 1.0 Test accuracy: 0.9482\n",
            "49 Batch accuracy: 0.96 Test accuracy: 0.9454\n",
            "50 Batch accuracy: 0.98 Test accuracy: 0.9465\n",
            "51 Batch accuracy: 0.98 Test accuracy: 0.946\n",
            "52 Batch accuracy: 0.94 Test accuracy: 0.9357\n",
            "53 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "54 Batch accuracy: 0.98 Test accuracy: 0.9372\n",
            "55 Batch accuracy: 0.96 Test accuracy: 0.9424\n",
            "56 Batch accuracy: 1.0 Test accuracy: 0.9368\n",
            "57 Batch accuracy: 0.94 Test accuracy: 0.9358\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "58 Batch accuracy: 1.0 Test accuracy: 0.9432\n",
            "59 Batch accuracy: 0.96 Test accuracy: 0.9416\n",
            "60 Batch accuracy: 0.9 Test accuracy: 0.9444\n",
            "61 Batch accuracy: 0.98 Test accuracy: 0.9438\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.9366\n",
            "63 Batch accuracy: 0.96 Test accuracy: 0.9392\n",
            "64 Batch accuracy: 0.98 Test accuracy: 0.9374\n",
            "65 Batch accuracy: 0.98 Test accuracy: 0.947\n",
            "66 Batch accuracy: 0.98 Test accuracy: 0.9456\n",
            "67 Batch accuracy: 0.98 Test accuracy: 0.9416\n",
            "68 Batch accuracy: 0.94 Test accuracy: 0.9412\n",
            "69 Batch accuracy: 0.92 Test accuracy: 0.9447\n",
            "70 Batch accuracy: 0.94 Test accuracy: 0.9425\n",
            "71 Batch accuracy: 0.96 Test accuracy: 0.9431\n",
            "72 Batch accuracy: 0.96 Test accuracy: 0.9421\n",
            "73 Batch accuracy: 0.96 Test accuracy: 0.9363\n",
            "74 Batch accuracy: 0.96 Test accuracy: 0.9467\n",
            "75 Batch accuracy: 0.98 Test accuracy: 0.9457\n",
            "76 Batch accuracy: 0.94 Test accuracy: 0.9445\n",
            "77 Batch accuracy: 0.98 Test accuracy: 0.9473\n",
            "78 Batch accuracy: 0.96 Test accuracy: 0.9428\n",
            "79 Batch accuracy: 0.98 Test accuracy: 0.9432\n",
            "80 Batch accuracy: 0.96 Test accuracy: 0.9453\n",
            "81 Batch accuracy: 0.98 Test accuracy: 0.9485\n",
            "82 Batch accuracy: 0.96 Test accuracy: 0.9482\n",
            "83 Batch accuracy: 0.96 Test accuracy: 0.9417\n",
            "84 Batch accuracy: 0.96 Test accuracy: 0.9472\n",
            "85 Batch accuracy: 0.94 Test accuracy: 0.9449\n",
            "86 Batch accuracy: 0.98 Test accuracy: 0.9481\n",
            "87 Batch accuracy: 0.98 Test accuracy: 0.9496\n",
            "88 Batch accuracy: 0.96 Test accuracy: 0.9505\n",
            "89 Batch accuracy: 0.94 Test accuracy: 0.9453\n",
            "90 Batch accuracy: 0.98 Test accuracy: 0.9494\n",
            "91 Batch accuracy: 1.0 Test accuracy: 0.952\n",
            "92 Batch accuracy: 0.96 Test accuracy: 0.9466\n",
            "93 Batch accuracy: 0.94 Test accuracy: 0.9496\n",
            "94 Batch accuracy: 0.94 Test accuracy: 0.944\n",
            "95 Batch accuracy: 1.0 Test accuracy: 0.9475\n",
            "96 Batch accuracy: 0.96 Test accuracy: 0.9516\n",
            "97 Batch accuracy: 0.96 Test accuracy: 0.9425\n",
            "98 Batch accuracy: 0.96 Test accuracy: 0.9457\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.9451\n",
            "--- 3069.41 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "L0Ax4Dbc-pM0",
        "outputId": "cf5f17f7-4f2c-4841-b23a-222d09124c13"
      },
      "source": [
        "imported_device_states = import_data_from_csv(filename='learning_curve_vinod.csv')\n",
        "\n",
        "\n",
        "run_MLP_simulation(num_epochs_input = 100, \n",
        "                   hardware_simulation_input = True, \n",
        "                   device_states_input = imported_device_states,\n",
        "                   read_noise_mean_input = 0.0,\n",
        "                   read_noise_stddev_input = 0.1,\n",
        "                   device_variation_stddev_input = 0.0,\n",
        "                   device_stuck_on_prob_input = 0.00,\n",
        "                   device_stuck_off_prob_input = 0.00,\n",
        "                   save_results_input = True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Batch accuracy: 0.72 Test accuracy: 0.6556\n",
            "1 Batch accuracy: 0.6 Test accuracy: 0.5914\n",
            "2 Batch accuracy: 0.7 Test accuracy: 0.7075\n",
            "3 Batch accuracy: 0.5 Test accuracy: 0.5555\n",
            "4 Batch accuracy: 0.82 Test accuracy: 0.7896\n",
            "5 Batch accuracy: 0.76 Test accuracy: 0.7968\n",
            "6 Batch accuracy: 0.8 Test accuracy: 0.776\n",
            "7 Batch accuracy: 0.82 Test accuracy: 0.7581\n",
            "8 Batch accuracy: 0.9 Test accuracy: 0.8142\n",
            "9 Batch accuracy: 0.6 Test accuracy: 0.6915\n",
            "10 Batch accuracy: 0.78 Test accuracy: 0.8267\n",
            "11 Batch accuracy: 0.9 Test accuracy: 0.8334\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.8398\n",
            "13 Batch accuracy: 0.82 Test accuracy: 0.8183\n",
            "14 Batch accuracy: 0.8 Test accuracy: 0.843\n",
            "15 Batch accuracy: 0.92 Test accuracy: 0.846\n",
            "16 Batch accuracy: 0.78 Test accuracy: 0.826\n",
            "17 Batch accuracy: 0.82 Test accuracy: 0.8299\n",
            "18 Batch accuracy: 0.84 Test accuracy: 0.8476\n",
            "19 Batch accuracy: 0.86 Test accuracy: 0.8514\n",
            "20 Batch accuracy: 0.84 Test accuracy: 0.8119\n",
            "21 Batch accuracy: 0.88 Test accuracy: 0.829\n",
            "22 Batch accuracy: 0.78 Test accuracy: 0.8402\n",
            "23 Batch accuracy: 0.86 Test accuracy: 0.8478\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.8553\n",
            "25 Batch accuracy: 0.76 Test accuracy: 0.8315\n",
            "26 Batch accuracy: 0.88 Test accuracy: 0.8339\n",
            "27 Batch accuracy: 0.88 Test accuracy: 0.8776\n",
            "28 Batch accuracy: 0.84 Test accuracy: 0.8667\n",
            "29 Batch accuracy: 0.86 Test accuracy: 0.8583\n",
            "30 Batch accuracy: 0.86 Test accuracy: 0.874\n",
            "31 Batch accuracy: 0.92 Test accuracy: 0.8726\n",
            "32 Batch accuracy: 0.88 Test accuracy: 0.8804\n",
            "33 Batch accuracy: 0.88 Test accuracy: 0.8656\n",
            "34 Batch accuracy: 0.86 Test accuracy: 0.8395\n",
            "35 Batch accuracy: 0.88 Test accuracy: 0.865\n",
            "36 Batch accuracy: 0.88 Test accuracy: 0.8673\n",
            "37 Batch accuracy: 0.82 Test accuracy: 0.8524\n",
            "38 Batch accuracy: 0.8 Test accuracy: 0.8347\n",
            "39 Batch accuracy: 0.82 Test accuracy: 0.877\n",
            "40 Batch accuracy: 0.92 Test accuracy: 0.8657\n",
            "41 Batch accuracy: 0.82 Test accuracy: 0.881\n",
            "42 Batch accuracy: 0.84 Test accuracy: 0.8589\n",
            "43 Batch accuracy: 0.88 Test accuracy: 0.8753\n",
            "44 Batch accuracy: 0.84 Test accuracy: 0.8859\n",
            "45 Batch accuracy: 0.9 Test accuracy: 0.8712\n",
            "46 Batch accuracy: 0.86 Test accuracy: 0.869\n",
            "47 Batch accuracy: 0.82 Test accuracy: 0.8643\n",
            "48 Batch accuracy: 0.9 Test accuracy: 0.8693\n",
            "49 Batch accuracy: 0.92 Test accuracy: 0.8565\n",
            "50 Batch accuracy: 0.8 Test accuracy: 0.8866\n",
            "51 Batch accuracy: 0.96 Test accuracy: 0.8775\n",
            "52 Batch accuracy: 0.9 Test accuracy: 0.8685\n",
            "53 Batch accuracy: 0.74 Test accuracy: 0.8609\n",
            "54 Batch accuracy: 0.86 Test accuracy: 0.8633\n",
            "55 Batch accuracy: 0.92 Test accuracy: 0.8693\n",
            "56 Batch accuracy: 0.82 Test accuracy: 0.871\n",
            "57 Batch accuracy: 0.9 Test accuracy: 0.881\n",
            "58 Batch accuracy: 0.84 Test accuracy: 0.8849\n",
            "59 Batch accuracy: 0.9 Test accuracy: 0.8547\n",
            "60 Batch accuracy: 0.88 Test accuracy: 0.8763\n",
            "61 Batch accuracy: 0.88 Test accuracy: 0.8825\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.8704\n",
            "63 Batch accuracy: 0.88 Test accuracy: 0.8854\n",
            "64 Batch accuracy: 0.84 Test accuracy: 0.8656\n",
            "65 Batch accuracy: 0.9 Test accuracy: 0.8631\n",
            "66 Batch accuracy: 0.92 Test accuracy: 0.8702\n",
            "67 Batch accuracy: 0.92 Test accuracy: 0.8812\n",
            "68 Batch accuracy: 0.9 Test accuracy: 0.8789\n",
            "69 Batch accuracy: 0.9 Test accuracy: 0.8849\n",
            "70 Batch accuracy: 0.88 Test accuracy: 0.8887\n",
            "71 Batch accuracy: 0.88 Test accuracy: 0.8795\n",
            "72 Batch accuracy: 0.9 Test accuracy: 0.8821\n",
            "73 Batch accuracy: 0.94 Test accuracy: 0.8834\n",
            "74 Batch accuracy: 0.9 Test accuracy: 0.8834\n",
            "75 Batch accuracy: 0.94 Test accuracy: 0.884\n",
            "76 Batch accuracy: 0.92 Test accuracy: 0.8814\n",
            "77 Batch accuracy: 0.9 Test accuracy: 0.8798\n",
            "78 Batch accuracy: 0.92 Test accuracy: 0.8825\n",
            "79 Batch accuracy: 0.92 Test accuracy: 0.886\n",
            "80 Batch accuracy: 0.9 Test accuracy: 0.8741\n",
            "81 Batch accuracy: 0.8 Test accuracy: 0.8845\n",
            "82 Batch accuracy: 0.94 Test accuracy: 0.8958\n",
            "83 Batch accuracy: 0.88 Test accuracy: 0.9004\n",
            "84 Batch accuracy: 0.9 Test accuracy: 0.8872\n",
            "85 Batch accuracy: 0.82 Test accuracy: 0.8762\n",
            "86 Batch accuracy: 0.9 Test accuracy: 0.885\n",
            "87 Batch accuracy: 0.84 Test accuracy: 0.8654\n",
            "88 Batch accuracy: 0.94 Test accuracy: 0.8849\n",
            "89 Batch accuracy: 0.86 Test accuracy: 0.8693\n",
            "90 Batch accuracy: 0.94 Test accuracy: 0.8902\n",
            "91 Batch accuracy: 0.9 Test accuracy: 0.9053\n",
            "92 Batch accuracy: 0.84 Test accuracy: 0.8824\n",
            "93 Batch accuracy: 0.88 Test accuracy: 0.8821\n",
            "94 Batch accuracy: 0.86 Test accuracy: 0.875\n",
            "95 Batch accuracy: 0.98 Test accuracy: 0.8869\n",
            "96 Batch accuracy: 0.92 Test accuracy: 0.8769\n",
            "97 Batch accuracy: 0.82 Test accuracy: 0.8863\n",
            "98 Batch accuracy: 0.88 Test accuracy: 0.8889\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.8792\n",
            "--- 3071.88 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_rXVNJjl-pM1",
        "outputId": "bd466399-4c62-4e9d-80fe-c636bad5968a"
      },
      "source": [
        "# mock simulation using np.arange for device states\n",
        "run_MLP_simulation(num_epochs_input = 100, \n",
        "                   hardware_simulation_input = False, \n",
        "                   device_states_input = False,\n",
        "                   read_noise_mean_input = 0.0,\n",
        "                   read_noise_stddev_input = 0.0,\n",
        "                   device_variation_stddev_input = 0.0,\n",
        "                   device_stuck_on_prob_input = 0.0,\n",
        "                   device_stuck_off_prob_input = 0.0,\n",
        "                   save_results_input = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Batch accuracy: 0.88 Test accuracy: 0.8849\n",
            "1 Batch accuracy: 0.86 Test accuracy: 0.9082\n",
            "2 Batch accuracy: 0.92 Test accuracy: 0.9206\n",
            "3 Batch accuracy: 0.96 Test accuracy: 0.9269\n",
            "4 Batch accuracy: 1.0 Test accuracy: 0.9298\n",
            "5 Batch accuracy: 0.98 Test accuracy: 0.9327\n",
            "6 Batch accuracy: 0.96 Test accuracy: 0.9368\n",
            "7 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "8 Batch accuracy: 0.96 Test accuracy: 0.944\n",
            "9 Batch accuracy: 0.98 Test accuracy: 0.9456\n",
            "10 Batch accuracy: 0.98 Test accuracy: 0.9467\n",
            "11 Batch accuracy: 0.9 Test accuracy: 0.9497\n",
            "12 Batch accuracy: 0.92 Test accuracy: 0.9499\n",
            "13 Batch accuracy: 0.98 Test accuracy: 0.9533\n",
            "14 Batch accuracy: 0.94 Test accuracy: 0.9533\n",
            "15 Batch accuracy: 0.94 Test accuracy: 0.9553\n",
            "16 Batch accuracy: 1.0 Test accuracy: 0.9558\n",
            "17 Batch accuracy: 0.94 Test accuracy: 0.9566\n",
            "18 Batch accuracy: 0.98 Test accuracy: 0.9581\n",
            "19 Batch accuracy: 0.96 Test accuracy: 0.9574\n",
            "20 Batch accuracy: 0.96 Test accuracy: 0.9579\n",
            "21 Batch accuracy: 0.98 Test accuracy: 0.9595\n",
            "22 Batch accuracy: 0.94 Test accuracy: 0.9607\n",
            "23 Batch accuracy: 0.98 Test accuracy: 0.9607\n",
            "24 Batch accuracy: 0.98 Test accuracy: 0.961\n",
            "25 Batch accuracy: 0.98 Test accuracy: 0.9612\n",
            "26 Batch accuracy: 1.0 Test accuracy: 0.9623\n",
            "27 Batch accuracy: 1.0 Test accuracy: 0.9628\n",
            "28 Batch accuracy: 1.0 Test accuracy: 0.9622\n",
            "29 Batch accuracy: 0.98 Test accuracy: 0.9632\n",
            "30 Batch accuracy: 0.98 Test accuracy: 0.9636\n",
            "31 Batch accuracy: 1.0 Test accuracy: 0.9625\n",
            "32 Batch accuracy: 0.92 Test accuracy: 0.9637\n",
            "33 Batch accuracy: 0.96 Test accuracy: 0.9652\n",
            "34 Batch accuracy: 0.96 Test accuracy: 0.9635\n",
            "35 Batch accuracy: 0.96 Test accuracy: 0.9637\n",
            "36 Batch accuracy: 0.98 Test accuracy: 0.9655\n",
            "37 Batch accuracy: 1.0 Test accuracy: 0.9656\n",
            "38 Batch accuracy: 1.0 Test accuracy: 0.9662\n",
            "39 Batch accuracy: 0.98 Test accuracy: 0.9666\n",
            "40 Batch accuracy: 1.0 Test accuracy: 0.966\n",
            "41 Batch accuracy: 0.98 Test accuracy: 0.9665\n",
            "42 Batch accuracy: 0.96 Test accuracy: 0.9666\n",
            "43 Batch accuracy: 0.98 Test accuracy: 0.9681\n",
            "44 Batch accuracy: 1.0 Test accuracy: 0.9677\n",
            "45 Batch accuracy: 0.98 Test accuracy: 0.9666\n",
            "46 Batch accuracy: 0.96 Test accuracy: 0.9675\n",
            "47 Batch accuracy: 1.0 Test accuracy: 0.9675\n",
            "48 Batch accuracy: 1.0 Test accuracy: 0.9682\n",
            "49 Batch accuracy: 1.0 Test accuracy: 0.9683\n",
            "50 Batch accuracy: 0.98 Test accuracy: 0.9678\n",
            "51 Batch accuracy: 0.96 Test accuracy: 0.968\n",
            "52 Batch accuracy: 0.98 Test accuracy: 0.9683\n",
            "53 Batch accuracy: 1.0 Test accuracy: 0.9681\n",
            "54 Batch accuracy: 1.0 Test accuracy: 0.9697\n",
            "55 Batch accuracy: 0.98 Test accuracy: 0.9691\n",
            "56 Batch accuracy: 1.0 Test accuracy: 0.9692\n",
            "57 Batch accuracy: 1.0 Test accuracy: 0.9697\n",
            "58 Batch accuracy: 0.98 Test accuracy: 0.9706\n",
            "59 Batch accuracy: 0.98 Test accuracy: 0.9696\n",
            "60 Batch accuracy: 0.98 Test accuracy: 0.9705\n",
            "61 Batch accuracy: 1.0 Test accuracy: 0.971\n",
            "62 Batch accuracy: 0.98 Test accuracy: 0.9707\n",
            "63 Batch accuracy: 1.0 Test accuracy: 0.97\n",
            "64 Batch accuracy: 1.0 Test accuracy: 0.9703\n",
            "65 Batch accuracy: 1.0 Test accuracy: 0.9712\n",
            "66 Batch accuracy: 1.0 Test accuracy: 0.972\n",
            "67 Batch accuracy: 0.98 Test accuracy: 0.9716\n",
            "68 Batch accuracy: 1.0 Test accuracy: 0.9721\n",
            "69 Batch accuracy: 1.0 Test accuracy: 0.9718\n",
            "70 Batch accuracy: 1.0 Test accuracy: 0.9716\n",
            "71 Batch accuracy: 1.0 Test accuracy: 0.9714\n",
            "72 Batch accuracy: 1.0 Test accuracy: 0.9721\n",
            "73 Batch accuracy: 1.0 Test accuracy: 0.9718\n",
            "74 Batch accuracy: 0.98 Test accuracy: 0.9717\n",
            "75 Batch accuracy: 0.98 Test accuracy: 0.9722\n",
            "76 Batch accuracy: 1.0 Test accuracy: 0.9725\n",
            "77 Batch accuracy: 1.0 Test accuracy: 0.9724\n",
            "78 Batch accuracy: 1.0 Test accuracy: 0.972\n",
            "79 Batch accuracy: 1.0 Test accuracy: 0.9727\n",
            "80 Batch accuracy: 1.0 Test accuracy: 0.9715\n",
            "81 Batch accuracy: 1.0 Test accuracy: 0.9727\n",
            "82 Batch accuracy: 1.0 Test accuracy: 0.9725\n",
            "83 Batch accuracy: 0.98 Test accuracy: 0.9722\n",
            "84 Batch accuracy: 1.0 Test accuracy: 0.973\n",
            "85 Batch accuracy: 0.98 Test accuracy: 0.9727\n",
            "86 Batch accuracy: 1.0 Test accuracy: 0.9723\n",
            "87 Batch accuracy: 1.0 Test accuracy: 0.9724\n",
            "88 Batch accuracy: 1.0 Test accuracy: 0.9728\n",
            "89 Batch accuracy: 0.98 Test accuracy: 0.9729\n",
            "90 Batch accuracy: 1.0 Test accuracy: 0.9728\n",
            "91 Batch accuracy: 1.0 Test accuracy: 0.9727\n",
            "92 Batch accuracy: 1.0 Test accuracy: 0.9727\n",
            "93 Batch accuracy: 1.0 Test accuracy: 0.9733\n",
            "94 Batch accuracy: 1.0 Test accuracy: 0.9722\n",
            "95 Batch accuracy: 1.0 Test accuracy: 0.9734\n",
            "96 Batch accuracy: 1.0 Test accuracy: 0.9734\n",
            "97 Batch accuracy: 1.0 Test accuracy: 0.9724\n",
            "98 Batch accuracy: 1.0 Test accuracy: 0.9724\n",
            "99 Batch accuracy: 1.0 Test accuracy: 0.973\n",
            "--- 254.00 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bm4RZf9-pM2"
      },
      "source": [
        "# Results\n",
        "\n",
        "## software only (~2 mins , 10 sec)\n",
        "- Learning rate = 0.01\n",
        "0 Batch accuracy: 0.88 Test accuracy: 0.8849\n",
        "1 Batch accuracy: 0.86 Test accuracy: 0.9082\n",
        "2 Batch accuracy: 0.92 Test accuracy: 0.9206\n",
        "3 Batch accuracy: 0.96 Test accuracy: 0.9269\n",
        "4 Batch accuracy: 1.0 Test accuracy: 0.9298\n",
        "5 Batch accuracy: 0.98 Test accuracy: 0.9327\n",
        "6 Batch accuracy: 0.96 Test accuracy: 0.9368\n",
        "7 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
        "8 Batch accuracy: 0.96 Test accuracy: 0.944\n",
        "9 Batch accuracy: 0.98 Test accuracy: 0.9456\n",
        "10 Batch accuracy: 0.98 Test accuracy: 0.9467\n",
        "11 Batch accuracy: 0.9 Test accuracy: 0.9497\n",
        "12 Batch accuracy: 0.92 Test accuracy: 0.9499\n",
        "13 Batch accuracy: 0.98 Test accuracy: 0.9533\n",
        "14 Batch accuracy: 0.94 Test accuracy: 0.9533\n",
        "15 Batch accuracy: 0.94 Test accuracy: 0.9553\n",
        "16 Batch accuracy: 1.0 Test accuracy: 0.9558\n",
        "17 Batch accuracy: 0.94 Test accuracy: 0.9566\n",
        "18 Batch accuracy: 0.98 Test accuracy: 0.9581\n",
        "19 Batch accuracy: 0.96 Test accuracy: 0.9574\n",
        "20 Batch accuracy: 0.96 Test accuracy: 0.9579\n",
        "21 Batch accuracy: 0.98 Test accuracy: 0.9595\n",
        "22 Batch accuracy: 0.94 Test accuracy: 0.9607\n",
        "23 Batch accuracy: 0.98 Test accuracy: 0.9607\n",
        "24 Batch accuracy: 0.98 Test accuracy: 0.961\n",
        "25 Batch accuracy: 0.98 Test accuracy: 0.9612\n",
        "26 Batch accuracy: 1.0 Test accuracy: 0.9623\n",
        "27 Batch accuracy: 1.0 Test accuracy: 0.9628\n",
        "28 Batch accuracy: 1.0 Test accuracy: 0.9622\n",
        "29 Batch accuracy: 0.98 Test accuracy: 0.9632\n",
        "30 Batch accuracy: 0.98 Test accuracy: 0.9636\n",
        "31 Batch accuracy: 1.0 Test accuracy: 0.9625\n",
        "32 Batch accuracy: 0.92 Test accuracy: 0.9637\n",
        "33 Batch accuracy: 0.96 Test accuracy: 0.9652\n",
        "34 Batch accuracy: 0.96 Test accuracy: 0.9635\n",
        "35 Batch accuracy: 0.96 Test accuracy: 0.9637\n",
        "36 Batch accuracy: 0.98 Test accuracy: 0.9655\n",
        "37 Batch accuracy: 1.0 Test accuracy: 0.9656\n",
        "38 Batch accuracy: 1.0 Test accuracy: 0.9662\n",
        "39 Batch accuracy: 0.98 Test accuracy: 0.9666\n",
        "40 Batch accuracy: 1.0 Test accuracy: 0.966\n",
        "41 Batch accuracy: 0.98 Test accuracy: 0.9665\n",
        "42 Batch accuracy: 0.96 Test accuracy: 0.9666\n",
        "43 Batch accuracy: 0.98 Test accuracy: 0.9681\n",
        "44 Batch accuracy: 1.0 Test accuracy: 0.9677\n",
        "45 Batch accuracy: 0.98 Test accuracy: 0.9666\n",
        "46 Batch accuracy: 0.96 Test accuracy: 0.9675\n",
        "47 Batch accuracy: 1.0 Test accuracy: 0.9675\n",
        "48 Batch accuracy: 1.0 Test accuracy: 0.9682\n",
        "49 Batch accuracy: 1.0 Test accuracy: 0.9683\n",
        "--- 140.81 seconds ---\n",
        "\n",
        "## software only (~30 secs)\n",
        "- Learning rate = 0.1\n",
        "0 Batch accuracy: 0.94 Test accuracy: 0.9427\n",
        "1 Batch accuracy: 0.98 Test accuracy: 0.9556\n",
        "2 Batch accuracy: 0.98 Test accuracy: 0.9635\n",
        "3 Batch accuracy: 1.0 Test accuracy: 0.9665\n",
        "4 Batch accuracy: 1.0 Test accuracy: 0.965\n",
        "5 Batch accuracy: 1.0 Test accuracy: 0.9678\n",
        "6 Batch accuracy: 1.0 Test accuracy: 0.9699\n",
        "7 Batch accuracy: 1.0 Test accuracy: 0.9722\n",
        "8 Batch accuracy: 1.0 Test accuracy: 0.9727\n",
        "9 Batch accuracy: 1.0 Test accuracy: 0.9718\n",
        "10 Batch accuracy: 1.0 Test accuracy: 0.9746\n",
        "11 Batch accuracy: 0.98 Test accuracy: 0.9745\n",
        "12 Batch accuracy: 1.0 Test accuracy: 0.9765\n",
        "13 Batch accuracy: 1.0 Test accuracy: 0.9765\n",
        "14 Batch accuracy: 1.0 Test accuracy: 0.9762\n",
        "15 Batch accuracy: 1.0 Test accuracy: 0.9753\n",
        "16 Batch accuracy: 1.0 Test accuracy: 0.9754\n",
        "17 Batch accuracy: 1.0 Test accuracy: 0.977\n",
        "18 Batch accuracy: 1.0 Test accuracy: 0.9756\n",
        "19 Batch accuracy: 1.0 Test accuracy: 0.9768\n",
        "20 Batch accuracy: 1.0 Test accuracy: 0.977\n",
        "\n",
        "## hardware ON, but just discrete states (20) (~2 min, 13 s)\n",
        "0 Batch accuracy: 0.92 Test accuracy: 0.933\n",
        "1 Batch accuracy: 0.92 Test accuracy: 0.938\n",
        "2 Batch accuracy: 0.94 Test accuracy: 0.9418\n",
        "3 Batch accuracy: 0.98 Test accuracy: 0.9431\n",
        "4 Batch accuracy: 0.94 Test accuracy: 0.942\n",
        "5 Batch accuracy: 0.96 Test accuracy: 0.9401\n",
        "6 Batch accuracy: 0.92 Test accuracy: 0.9405\n",
        "7 Batch accuracy: 0.96 Test accuracy: 0.9417\n",
        "8 Batch accuracy: 0.92 Test accuracy: 0.9422\n",
        "9 Batch accuracy: 0.96 Test accuracy: 0.9402\n",
        "10 Batch accuracy: 1.0 Test accuracy: 0.9405\n",
        "11 Batch accuracy: 0.92 Test accuracy: 0.9405\n",
        "12 Batch accuracy: 0.96 Test accuracy: 0.9416\n",
        "13 Batch accuracy: 0.94 Test accuracy: 0.9415\n",
        "14 Batch accuracy: 0.98 Test accuracy: 0.9417\n",
        "15 Batch accuracy: 0.98 Test accuracy: 0.9415\n",
        "16 Batch accuracy: 0.96 Test accuracy: 0.9422\n",
        "17 Batch accuracy: 0.96 Test accuracy: 0.9422\n",
        "18 Batch accuracy: 0.88 Test accuracy: 0.9425\n",
        "19 Batch accuracy: 0.98 Test accuracy: 0.942\n",
        "\n",
        "## hardware ON, but just discrete states (100) ( min,  s)\n",
        "0 Batch accuracy: 0.94 Test accuracy: 0.941\n",
        "1 Batch accuracy: 0.96 Test accuracy: 0.9539\n",
        "2 Batch accuracy: 0.98 Test accuracy: 0.9604\n",
        "3 Batch accuracy: 1.0 Test accuracy: 0.9651\n",
        "4 Batch accuracy: 1.0 Test accuracy: 0.9664\n",
        "5 Batch accuracy: 1.0 Test accuracy: 0.9679\n",
        "6 Batch accuracy: 0.98 Test accuracy: 0.9671\n",
        "7 Batch accuracy: 1.0 Test accuracy: 0.971\n",
        "8 Batch accuracy: 0.98 Test accuracy: 0.9705\n",
        "9 Batch accuracy: 1.0 Test accuracy: 0.9709\n",
        "10 Batch accuracy: 1.0 Test accuracy: 0.9711\n",
        "11 Batch accuracy: 0.98 Test accuracy: 0.971\n",
        "12 Batch accuracy: 1.0 Test accuracy: 0.9704\n",
        "13 Batch accuracy: 0.98 Test accuracy: 0.9706\n",
        "14 Batch accuracy: 1.0 Test accuracy: 0.9729\n",
        "15 Batch accuracy: 1.0 Test accuracy: 0.9724\n",
        "16 Batch accuracy: 1.0 Test accuracy: 0.9736\n",
        "\n",
        "## hardware ON with... (1 min 11s)\n",
        "- 20 states\n",
        "- readnoise = 0.0 +/- 0.2\n",
        "- stuckon = stuckoff = 0.05\n",
        "- device_var = 0.1\n",
        "0 Batch accuracy: 0.4 Test accuracy: 0.3264\n",
        "1 Batch accuracy: 0.44 Test accuracy: 0.4225\n",
        "2 Batch accuracy: 0.52 Test accuracy: 0.4578\n",
        "3 Batch accuracy: 0.52 Test accuracy: 0.4802\n",
        "4 Batch accuracy: 0.64 Test accuracy: 0.6497\n",
        "5 Batch accuracy: 0.58 Test accuracy: 0.6118\n",
        "6 Batch accuracy: 0.46 Test accuracy: 0.551\n",
        "7 Batch accuracy: 0.52 Test accuracy: 0.5524\n",
        "--- 71.81 seconds ---\n",
        "\n",
        "## hardware ON with... (1 min 3s)\n",
        "- 20 states\n",
        "- readnoise = 0.0 +/- 0.05\n",
        "- stuckon = stuckoff = 0.05\n",
        "- device_var = 0.1\n",
        "0 Batch accuracy: 0.88 Test accuracy: 0.8143\n",
        "1 Batch accuracy: 0.94 Test accuracy: 0.8872\n",
        "2 Batch accuracy: 0.92 Test accuracy: 0.8669\n",
        "3 Batch accuracy: 0.78 Test accuracy: 0.8651\n",
        "4 Batch accuracy: 0.96 Test accuracy: 0.8995\n",
        "5 Batch accuracy: 0.9 Test accuracy: 0.9091\n",
        "6 Batch accuracy: 0.92 Test accuracy: 0.8873\n",
        "7 Batch accuracy: 0.88 Test accuracy: 0.8694\n",
        "--- 63.78 seconds ---\n",
        "\n",
        "\n",
        "## hardware ON with... (17 mins)\n",
        "- 100 states\n",
        "- readnoise = 0.0 +/- 0.05\n",
        "- stuckon = stuckoff = 0.05\n",
        "- device_var = 0.1\n",
        "0 Batch accuracy: 0.86 Test accuracy: 0.8376\n",
        "1 Batch accuracy: 0.96 Test accuracy: 0.8902\n",
        "2 Batch accuracy: 0.94 Test accuracy: 0.8869\n",
        "3 Batch accuracy: 0.9 Test accuracy: 0.8921\n",
        "4 Batch accuracy: 0.94 Test accuracy: 0.9196\n",
        "5 Batch accuracy: 0.9 Test accuracy: 0.9166\n",
        "6 Batch accuracy: 0.94 Test accuracy: 0.9174\n",
        "7 Batch accuracy: 0.88 Test accuracy: 0.9134\n",
        "8 Batch accuracy: 0.88 Test accuracy: 0.884\n",
        "9 Batch accuracy: 0.88 Test accuracy: 0.9095\n",
        "10 Batch accuracy: 0.92 Test accuracy: 0.913\n",
        "11 Batch accuracy: 0.86 Test accuracy: 0.909\n",
        "12 Batch accuracy: 0.94 Test accuracy: 0.9265\n",
        "13 Batch accuracy: 0.9 Test accuracy: 0.901\n",
        "14 Batch accuracy: 0.92 Test accuracy: 0.9157\n",
        "15 Batch accuracy: 0.92 Test accuracy: 0.8996\n",
        "16 Batch accuracy: 0.9 Test accuracy: 0.9165\n",
        "17 Batch accuracy: 0.92 Test accuracy: 0.917\n",
        "18 Batch accuracy: 0.96 Test accuracy: 0.926\n",
        "19 Batch accuracy: 0.94 Test accuracy: 0.9229\n",
        "20 Batch accuracy: 0.98 Test accuracy: 0.9061\n",
        "21 Batch accuracy: 0.94 Test accuracy: 0.9252\n",
        "22 Batch accuracy: 0.92 Test accuracy: 0.9188\n",
        "23 Batch accuracy: 0.96 Test accuracy: 0.9229\n",
        "24 Batch accuracy: 0.94 Test accuracy: 0.9326\n",
        "25 Batch accuracy: 0.96 Test accuracy: 0.9163\n",
        "26 Batch accuracy: 0.94 Test accuracy: 0.923\n",
        "27 Batch accuracy: 0.92 Test accuracy: 0.9222\n",
        "28 Batch accuracy: 0.94 Test accuracy: 0.926\n",
        "29 Batch accuracy: 0.98 Test accuracy: 0.9132\n",
        "30 Batch accuracy: 0.96 Test accuracy: 0.9141\n",
        "31 Batch accuracy: 0.94 Test accuracy: 0.9229\n",
        "32 Batch accuracy: 0.88 Test accuracy: 0.9223\n",
        "33 Batch accuracy: 0.9 Test accuracy: 0.8704\n",
        "34 Batch accuracy: 0.9 Test accuracy: 0.9216\n",
        "35 Batch accuracy: 0.92 Test accuracy: 0.9069\n",
        "36 Batch accuracy: 0.94 Test accuracy: 0.9095\n",
        "37 Batch accuracy: 0.92 Test accuracy: 0.9306\n",
        "38 Batch accuracy: 0.9 Test accuracy: 0.9147\n",
        "39 Batch accuracy: 0.94 Test accuracy: 0.9339\n",
        "40 Batch accuracy: 0.96 Test accuracy: 0.9148\n",
        "41 Batch accuracy: 0.96 Test accuracy: 0.8807\n",
        "42 Batch accuracy: 0.92 Test accuracy: 0.8752\n",
        "43 Batch accuracy: 0.92 Test accuracy: 0.9108\n",
        "44 Batch accuracy: 0.92 Test accuracy: 0.9234\n",
        "45 Batch accuracy: 0.94 Test accuracy: 0.9276\n",
        "46 Batch accuracy: 0.94 Test accuracy: 0.9113\n",
        "47 Batch accuracy: 0.9 Test accuracy: 0.914\n",
        "48 Batch accuracy: 0.98 Test accuracy: 0.9277\n",
        "49 Batch accuracy: 0.9 Test accuracy: 0.9335\n",
        "--- 995.70 seconds ---\n",
        "\n",
        "## hardware ON with... (14 mins)\n",
        "- 100 states\n",
        "- readnoise = 0.0 +/- 0.00\n",
        "- stuckon = stuckoff = 0.05\n",
        "- device_var = 0.1\n",
        "\n",
        "0 Batch accuracy: 0.92 Test accuracy: 0.9238\n",
        "1 Batch accuracy: 0.92 Test accuracy: 0.9367\n",
        "2 Batch accuracy: 0.96 Test accuracy: 0.9368\n",
        "3 Batch accuracy: 0.96 Test accuracy: 0.9459\n",
        "4 Batch accuracy: 0.98 Test accuracy: 0.9495\n",
        "5 Batch accuracy: 0.98 Test accuracy: 0.9565\n",
        "6 Batch accuracy: 0.9 Test accuracy: 0.9342\n",
        "7 Batch accuracy: 0.98 Test accuracy: 0.9486\n",
        "8 Batch accuracy: 0.96 Test accuracy: 0.9432\n",
        "9 Batch accuracy: 0.96 Test accuracy: 0.948\n",
        "10 Batch accuracy: 1.0 Test accuracy: 0.9513\n",
        "11 Batch accuracy: 0.94 Test accuracy: 0.9572\n",
        "12 Batch accuracy: 1.0 Test accuracy: 0.9436\n",
        "13 Batch accuracy: 0.92 Test accuracy: 0.9293\n",
        "14 Batch accuracy: 0.96 Test accuracy: 0.9586\n",
        "15 Batch accuracy: 1.0 Test accuracy: 0.9583\n",
        "16 Batch accuracy: 0.98 Test accuracy: 0.9644\n",
        "17 Batch accuracy: 1.0 Test accuracy: 0.9469\n",
        "18 Batch accuracy: 0.9 Test accuracy: 0.9589\n",
        "19 Batch accuracy: 0.98 Test accuracy: 0.9617\n",
        "20 Batch accuracy: 0.96 Test accuracy: 0.9519\n",
        "21 Batch accuracy: 0.94 Test accuracy: 0.9536\n",
        "22 Batch accuracy: 0.96 Test accuracy: 0.9654\n",
        "23 Batch accuracy: 0.98 Test accuracy: 0.9594\n",
        "24 Batch accuracy: 0.98 Test accuracy: 0.9655\n",
        "25 Batch accuracy: 1.0 Test accuracy: 0.9624\n",
        "26 Batch accuracy: 0.96 Test accuracy: 0.9626\n",
        "27 Batch accuracy: 1.0 Test accuracy: 0.958\n",
        "28 Batch accuracy: 1.0 Test accuracy: 0.9532\n",
        "29 Batch accuracy: 1.0 Test accuracy: 0.9704\n",
        "30 Batch accuracy: 0.98 Test accuracy: 0.9576\n",
        "31 Batch accuracy: 1.0 Test accuracy: 0.9594\n",
        "32 Batch accuracy: 0.98 Test accuracy: 0.9676\n",
        "33 Batch accuracy: 1.0 Test accuracy: 0.9568\n",
        "34 Batch accuracy: 1.0 Test accuracy: 0.97\n",
        "35 Batch accuracy: 0.98 Test accuracy: 0.9625\n",
        "36 Batch accuracy: 1.0 Test accuracy: 0.9638\n",
        "37 Batch accuracy: 0.98 Test accuracy: 0.9559\n",
        "38 Batch accuracy: 1.0 Test accuracy: 0.9564\n",
        "39 Batch accuracy: 0.98 Test accuracy: 0.9416\n",
        "40 Batch accuracy: 0.98 Test accuracy: 0.9536\n",
        "41 Batch accuracy: 0.98 Test accuracy: 0.9669\n",
        "42 Batch accuracy: 0.96 Test accuracy: 0.9723\n",
        "43 Batch accuracy: 0.94 Test accuracy: 0.9654\n",
        "44 Batch accuracy: 0.96 Test accuracy: 0.9631\n",
        "45 Batch accuracy: 0.98 Test accuracy: 0.9669\n",
        "46 Batch accuracy: 1.0 Test accuracy: 0.9717\n",
        "47 Batch accuracy: 0.94 Test accuracy: 0.9653\n",
        "48 Batch accuracy: 0.92 Test accuracy: 0.9347\n",
        "49 Batch accuracy: 1.0 Test accuracy: 0.9634\n",
        "--- 875.17 seconds ---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx1-XYLt-pM6",
        "outputId": "b20ae610-bbdd-4b1e-e64d-3ff635256a0b"
      },
      "source": [
        "weights_before"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.00363304, -0.16495076, -0.00245212, -0.07429077, -0.0231128 ,\n",
              "       -0.34697148,  0.3885961 ,  0.30065742,  0.22381195, -0.0381159 ,\n",
              "        0.00310417,  0.08535535,  0.17385383,  0.30208942,  0.125374  ,\n",
              "        0.00897076,  0.07525111, -0.29270896, -0.18102363,  0.06648245,\n",
              "       -0.01434219, -0.12452476, -0.23496754,  0.24518795, -0.03454113,\n",
              "        0.09062955,  0.05114428, -0.01170656,  0.31281415,  0.05068856,\n",
              "       -0.07658286, -0.3558821 , -0.02831533,  0.29215947, -0.01215394,\n",
              "        0.05968314,  0.26844263,  0.34673175,  0.00499299,  0.01214231,\n",
              "       -0.26232064, -0.18391348, -0.30076265,  0.08745792,  0.04777403,\n",
              "       -0.30305094,  0.33885407, -0.22074407, -0.01648456,  0.14930668,\n",
              "       -0.10613731, -0.15380175,  0.04764128,  0.1736799 , -0.05961963,\n",
              "       -0.23478894, -0.18598206, -0.05220306, -0.03114807,  0.04526016,\n",
              "       -0.13837756,  0.17210205, -0.11568228, -0.06414939, -0.07839669,\n",
              "       -0.31229424, -0.2896966 ,  0.03144627, -0.03642305, -0.16567579,\n",
              "       -0.00267657,  0.17316784,  0.00085319, -0.09679439, -0.02308435,\n",
              "        0.16394866,  0.01165754,  0.05500915,  0.41136825, -0.05219844,\n",
              "        0.2085114 , -0.07541733, -0.1070393 , -0.01492016,  0.08076164,\n",
              "        0.19692856,  0.13495956, -0.38460404, -0.04849344, -0.08398602,\n",
              "        0.14246887, -0.21932591,  0.06827202, -0.2051726 , -0.17666604,\n",
              "       -0.05961052, -0.10623793, -0.0255966 ,  0.13482282, -0.17893608,\n",
              "        0.09000875, -0.07414095, -0.00147178, -0.3673266 ,  0.08518526,\n",
              "       -0.3438186 , -0.08230692,  0.21740241,  0.13392316, -0.09173317,\n",
              "        0.34868085,  0.06192811,  0.2656322 ,  0.05334428,  0.14007658,\n",
              "        0.2281066 , -0.3195803 ,  0.18029472, -0.19715586, -0.02840302,\n",
              "        0.13200265,  0.1640659 ,  0.08478154,  0.07364658, -0.3171663 ,\n",
              "       -0.11999371,  0.3375892 , -0.00573255, -0.21645758, -0.1885861 ,\n",
              "        0.06762656,  0.218657  ,  0.04552095,  0.3021214 , -0.3293409 ,\n",
              "        0.09390545,  0.15122677, -0.14340286, -0.2328385 , -0.271851  ,\n",
              "        0.11863299,  0.1443909 , -0.32996917, -0.03591542, -0.04326014,\n",
              "        0.07065223, -0.01636403,  0.10281464,  0.05116272,  0.33759323,\n",
              "        0.11180329, -0.27110025,  0.22969015,  0.14410236, -0.30995998,\n",
              "        0.16053978,  0.03548114,  0.17458898,  0.08910751, -0.38312206,\n",
              "        0.20420177, -0.05197211, -0.03291531,  0.20131718, -0.30613896,\n",
              "        0.03595546, -0.12058713,  0.0586332 , -0.11217057,  0.19694291,\n",
              "       -0.17973398, -0.14652523, -0.02917453,  0.26436493, -0.06099458,\n",
              "       -0.11913513, -0.2629287 , -0.19920772, -0.17564017,  0.17017403,\n",
              "       -0.01270065, -0.18048352, -0.16957238,  0.16083811, -0.17279983,\n",
              "       -0.07432749, -0.14277601,  0.30492598,  0.03528479, -0.23299056,\n",
              "       -0.22208396,  0.04902112, -0.09590512,  0.14306852,  0.19182707,\n",
              "       -0.19023907, -0.00794895, -0.12115265, -0.16815071, -0.05340749,\n",
              "       -0.21926986,  0.01095075,  0.0968822 , -0.29020125, -0.02158891,\n",
              "       -0.10390481, -0.20072246,  0.26937482, -0.06449796,  0.08901459,\n",
              "       -0.2591222 ,  0.02090825, -0.02636197, -0.03075243,  0.12408592,\n",
              "       -0.3049613 , -0.13866909,  0.28398675,  0.05102077,  0.01707341,\n",
              "        0.09695832,  0.15275683,  0.02451089, -0.15840153,  0.05042589,\n",
              "       -0.24000023,  0.03005715, -0.2378383 ,  0.10830259,  0.0710686 ,\n",
              "       -0.01086262, -0.00347498,  0.0264352 ,  0.07423522,  0.29181156,\n",
              "       -0.1386595 ,  0.2349203 , -0.0437406 ,  0.19554102,  0.14396428,\n",
              "        0.09926233,  0.07350031, -0.33096662,  0.22308242,  0.17690367,\n",
              "       -0.20106262,  0.00483929, -0.0394629 ,  0.09772117,  0.13834712,\n",
              "       -0.31102046, -0.17354865, -0.12152156, -0.16103064,  0.13679971,\n",
              "        0.07532874,  0.11013555, -0.12267293,  0.09924937, -0.34042314,\n",
              "        0.02201365,  0.27052307,  0.04294404, -0.25432816, -0.19746897,\n",
              "       -0.13402449, -0.23749909,  0.19029996,  0.19579083, -0.26166064,\n",
              "       -0.15412852,  0.17491113, -0.1651232 ,  0.02764448,  0.20055656,\n",
              "       -0.01854535,  0.05692549, -0.08943276,  0.03881437,  0.4106647 ,\n",
              "        0.04369108,  0.03399525,  0.11422517,  0.06415461,  0.3406343 ,\n",
              "        0.0845423 ,  0.05388894,  0.05470451,  0.04703617, -0.09848036,\n",
              "       -0.15698525,  0.07941221, -0.17882024, -0.05065073,  0.05850855,\n",
              "        0.1418438 ,  0.09312636,  0.01073388, -0.05722875, -0.08071069],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "beo9Hh2B-pM9",
        "outputId": "085d09b7-9336-4ba5-ed17-8fcd42374fc2"
      },
      "source": [
        "weights_after"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0. , -0.2, -0. , -0.1, -0. , -0.3,  0.4,  0.3,  0.2, -0. , -0. ,\n",
              "        0.1,  0.2,  0.3,  0.1, -0. ,  0.1, -0.3, -0.2,  0.1, -0. , -0.1,\n",
              "       -0.2,  0.2, -0. ,  0.1,  0.1, -0. ,  0.3,  0.1, -0.1, -0.4, -0. ,\n",
              "        0.3, -0. ,  0.1,  0.3,  0.3, -0. , -0. , -0.3, -0.2, -0.3,  0.1,\n",
              "       -0. , -0.3,  0.3, -0.2, -0. ,  0.1, -0.1, -0.2, -0. ,  0.2, -0.1,\n",
              "       -0.2, -0.2, -0.1, -0. , -0. , -0.1,  0.2, -0.1, -0.1, -0.1, -0.3,\n",
              "       -0.3, -0. , -0. , -0.2, -0. ,  0.2, -0. , -0.1, -0. ,  0.2, -0. ,\n",
              "        0.1,  0.4, -0.1,  0.2, -0.1, -0.1, -0. ,  0.1,  0.2,  0.1, -0.4,\n",
              "       -0. , -0.1,  0.1, -0.2,  0.1, -0.2, -0.2, -0.1, -0.1, -0. ,  0.1,\n",
              "       -0.2,  0.1, -0.1, -0. , -0.4,  0.1, -0.3, -0.1,  0.2,  0.1, -0.1,\n",
              "        0.3,  0.1,  0.3,  0.1,  0.1,  0.2, -0.3,  0.2, -0.2, -0. ,  0.1,\n",
              "        0.2,  0.1,  0.1, -0.3, -0.1,  0.3, -0. , -0.2, -0.2,  0.1,  0.2,\n",
              "       -0. ,  0.3, -0.3,  0.1,  0.2, -0.1, -0.2, -0.3,  0.1,  0.1, -0.3,\n",
              "       -0. , -0. ,  0.1, -0. ,  0.1,  0.1,  0.3,  0.1, -0.3,  0.2,  0.1,\n",
              "       -0.3,  0.2, -0. ,  0.2,  0.1, -0.4,  0.2, -0.1, -0. ,  0.2, -0.3,\n",
              "       -0. , -0.1,  0.1, -0.1,  0.2, -0.2, -0.1, -0. ,  0.3, -0.1, -0.1,\n",
              "       -0.3, -0.2, -0.2,  0.2, -0. , -0.2, -0.2,  0.2, -0.2, -0.1, -0.1,\n",
              "        0.3, -0. , -0.2, -0.2, -0. , -0.1,  0.1,  0.2, -0.2, -0. , -0.1,\n",
              "       -0.2, -0.1, -0.2, -0. ,  0.1, -0.3, -0. , -0.1, -0.2,  0.3, -0.1,\n",
              "        0.1, -0.3, -0. , -0. , -0. ,  0.1, -0.3, -0.1,  0.3,  0.1, -0. ,\n",
              "        0.1,  0.2, -0. , -0.2,  0.1, -0.2, -0. , -0.2,  0.1,  0.1, -0. ,\n",
              "       -0. , -0. ,  0.1,  0.3, -0.1,  0.2, -0. ,  0.2,  0.1,  0.1,  0.1,\n",
              "       -0.3,  0.2,  0.2, -0.2, -0. , -0. ,  0.1,  0.1, -0.3, -0.2, -0.1,\n",
              "       -0.2,  0.1,  0.1,  0.1, -0.1,  0.1, -0.3, -0. ,  0.3, -0. , -0.3,\n",
              "       -0.2, -0.1, -0.2,  0.2,  0.2, -0.3, -0.2,  0.2, -0.2, -0. ,  0.2,\n",
              "       -0. ,  0.1, -0.1, -0. ,  0.4, -0. , -0. ,  0.1,  0.1,  0.3,  0.1,\n",
              "        0.1,  0.1, -0. , -0.1, -0.2,  0.1, -0.2, -0.1,  0.1,  0.1,  0.1,\n",
              "       -0. , -0.1, -0.1], dtype=float32)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYazlfWP-pM-"
      },
      "source": [
        "AlexNet = maxpool lots of layers\n",
        "Vggnet = after alexnet, less intensive convolutions; higher num of params and lower accuracy\n",
        "Resnet = \n",
        "inception = best but lots improve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4oprKOm-pM_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "RNN_4_terminals_memtransistor_sim.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrizZhuang/memtransistor_NLP/blob/main/RNN_4_terminals_memtransistor_sim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "516V8VJij8a7"
      },
      "source": [
        "#**RNN Simulation of Dual gates 4 terminals memtransistor**\n",
        "\n",
        "**Hardware paper**\n",
        "\n",
        "- *Dual-Gated MoS2 Memtransistor Crossbar Array* https://onlinelibrary.wiley.com/doi/abs/10.1002/adfm.202003683\n",
        "\n",
        "**Hardware code with the application of CV**\n",
        "\n",
        "- https://colab.research.google.com/drive/1_zY4qp1u8IZhc_ht4t-iHr2m53j7u2li\n",
        "\n",
        "**RNN Algorithm for text generation**\n",
        "\n",
        "- https://www.tensorflow.org/text/tutorials/text_generation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import modules**"
      ],
      "metadata": {
        "id": "9CaH29FmV9Ny"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU0puRjbltix",
        "outputId": "21419345-796b-4810-d004-3777f3d39e48"
      },
      "source": [
        "# uses tensorflow v2.7.0\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Parse in devise states**\n",
        "! Should include the *learning_curve_vinod.csv* file in the directory"
      ],
      "metadata": {
        "id": "ge3hMlEKWl0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports data from single column CSV file with possible current/conductance states\n",
        "# return numpy array of approximate states possible using this hardware\n",
        "# this import method is not generalized, but fine-tuned to Vinod's devices\n",
        "def import_data_from_csv(filename):\n",
        "  # import data\n",
        "  imported_device_states = np.genfromtxt(filename, delimiter=',')[1:]\n",
        "\n",
        "  # since data is in ~1 nA, assume maximum precision is ~1 pA\n",
        "  # this will make some states redundant\n",
        "  imported_device_states = np.unique(np.round(np.sort(imported_device_states), decimals=3))\n",
        "\n",
        "  # calculate device states possible\n",
        "  device_states = np.array([])\n",
        "  for i, value in enumerate(imported_device_states):\n",
        "      if i+1 > len(imported_device_states):\n",
        "          break\n",
        "      temp_ls = value - imported_device_states\n",
        "      device_states = np.append(device_states, temp_ls)\n",
        "\n",
        "\n",
        "  # normalize to -1 to 1\n",
        "  device_states = np.unique(np.sort(device_states))\n",
        "  device_states = device_states / np.abs(device_states).max()\n",
        "\n",
        "  # given the large number of states, we can assume some states are almost equivalent\n",
        "  # moreover, once the number of states is > 100, the discreteness doesnt matter\n",
        "  # for simplicity in the simulations, we will simply  round to 2 digits of the calculated states\n",
        "  device_states = np.round(device_states, decimals = 2)\n",
        "  device_states = np.unique(np.sort(device_states))\n",
        "  \n",
        "  return device_states"
      ],
      "metadata": {
        "id": "dF6LPUffWji7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Define global constants**"
      ],
      "metadata": {
        "id": "g2qQjpHbYB6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for device\n",
        "DEVICE_STATES = import_data_from_csv('learning_curve_vinod.csv')\n",
        "\n",
        "READ_NOISE_MEAN = 0\n",
        "READ_NOISE_STDDEV = 0.1\n",
        "\n",
        "DEVICE_VARIATION_STDDEV = 0.1\n",
        "\n",
        "DEVICE_STUCK_ON_PROB = 0.1\n",
        "DEVICE_STUCK_OFF_PROB = 0.1"
      ],
      "metadata": {
        "id": "8zTVB2RB7ykk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for RNN model and training\n",
        "NUM_EPOCHS = 100\n",
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "maKGbCyqdSaT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Load and preprocess data**"
      ],
      "metadata": {
        "id": "6g9kc9jaYkkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "dataset, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "HUqmuUPW9LPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a0c1857-a5c8-4287-a289-05e57e48f8d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteA2E7XB/imdb_reviews-train.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteA2E7XB/imdb_reviews-test.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteA2E7XB/imdb_reviews-unsupervised.tfrecord\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data example\n",
        "for example, label in train_dataset.take(1):\n",
        "  print('texts: ', example.numpy()[:3])\n",
        "  print()\n",
        "  print('labels: ', label.numpy()[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUeOH6FIdh4k",
        "outputId": "cbc24d4a-9d02-40ef-b849-d45e4955e68b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texts:  [b\"Ira Levin's Broadway smash comes to the screen with hardly any meat on its bones, a mystery plot with just a few tricks and twists but nobody worth caring about. Frustrated writer Michael Caine plots to steal the work of a brilliant young man and pass it off as his own; his devious plan may include murdering the talented kid, which has Caine's flighty spouse up in arms. The first act in which everyone is introduced is excruciatingly dead, with Caine doing everything an actor can to keep the pacing up. Dyan Cannon is miscast as his wife (she's too smart and clever herself to be passed off as a ditz) and Christopher Reeve (in the middle portion of the film) seems extremely uncomfortable in the role of the better writer. These three characters, and Irene Worth's bothersome neighbor, are so undefined that what happens after the set-up barely even registers until well after the second act has begun. Sidney Lumet's direction is stagy and fuzzy, the set design unconvincing and poorly-lit, and the finale is a total disaster. The actors struggle to give the script some substance, but with such thin material all we see are their laborious efforts. *1/2 from ****\"\n",
            " b'I\\'m not quite sure if the term \"serious comedy\" applies to this movie, Im not even sure if this can be applied. On the last few years movie theaters have become filled with comedy movies which are way too stupid to even make us grin. Therefore, I considered the movies which do not fill these requirements as \"serious comedies\".<br /><br />Does The 40 Year Old Virgin fit into this guild? That is finally up to you, but in my opinion, this is a very funny movie. You get to laugh a lot, plus it delivers a social commentary through some really great characters and situations.<br /><br />I\\'m pretty there is more than one 40 year old virgin out there, and even the people whom do not exactly fit this specifications, may feel identified by one of the characters in the movie, especially men.<br /><br />The story, as the title says it, is about Andy, a shy, silent guy, whom collects action figures, watches Survivor with his octogenarian neighbors and whose favorite band is Asia.<br /><br />Kal is Andy\\'s co-worker at SmartTech. He believes Andy to be a psychopath until Andy\\'s secret is revealed. Kal is clearly a sexual pervert but yet he seems to get what he wants with the opposite genre.<br /><br />David is the passionate guy who is still in love with his ex-girlfriend, whom ran away with another guy. And Jay, a man in a relationship which seems to be affected by his continuous cheating and getting caught acts.<br /><br />I\\'m pretty sure most youngsters from 13 to 21 have already watched this film, but it really does not have an age limit to be able to enjoy it. So in case you haven\\'t seen it and will enjoy a little laugh, with social commentary, than go to your video store and rest from those deep and depressing independent films.<br /><br />It also includes DVD bonuses which you\\'ll really see from top to bottom.'\n",
            " b\"What is interesting is that the acting; was not bad, just not enough. It was rather lame., special effects nor the lines were the single culprit for this failure. Standing alone they weren't horribly bad, but put together was a tragic move. The show seemed long winded and slow with special effects apparently designed to speed the movie along, but it failed totally.<br /><br />Much of the blame for this disaster was put on special effects.Don't believe it, they were kinda cool. Appleby was not the best choice for this endeavor. Though she may have been all they had to chose from with a bit of fan recogniton. An experienced actress would have brought something to the part, like Appleby never did. Scfi puts out some really good original movies, it's just too bad that this failed so drastically.\"]\n",
            "\n",
            "labels:  [0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Create the text encodert**\n",
        "The raw text loaded by `tfds` needs to be processed before it can be used in a model. The simplest way to process text for training is using the `TextVectorization` layer. This layer has many capabilities, but this tutorial sticks to the default behavior.\n",
        "\n",
        "Create the layer, and pass the dataset's text to the layer's `.adapt` method:"
      ],
      "metadata": {
        "id": "G6uGs7QJBlXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 1000\n",
        "# Maximum size of the vocabulary for this layer. \n",
        "# This should only be specified when adapting a vocabulary or when setting pad_to_max_tokens=True. \n",
        "encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE)\n",
        "# adapt: Fits the state of the preprocessing layer to the data being passed.\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))\n",
        "\n",
        "vocab = np.array(encoder.get_vocabulary()) # len(vocab) = 1000 as VOCAB_SIZE = 1000"
      ],
      "metadata": {
        "id": "UWfHnOn_eL-N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Build the model and get the weights**"
      ],
      "metadata": {
        "id": "FX_k02RCebx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "F0dGeMMxANoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dde681c2-6994-4bcf-aa78-f8748675d613"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_1 (TextV  (None, None)             0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 64)          64000     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,249\n",
            "Trainable params: 101,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. keras.layers.preprocessing.index_lookup.VocabWeightHandler\n",
        "# 2. 'embedding/embeddings:0' shape=(1000, 64)\n",
        "# 3. 'lstm/lstm_cell/kernel:0' shape=(64, 256)\n",
        "# 4. 'lstm/lstm_cell/recurrent_kernel:0' shape=(64, 256)\n",
        "# 5. 'lstm/lstm_cell/bias:0' shape=(256,)\n",
        "# 6. 'dense/kernel:0' shape=(64, 64)\n",
        "# 7. 'dense/bias:0' shape=(64,)\n",
        "# 8. 'dense_1/kernel:0' shape=(64, 1)\n",
        "# 9. 'dense_1/bias:0' shape=(1,)\n",
        "weights = model.weights # len(weights) = 9\n",
        "#weights"
      ],
      "metadata": {
        "id": "cdfTljK-eyaO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Gradient update scheme of memtransistor**"
      ],
      "metadata": {
        "id": "jbN1q8lMRJe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_min_value = np.min(np.abs(DEVICE_STATES))\n",
        "g_max_value = np.max(np.abs(DEVICE_STATES))\n",
        "    \n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "  tf.random.set_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "\n",
        "# will create matrix to simulate device-to-device variation by creating clipping the weights\n",
        "# will also simulate devices being stuck-on-open and stuck-on-close \n",
        "def initialize_variation_stuck_mat(shape):\n",
        "  # VARIATION\n",
        "  wp_max = np.ones(shape=shape) - np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape)) # max. is smaller than 1\n",
        "  wp_min = np.zeros(shape=shape) + np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape)) # min. is larger than 0\n",
        "\n",
        "  wm_max = np.ones(shape=shape) - np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape)) # max. is smaller than 1\n",
        "  wm_min = np.zeros(shape=shape) + np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape)) # min. is larger than 0\n",
        "\n",
        "  # STUCK\n",
        "  stuck_prob = [DEVICE_STUCK_OFF_PROB, 1 - DEVICE_STUCK_ON_PROB - DEVICE_STUCK_OFF_PROB, DEVICE_STUCK_ON_PROB]\n",
        "  w_p_stuck = np.random.choice([-1, 0, 1], size=shape, p=stuck_prob) \n",
        "  w_m_stuck = np.random.choice([-1, 0, 1], size=shape, p=stuck_prob)\n",
        "\n",
        "  # if device is stuck OFF\n",
        "  wp_max = wp_max + (w_p_stuck == -1) * (wp_min - wp_max)\n",
        "  wm_max = wm_max + (w_m_stuck == -1) * (wm_min - wm_max)\n",
        "\n",
        "  # if device is stuck ON\n",
        "  wp_min = wp_min + (w_p_stuck == 1) * (wp_max - wp_min)\n",
        "  wm_min = wm_min + (w_m_stuck == 1) * (wm_max - wm_min)\n",
        "\n",
        "\n",
        "  # PUTTING TOGETHER CLIPPING MATRIX\n",
        "  # numpy.clip(a, a_min, a_max) \n",
        "  # Clip (limit) the values in an array.\n",
        "  # Given an interval, values outside the interval are clipped to the interval edges\n",
        "  lower_lim = np.clip(wp_min - wm_max, -g_max_value, -g_min_value)\n",
        "  upper_lim = np.clip(wp_max - wm_min, g_min_value, g_max_value)\n",
        "\n",
        "  #print('Lower lim: ' + str(lower_lim))\n",
        "  #print('Upper lim: ' + str(upper_lim))\n",
        "\n",
        "  return [lower_lim, upper_lim]\n",
        "\n",
        "# weight update with a discrete number of states and (optional) add read noise\n",
        "def discrete_weight_update(value, read_noise_mean=0, read_noise_stddev=0):\n",
        "    if read_noise_stddev != 0:\n",
        "        value += np.random.normal(read_noise_mean, read_noise_stddev)\n",
        "    absolute_difference_function = lambda list_value : abs(list_value - value)\n",
        "    return min(DEVICE_STATES, key=absolute_difference_function)\n",
        "v_discrete_weight_update = np.vectorize(discrete_weight_update)\n",
        "\n",
        "# function puts together all the parts\n",
        "# 1. Device variation\n",
        "# 2. Stuck-on/off \n",
        "# 3. Discrete number of weight states\n",
        "# Input = software weights matrix, Output = hardware weights matrix\n",
        "def simulate_hardware_weight_update(weights_mat, var_stuck_mat):\n",
        "\n",
        "  # initialize variation and stuck matrix if not initialized\n",
        "  if type(var_stuck_mat) is not np.ndarray:\n",
        "      var_stuck_mat = initialize_variation_stuck_mat(weights_mat.shape)\n",
        "\n",
        "  # simulate weight variation and stuck on open/close\n",
        "  weights_mat = weights_mat.clip(var_stuck_mat[0], var_stuck_mat[1])\n",
        "\n",
        "  # simulate discrete states\n",
        "  weights_mat = v_discrete_weight_update(weights_mat, read_noise_mean = READ_NOISE_MEAN,\n",
        "                        read_noise_stddev = READ_NOISE_STDDEV)\n",
        "\n",
        "  return weights_mat"
      ],
      "metadata": {
        "id": "rKCbZ0DeRIxc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Train the model**"
      ],
      "metadata": {
        "id": "FMRkQxBr4QVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Old codes for CV**"
      ],
      "metadata": {
        "id": "YHjCoGUOGfpo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xDlMT8Cjtmj"
      },
      "source": [
        "# need to upgrade to tf 2.7.0\n",
        "\n",
        "def run_MLP_simulation(save_results_input = False,\n",
        "                       num_epochs_input=50, \n",
        "                       hardware_simulation_input=False, \n",
        "                       device_states_input=False,\n",
        "                       read_noise_mean_input=0,\n",
        "                       read_noise_stddev_input=0,\n",
        "                       device_variation_stddev_input=0,\n",
        "                       device_stuck_on_prob_input=0,\n",
        "                       device_stuck_off_prob_input=0):\n",
        "    \n",
        "    \n",
        "    tf.compat.v1.disable_v2_behavior() # disable v2 behavior\n",
        "    \n",
        "    ###################### USER DEFINED PARAMETERS FOR SIMULATION\n",
        "    # whether or not to save results\n",
        "    SAVE_RESULTS = save_results_input\n",
        "    \n",
        "    # number of epochs to test\n",
        "    NUM_EPOCHS = num_epochs_input\n",
        "\n",
        "    # flag which determines whether this is a hardware simulation or purely software\n",
        "    HARDWARE_SIMULATION = hardware_simulation_input\n",
        "\n",
        "    # parameter set by user that gives all the possible normalized weight states\n",
        "    # assumes (1) discrete number of states that are normalized \n",
        "    #         (2) states are set by two synaptic devices such that weight = weight_p - weight_m\n",
        "    #         (3) because of (2), weights can vary from [-1,1]\n",
        "    # user input = a 1D numpy array with values from [-1, 1]\n",
        "    DEVICE_STATES = device_states_input\n",
        "\n",
        "\n",
        "    # parameters for simulating read noise\n",
        "    # user input = read noise mean and standard dev assuming a normal noise function\n",
        "    READ_NOISE_MEAN = read_noise_mean_input\n",
        "    READ_NOISE_STDDEV = read_noise_stddev_input\n",
        "\n",
        "    # parameter for simulating device-to-device variation\n",
        "    # user input =  standard deviation of conductances\n",
        "    DEVICE_VARIATION_STDDEV = device_variation_stddev_input\n",
        "\n",
        "    # parameter for simulating devices that get stuck on Gmax or Gmin states from the start\n",
        "    # user input = probability for a device to get stuck\n",
        "    # What is G?\n",
        "    DEVICE_STUCK_ON_PROB = device_stuck_on_prob_input\n",
        "    DEVICE_STUCK_OFF_PROB = device_stuck_off_prob_input\n",
        "\n",
        "    \n",
        "    \n",
        "    ###################### SIM PARAMETERS\n",
        "    n_inputs = 28*28  # MNIST\n",
        "    n_hidden1 = 300 # neurons in 1st hidden layers\n",
        "    n_outputs = 10 # neurons in output layer\n",
        "    learning_rate = 0.1#0.01 # grad descent\n",
        "    initializer_stddev = 0.2 # standar deviation of initialized random weights\n",
        "    n_epochs = NUM_EPOCHS # number of epochs to test\n",
        "    batch_size = 50 # batch size before tuning weights in grad descent\n",
        "\n",
        "    # What are the possible values of DEVICE_STATES?\n",
        "    g_min_value = np.min(np.abs(DEVICE_STATES))\n",
        "    g_max_value = np.max(np.abs(DEVICE_STATES))\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    ###################### FUNCTIONS\n",
        "\n",
        "    # to make this notebook's output stable across runs\n",
        "    def reset_graph(seed=42):\n",
        "        #tf.reset_default_graph() # Why reset_default_graph()? helpful in testing process?\n",
        "        tf.compat.v1.reset_default_graph\n",
        "        tf.compat.v1.set_random_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    # will create matrix to simulate device-to-device variation by creating clipping the weights\n",
        "    # will also simulate devices being stuck-on-open and stuck-on-close \n",
        "    # What is wp, wm, and how do them relate to g?\n",
        "    def initialize_variation_stuck_mat(shape):\n",
        "\n",
        "        # VARIATION\n",
        "        wp_max = np.ones(shape=shape) - np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape)) # max. is around 1\n",
        "        wp_min = np.zeros(shape=shape) + np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape)) # min. is around 0\n",
        "\n",
        "        wm_max = np.ones(shape=shape) - np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape)) # max. is around 1\n",
        "        wm_min = np.zeros(shape=shape) + np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape)) # min. is around 0\n",
        "\n",
        "        # STUCK\n",
        "        stuck_prob = [DEVICE_STUCK_OFF_PROB, 1 - DEVICE_STUCK_ON_PROB - DEVICE_STUCK_OFF_PROB, DEVICE_STUCK_ON_PROB]\n",
        "        w_p_stuck = np.random.choice([-1, 0, 1], size=shape, p=stuck_prob)\n",
        "        w_m_stuck = np.random.choice([-1, 0, 1], size=shape, p=stuck_prob)\n",
        "\n",
        "        # if device is stuck OFF\n",
        "        wp_max = wp_max + (w_p_stuck == -1) * (wp_min - wp_max)\n",
        "        wm_max = wm_max + (w_m_stuck == -1) * (wm_min - wm_max)\n",
        "\n",
        "        # if device is stuck ON\n",
        "        wp_min = wp_min + (w_p_stuck == 1) * (wp_max - wp_min)\n",
        "        wm_min = wm_min + (w_m_stuck == 1) * (wm_max - wm_min)\n",
        "\n",
        "\n",
        "        # PUTTING TOGETHER CLIPPING MATRIX\n",
        "        lower_lim = np.clip(wp_min - wm_max, -g_max_value, -g_min_value)\n",
        "        upper_lim = np.clip(wp_max - wm_min, g_min_value, g_max_value)\n",
        "\n",
        "        print('Lower lim: ' + str(lower_lim))\n",
        "        print('Upper lim: ' + str(upper_lim))\n",
        "\n",
        "        return [lower_lim, upper_lim]\n",
        "\n",
        "\n",
        "    # weight update with a discrete number of states and (optional) add read noise\n",
        "    def discrete_weight_update(value, read_noise_mean=0, read_noise_stddev=0):\n",
        "        if read_noise_stddev != 0:\n",
        "            value += np.random.normal(read_noise_mean, read_noise_stddev)\n",
        "        absolute_difference_function = lambda list_value : abs(list_value - value)\n",
        "        return min(DEVICE_STATES, key=absolute_difference_function)\n",
        "    v_discrete_weight_update = np.vectorize(discrete_weight_update)\n",
        "\n",
        "\n",
        "\n",
        "    # function puts together all the parts\n",
        "    # 1. Device variation\n",
        "    # 2. Stuck-on/off \n",
        "    # 3. Discrete number of weight states\n",
        "    # Input = software weights matrix, Output = hardware weights matrix\n",
        "    def simulate_hardware_weight_update(weights_mat, var_stuck_mat):\n",
        "\n",
        "        # initialize variation and stuck matrix if not initialized\n",
        "        if type(var_stuck_mat) is not np.ndarray:\n",
        "            var_stuck_mat = initialize_variation_stuck_mat(weights_mat.shape)\n",
        "\n",
        "        # simulate weight variation and stuck on open/close\n",
        "        weights_mat = weights_mat.clip(var_stuck_mat[0], var_stuck_mat[1])\n",
        "\n",
        "        # simulate discrete states\n",
        "        weights_mat = v_discrete_weight_update(weights_mat, read_noise_mean = READ_NOISE_MEAN,\n",
        "                                                 read_noise_stddev = READ_NOISE_STDDEV)\n",
        "\n",
        "        return weights_mat\n",
        "    \n",
        "    \n",
        "    ###################### MLP SIM SETUP\n",
        "    # reset default tf graph before running sim\n",
        "    reset_graph()\n",
        "\n",
        "    # get data, format\n",
        "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "    X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "    y_train = y_train.astype(np.int32)\n",
        "    y_test = y_test.astype(np.int32)\n",
        "    #X_valid, X_train = X_train[:5000], X_train[5000:]\n",
        "    #y_valid, y_train = y_train[:5000], y_train[5000:]\n",
        "\n",
        "\n",
        "    # define input and output placeholder variables\n",
        "    X = tf.compat.v1.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\") # input\n",
        "    y = tf.compat.v1.placeholder(tf.int32, shape=(None), name=\"y\") # output\n",
        "\n",
        "    # define NN layers\n",
        "    # tf.name_scope similar to namespace in C++, so that variable logits -> dnn/logits\n",
        "    with tf.name_scope(\"dnn\"): \n",
        "        initiliazer = tf.truncated_normal_initializer(stddev = initializer_stddev)\n",
        "        hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu, \n",
        "                                  kernel_initializer=initiliazer, bias_initializer=initiliazer)\n",
        "        logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\",\n",
        "                                 kernel_initializer=initiliazer, bias_initializer=initiliazer)\n",
        "        y_proba = tf.nn.softmax(logits)\n",
        "\n",
        "        #embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        #gru = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
        "        #dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # define loss\n",
        "    with tf.name_scope(\"loss\"): \n",
        "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "\n",
        "    # define training\n",
        "    with tf.name_scope(\"train\"):\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "        training_op = optimizer.minimize(loss)\n",
        "\n",
        "    # define recognition rate eval op\n",
        "    with tf.name_scope(\"eval\"):\n",
        "        correct = tf.nn.in_top_k(logits, y, 1)\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "    # define weight update ops\n",
        "    var_stuck_mat = [False, False, False, False]\n",
        "    weights = [0,0,0,0]\n",
        "    new_weights = [0,0,0,0]\n",
        "    weight_update_op = [0,0,0,0]\n",
        "    with tf.name_scope(\"weight_update\"):\n",
        "        weight_layers = [\"hidden1/kernel:0\", \"hidden1/bias:0\", \"outputs/kernel:0\", \"outputs/bias:0\"]\n",
        "        for i, name in enumerate(weight_layers):\n",
        "            weights[i] = [v for v in tf.trainable_variables() if v.name == name][0]\n",
        "            new_weights[i] = tf.placeholder(tf.float32, name=\"new_weights\"+name.replace(\"/\",\"-\").replace(\":\",\"-\"))\n",
        "            weight_update_op[i] = tf.assign(weights[i], new_weights[i])\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    ###################### MLP SIM RUN\n",
        "    epoch_ls = []\n",
        "    recognition_rate_ls = []\n",
        "    start_time = time.time()\n",
        "    start_datetime  = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    weights_before = False\n",
        "    weights_after = False\n",
        "\n",
        "    def shuffle_batch(X, y, batch_size):\n",
        "        rnd_idx = np.random.permutation(len(X)) # permute - 改变序列\n",
        "        n_batches = len(X) // batch_size \n",
        "        for batch_idx in np.array_split(rnd_idx, n_batches): # split rnd_idx into n_batches indexes\n",
        "          X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
        "          yield X_batch, y_batch\n",
        "\n",
        "    with tf.compat.v1.Session() as sess:\n",
        "        init.run()\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "            for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "\n",
        "            if HARDWARE_SIMULATION:\n",
        "                ###### WEIGHT UPDATE  \n",
        "                # simulate hardware by updating weights\n",
        "                # includes discrete number of weight states\n",
        "\n",
        "                # the code below only updates hidden1/kernel:0 weights\n",
        "\n",
        "                # get weights\n",
        "                #weights_temp = [v for v in tf.trainable_variables() if v.name == \"hidden1/bias:0\"][0]\n",
        "                #weights_before = weights_temp.eval(session=sess)\n",
        "\n",
        "\n",
        "                # simulate hardware weight update\n",
        "                #new_weights_mat = simulate_hardware_weight_update(weights_mat, var_stuck_mat)\n",
        "\n",
        "                # update weights to hardware simulated weights\n",
        "\n",
        "                for i, weight in enumerate(weights):\n",
        "\n",
        "                    weight = weight.eval(session=sess)\n",
        "                    # !!! - where memtransistor works\n",
        "                    new_weights_mat = simulate_hardware_weight_update(weight, var_stuck_mat[i]) \n",
        "                    weight_update_op[i].eval(feed_dict={new_weights[i]: new_weights_mat})\n",
        "\n",
        "\n",
        "                ###### end of WEIGHT UPDATE\n",
        "\n",
        "\n",
        "\n",
        "            # test accuracy\n",
        "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "            acc_valid = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "            print(epoch, \"Batch accuracy:\", acc_batch, \"Test accuracy:\", acc_valid)\n",
        "            \n",
        "            # save to list\n",
        "            epoch_ls.append(epoch)\n",
        "            recognition_rate_ls.append(acc_valid)\n",
        "\n",
        "            #weights_temp = [v for v in tf.trainable_variables() if v.name == \"hidden1/bias:0\"][0]\n",
        "            #weights_after = weights_temp.eval(session=sess)    \n",
        "\n",
        "\n",
        "        # save results\n",
        "        if SAVE_RESULTS:\n",
        "            save_path = \"./MLP_sim_results/MLP_sim_\" + start_datetime + \"/model_\" + start_datetime\n",
        "            save_path = saver.save(sess, save_path + \".ckpt\")\n",
        "    \n",
        "    # print out duration\n",
        "    print(\"--- %0.2f seconds ---\" % (time.time() - start_time))\n",
        "    \n",
        "    # save all results, including testing parameters and data\n",
        "    if SAVE_RESULTS:\n",
        "        save_path = \"./MLP_sim_results/MLP_sim_\" + start_datetime + \"/model_\" + start_datetime\n",
        "\n",
        "        data_df = pd.DataFrame({\"Epoch\": epoch_ls, \"Recognition Rate\": recognition_rate_ls})\n",
        "        data_df.to_csv(save_path + \"_data.csv\", index=False,)\n",
        "\n",
        "        with open(save_path + \"_meta.txt\", \"w\") as text_file:\n",
        "            print(\"---------- User input parameters -------------\", file=text_file)\n",
        "            print(\"Simulation start time: {}\".format(start_datetime), file=text_file)\n",
        "            print(\"Duration: {}\".format(time.time() - start_time), file=text_file)\n",
        "            print(\"Epochs: {}\".format(num_epochs_input), file=text_file)\n",
        "            print(\"Hardware simulation?: {}\".format(hardware_simulation_input), file=text_file)\n",
        "            print(\"Read noise - mean: {}\".format(read_noise_mean_input), file=text_file)\n",
        "            print(\"Read noise - standard deviation: {}\".format(read_noise_stddev_input), file=text_file)\n",
        "            print(\"Device variation - standard deviation: {}\".format(device_variation_stddev_input), file=text_file)\n",
        "            print(\"Device stuck on probability: {}\".format(device_stuck_on_prob_input), file=text_file)\n",
        "            print(\"Device stuck off probability: {}\".format(device_stuck_off_prob_input), file=text_file)\n",
        "            print(\"Device states used: {}\".format(device_states_input), file=text_file)\n",
        "\n",
        "            print(\"---------- Simulation parameters -------------\", file=text_file)\n",
        "            print(\"Number of inputs: {}\".format(n_inputs), file=text_file)\n",
        "            print(\"Layers: {}\".format(weight_layers), file=text_file)\n",
        "            print(\"Hidden1 # of neurons: {}\".format(n_hidden1), file=text_file)\n",
        "            print(\"Outputs # of neurons: {}\".format(n_outputs), file=text_file)\n",
        "            print(\"Learning rate: {}\".format(learning_rate), file=text_file)\n",
        "            print(\"Initializer standad dev: {}\".format(initializer_stddev), file=text_file)\n",
        "            print(\"Batch size: {}\".format(batch_size), file=text_file)\n",
        "\n",
        "\n",
        "# imports data from single column CSV file with possible current/conductance states\n",
        "# return numpy array of approximate states possible using this hardware\n",
        "# this import method is not generalized, but fine-tuned to Vinod's devices\n",
        "def import_data_from_csv(filename):\n",
        "    # import data\n",
        "    imported_device_states = np.genfromtxt(filename, delimiter=',')[1:]\n",
        "\n",
        "    # since data is in ~1 nA, assume maximum precision is ~1 pA\n",
        "    # this will make some states redundant\n",
        "    imported_device_states = np.unique(np.round(np.sort(imported_device_states), decimals=3))\n",
        "\n",
        "    # calculate device states possible\n",
        "    device_states = np.array([])\n",
        "    for i, value in enumerate(imported_device_states):\n",
        "        if i+1 > len(imported_device_states):\n",
        "            break\n",
        "        temp_ls = value - imported_device_states\n",
        "        device_states = np.append(device_states, temp_ls)\n",
        "\n",
        "\n",
        "    # normalize to -1 to 1\n",
        "    device_states = np.unique(np.sort(device_states))\n",
        "    device_states = device_states / np.abs(device_states).max()\n",
        "\n",
        "    # given the large number of states, we can assume some states are almost equivalent\n",
        "    # moreover, once the number of states is > 100, the discreteness doesnt matter\n",
        "    # for simplicity in the simulations, we will simply  round to 2 digits of the calculated states\n",
        "    device_states = np.round(device_states, decimals = 2)\n",
        "    device_states = np.unique(np.sort(device_states))\n",
        "    \n",
        "    return device_states\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "u8cD0K-M-pMw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "49a4e272-ebc4-47dc-bfc3-855f893f7309"
      },
      "source": [
        "# mock simulation using np.arange for device states\n",
        "for i in range(5):\n",
        "    run_MLP_simulation(num_epochs_input = 100, \n",
        "                       hardware_simulation_input = False, \n",
        "                       device_states_input = False,\n",
        "                       read_noise_mean_input = 0.0,\n",
        "                       read_noise_stddev_input = 0.0,\n",
        "                       device_variation_stddev_input = 0.0,\n",
        "                       device_stuck_on_prob_input = 0.0,\n",
        "                       device_stuck_off_prob_input = 0.0,\n",
        "                       save_results_input = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f1baf16b8945>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                        \u001b[0mdevice_stuck_on_prob_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                        \u001b[0mdevice_stuck_off_prob_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                        save_results_input = True)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-0e87d7bbeaf8>\u001b[0m in \u001b[0;36mrun_MLP_simulation\u001b[0;34m(save_results_input, num_epochs_input, hardware_simulation_input, device_states_input, read_noise_mean_input, read_noise_stddev_input, device_variation_stddev_input, device_stuck_on_prob_input, device_stuck_off_prob_input)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;31m# define NN layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dnn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0minitiliazer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer_stddev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu, \n\u001b[1;32m    160\u001b[0m                                   kernel_initializer=initiliazer, bias_initializer=initiliazer)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'truncated_normal_initializer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rchKubR2-pMy",
        "outputId": "271df512-103c-4a55-c5e0-d8303c4f4e6f"
      },
      "source": [
        "# run hardware sim 4 times\n",
        "for i in range(4):\n",
        "    imported_device_states = import_data_from_csv(filename='learning_curve_vinod.csv')\n",
        "    run_MLP_simulation(num_epochs_input = 100, \n",
        "                       hardware_simulation_input = True, \n",
        "                       device_states_input = imported_device_states,\n",
        "                       read_noise_mean_input = 0.0,\n",
        "                       read_noise_stddev_input = 0.1,\n",
        "                       device_variation_stddev_input = 0.0,\n",
        "                       device_stuck_on_prob_input = 0.00,\n",
        "                       device_stuck_off_prob_input = 0.00,\n",
        "                       save_results_input = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Batch accuracy: 0.72 Test accuracy: 0.6556\n",
            "1 Batch accuracy: 0.6 Test accuracy: 0.5914\n",
            "2 Batch accuracy: 0.7 Test accuracy: 0.7075\n",
            "3 Batch accuracy: 0.5 Test accuracy: 0.5555\n",
            "4 Batch accuracy: 0.82 Test accuracy: 0.7896\n",
            "5 Batch accuracy: 0.76 Test accuracy: 0.7968\n",
            "6 Batch accuracy: 0.8 Test accuracy: 0.776\n",
            "7 Batch accuracy: 0.82 Test accuracy: 0.7581\n",
            "8 Batch accuracy: 0.9 Test accuracy: 0.8142\n",
            "9 Batch accuracy: 0.6 Test accuracy: 0.6915\n",
            "10 Batch accuracy: 0.78 Test accuracy: 0.8267\n",
            "11 Batch accuracy: 0.9 Test accuracy: 0.8334\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.8398\n",
            "13 Batch accuracy: 0.82 Test accuracy: 0.8183\n",
            "14 Batch accuracy: 0.8 Test accuracy: 0.843\n",
            "15 Batch accuracy: 0.92 Test accuracy: 0.846\n",
            "16 Batch accuracy: 0.78 Test accuracy: 0.826\n",
            "17 Batch accuracy: 0.82 Test accuracy: 0.8299\n",
            "18 Batch accuracy: 0.84 Test accuracy: 0.8476\n",
            "19 Batch accuracy: 0.86 Test accuracy: 0.8514\n",
            "20 Batch accuracy: 0.84 Test accuracy: 0.8119\n",
            "21 Batch accuracy: 0.88 Test accuracy: 0.829\n",
            "22 Batch accuracy: 0.78 Test accuracy: 0.8402\n",
            "23 Batch accuracy: 0.86 Test accuracy: 0.8478\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.8553\n",
            "25 Batch accuracy: 0.76 Test accuracy: 0.8315\n",
            "26 Batch accuracy: 0.88 Test accuracy: 0.8339\n",
            "27 Batch accuracy: 0.88 Test accuracy: 0.8776\n",
            "28 Batch accuracy: 0.84 Test accuracy: 0.8667\n",
            "29 Batch accuracy: 0.86 Test accuracy: 0.8583\n",
            "30 Batch accuracy: 0.86 Test accuracy: 0.874\n",
            "31 Batch accuracy: 0.92 Test accuracy: 0.8726\n",
            "32 Batch accuracy: 0.88 Test accuracy: 0.8804\n",
            "33 Batch accuracy: 0.88 Test accuracy: 0.8656\n",
            "34 Batch accuracy: 0.86 Test accuracy: 0.8395\n",
            "35 Batch accuracy: 0.88 Test accuracy: 0.865\n",
            "36 Batch accuracy: 0.88 Test accuracy: 0.8673\n",
            "37 Batch accuracy: 0.82 Test accuracy: 0.8524\n",
            "38 Batch accuracy: 0.8 Test accuracy: 0.8347\n",
            "39 Batch accuracy: 0.82 Test accuracy: 0.877\n",
            "40 Batch accuracy: 0.92 Test accuracy: 0.8657\n",
            "41 Batch accuracy: 0.82 Test accuracy: 0.881\n",
            "42 Batch accuracy: 0.84 Test accuracy: 0.8589\n",
            "43 Batch accuracy: 0.88 Test accuracy: 0.8753\n",
            "44 Batch accuracy: 0.84 Test accuracy: 0.8859\n",
            "45 Batch accuracy: 0.9 Test accuracy: 0.8712\n",
            "46 Batch accuracy: 0.86 Test accuracy: 0.869\n",
            "47 Batch accuracy: 0.82 Test accuracy: 0.8643\n",
            "48 Batch accuracy: 0.9 Test accuracy: 0.8693\n",
            "49 Batch accuracy: 0.92 Test accuracy: 0.8565\n",
            "50 Batch accuracy: 0.8 Test accuracy: 0.8866\n",
            "51 Batch accuracy: 0.96 Test accuracy: 0.8775\n",
            "52 Batch accuracy: 0.9 Test accuracy: 0.8685\n",
            "53 Batch accuracy: 0.74 Test accuracy: 0.8609\n",
            "54 Batch accuracy: 0.86 Test accuracy: 0.8633\n",
            "55 Batch accuracy: 0.92 Test accuracy: 0.8693\n",
            "56 Batch accuracy: 0.82 Test accuracy: 0.871\n",
            "57 Batch accuracy: 0.9 Test accuracy: 0.881\n",
            "58 Batch accuracy: 0.84 Test accuracy: 0.8849\n",
            "59 Batch accuracy: 0.9 Test accuracy: 0.8547\n",
            "60 Batch accuracy: 0.88 Test accuracy: 0.8763\n",
            "61 Batch accuracy: 0.88 Test accuracy: 0.8825\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.8704\n",
            "63 Batch accuracy: 0.88 Test accuracy: 0.8854\n",
            "64 Batch accuracy: 0.84 Test accuracy: 0.8656\n",
            "65 Batch accuracy: 0.9 Test accuracy: 0.8631\n",
            "66 Batch accuracy: 0.92 Test accuracy: 0.8702\n",
            "67 Batch accuracy: 0.92 Test accuracy: 0.8812\n",
            "68 Batch accuracy: 0.9 Test accuracy: 0.8789\n",
            "69 Batch accuracy: 0.9 Test accuracy: 0.8849\n",
            "70 Batch accuracy: 0.88 Test accuracy: 0.8887\n",
            "71 Batch accuracy: 0.88 Test accuracy: 0.8795\n",
            "72 Batch accuracy: 0.9 Test accuracy: 0.8821\n",
            "73 Batch accuracy: 0.94 Test accuracy: 0.8834\n",
            "74 Batch accuracy: 0.9 Test accuracy: 0.8834\n",
            "75 Batch accuracy: 0.94 Test accuracy: 0.884\n",
            "76 Batch accuracy: 0.92 Test accuracy: 0.8814\n",
            "77 Batch accuracy: 0.9 Test accuracy: 0.8798\n",
            "78 Batch accuracy: 0.92 Test accuracy: 0.8825\n",
            "79 Batch accuracy: 0.92 Test accuracy: 0.886\n",
            "80 Batch accuracy: 0.9 Test accuracy: 0.8741\n",
            "81 Batch accuracy: 0.8 Test accuracy: 0.8845\n",
            "82 Batch accuracy: 0.94 Test accuracy: 0.8958\n",
            "83 Batch accuracy: 0.88 Test accuracy: 0.9004\n",
            "84 Batch accuracy: 0.9 Test accuracy: 0.8872\n",
            "85 Batch accuracy: 0.82 Test accuracy: 0.8762\n",
            "86 Batch accuracy: 0.9 Test accuracy: 0.885\n",
            "87 Batch accuracy: 0.84 Test accuracy: 0.8654\n",
            "88 Batch accuracy: 0.94 Test accuracy: 0.8849\n",
            "89 Batch accuracy: 0.86 Test accuracy: 0.8693\n",
            "90 Batch accuracy: 0.94 Test accuracy: 0.8902\n",
            "91 Batch accuracy: 0.9 Test accuracy: 0.9053\n",
            "92 Batch accuracy: 0.84 Test accuracy: 0.8824\n",
            "93 Batch accuracy: 0.88 Test accuracy: 0.8821\n",
            "94 Batch accuracy: 0.86 Test accuracy: 0.875\n",
            "95 Batch accuracy: 0.98 Test accuracy: 0.8869\n",
            "96 Batch accuracy: 0.92 Test accuracy: 0.8769\n",
            "97 Batch accuracy: 0.82 Test accuracy: 0.8863\n",
            "98 Batch accuracy: 0.88 Test accuracy: 0.8889\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.8792\n",
            "--- 3070.01 seconds ---\n",
            "0 Batch accuracy: 0.72 Test accuracy: 0.6556\n",
            "1 Batch accuracy: 0.6 Test accuracy: 0.5914\n",
            "2 Batch accuracy: 0.7 Test accuracy: 0.7075\n",
            "3 Batch accuracy: 0.5 Test accuracy: 0.5555\n",
            "4 Batch accuracy: 0.82 Test accuracy: 0.7896\n",
            "5 Batch accuracy: 0.76 Test accuracy: 0.7968\n",
            "6 Batch accuracy: 0.8 Test accuracy: 0.776\n",
            "7 Batch accuracy: 0.82 Test accuracy: 0.7581\n",
            "8 Batch accuracy: 0.9 Test accuracy: 0.8142\n",
            "9 Batch accuracy: 0.6 Test accuracy: 0.6915\n",
            "10 Batch accuracy: 0.78 Test accuracy: 0.8267\n",
            "11 Batch accuracy: 0.9 Test accuracy: 0.8334\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.8398\n",
            "13 Batch accuracy: 0.82 Test accuracy: 0.8183\n",
            "14 Batch accuracy: 0.8 Test accuracy: 0.843\n",
            "15 Batch accuracy: 0.92 Test accuracy: 0.846\n",
            "16 Batch accuracy: 0.78 Test accuracy: 0.826\n",
            "17 Batch accuracy: 0.82 Test accuracy: 0.8299\n",
            "18 Batch accuracy: 0.84 Test accuracy: 0.8476\n",
            "19 Batch accuracy: 0.86 Test accuracy: 0.8514\n",
            "20 Batch accuracy: 0.84 Test accuracy: 0.8119\n",
            "21 Batch accuracy: 0.88 Test accuracy: 0.829\n",
            "22 Batch accuracy: 0.78 Test accuracy: 0.8402\n",
            "23 Batch accuracy: 0.86 Test accuracy: 0.8478\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.8553\n",
            "25 Batch accuracy: 0.76 Test accuracy: 0.8315\n",
            "26 Batch accuracy: 0.88 Test accuracy: 0.8339\n",
            "27 Batch accuracy: 0.88 Test accuracy: 0.8776\n",
            "28 Batch accuracy: 0.84 Test accuracy: 0.8667\n",
            "29 Batch accuracy: 0.86 Test accuracy: 0.8583\n",
            "30 Batch accuracy: 0.86 Test accuracy: 0.874\n",
            "31 Batch accuracy: 0.92 Test accuracy: 0.8726\n",
            "32 Batch accuracy: 0.88 Test accuracy: 0.8804\n",
            "33 Batch accuracy: 0.88 Test accuracy: 0.8656\n",
            "34 Batch accuracy: 0.86 Test accuracy: 0.8395\n",
            "35 Batch accuracy: 0.88 Test accuracy: 0.865\n",
            "36 Batch accuracy: 0.88 Test accuracy: 0.8673\n",
            "37 Batch accuracy: 0.82 Test accuracy: 0.8524\n",
            "38 Batch accuracy: 0.8 Test accuracy: 0.8347\n",
            "39 Batch accuracy: 0.82 Test accuracy: 0.877\n",
            "40 Batch accuracy: 0.92 Test accuracy: 0.8657\n",
            "41 Batch accuracy: 0.82 Test accuracy: 0.881\n",
            "42 Batch accuracy: 0.84 Test accuracy: 0.8589\n",
            "43 Batch accuracy: 0.88 Test accuracy: 0.8753\n",
            "44 Batch accuracy: 0.84 Test accuracy: 0.8859\n",
            "45 Batch accuracy: 0.9 Test accuracy: 0.8712\n",
            "46 Batch accuracy: 0.86 Test accuracy: 0.869\n",
            "47 Batch accuracy: 0.82 Test accuracy: 0.8643\n",
            "48 Batch accuracy: 0.9 Test accuracy: 0.8693\n",
            "49 Batch accuracy: 0.92 Test accuracy: 0.8565\n",
            "50 Batch accuracy: 0.8 Test accuracy: 0.8866\n",
            "51 Batch accuracy: 0.96 Test accuracy: 0.8775\n",
            "52 Batch accuracy: 0.9 Test accuracy: 0.8685\n",
            "53 Batch accuracy: 0.74 Test accuracy: 0.8609\n",
            "54 Batch accuracy: 0.86 Test accuracy: 0.8633\n",
            "55 Batch accuracy: 0.92 Test accuracy: 0.8693\n",
            "56 Batch accuracy: 0.82 Test accuracy: 0.871\n",
            "57 Batch accuracy: 0.9 Test accuracy: 0.881\n",
            "58 Batch accuracy: 0.84 Test accuracy: 0.8849\n",
            "59 Batch accuracy: 0.9 Test accuracy: 0.8547\n",
            "60 Batch accuracy: 0.88 Test accuracy: 0.8763\n",
            "61 Batch accuracy: 0.88 Test accuracy: 0.8825\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.8704\n",
            "63 Batch accuracy: 0.88 Test accuracy: 0.8854\n",
            "64 Batch accuracy: 0.84 Test accuracy: 0.8656\n",
            "65 Batch accuracy: 0.9 Test accuracy: 0.8631\n",
            "66 Batch accuracy: 0.92 Test accuracy: 0.8702\n",
            "67 Batch accuracy: 0.92 Test accuracy: 0.8812\n",
            "68 Batch accuracy: 0.9 Test accuracy: 0.8789\n",
            "69 Batch accuracy: 0.9 Test accuracy: 0.8849\n",
            "70 Batch accuracy: 0.88 Test accuracy: 0.8887\n",
            "71 Batch accuracy: 0.88 Test accuracy: 0.8795\n",
            "72 Batch accuracy: 0.9 Test accuracy: 0.8821\n",
            "73 Batch accuracy: 0.94 Test accuracy: 0.8834\n",
            "74 Batch accuracy: 0.9 Test accuracy: 0.8834\n",
            "75 Batch accuracy: 0.94 Test accuracy: 0.884\n",
            "76 Batch accuracy: 0.92 Test accuracy: 0.8814\n",
            "77 Batch accuracy: 0.9 Test accuracy: 0.8798\n",
            "78 Batch accuracy: 0.92 Test accuracy: 0.8825\n",
            "79 Batch accuracy: 0.92 Test accuracy: 0.886\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "80 Batch accuracy: 0.9 Test accuracy: 0.8741\n",
            "81 Batch accuracy: 0.8 Test accuracy: 0.8845\n",
            "82 Batch accuracy: 0.94 Test accuracy: 0.8958\n",
            "83 Batch accuracy: 0.88 Test accuracy: 0.9004\n",
            "84 Batch accuracy: 0.9 Test accuracy: 0.8872\n",
            "85 Batch accuracy: 0.82 Test accuracy: 0.8762\n",
            "86 Batch accuracy: 0.9 Test accuracy: 0.885\n",
            "87 Batch accuracy: 0.84 Test accuracy: 0.8654\n",
            "88 Batch accuracy: 0.94 Test accuracy: 0.8849\n",
            "89 Batch accuracy: 0.86 Test accuracy: 0.8693\n",
            "90 Batch accuracy: 0.94 Test accuracy: 0.8902\n",
            "91 Batch accuracy: 0.9 Test accuracy: 0.9053\n",
            "92 Batch accuracy: 0.84 Test accuracy: 0.8824\n",
            "93 Batch accuracy: 0.88 Test accuracy: 0.8821\n",
            "94 Batch accuracy: 0.86 Test accuracy: 0.875\n",
            "95 Batch accuracy: 0.98 Test accuracy: 0.8869\n",
            "96 Batch accuracy: 0.92 Test accuracy: 0.8769\n",
            "97 Batch accuracy: 0.82 Test accuracy: 0.8863\n",
            "98 Batch accuracy: 0.88 Test accuracy: 0.8889\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.8792\n",
            "--- 3072.75 seconds ---\n",
            "0 Batch accuracy: 0.72 Test accuracy: 0.6556\n",
            "1 Batch accuracy: 0.6 Test accuracy: 0.5914\n",
            "2 Batch accuracy: 0.7 Test accuracy: 0.7075\n",
            "3 Batch accuracy: 0.5 Test accuracy: 0.5555\n",
            "4 Batch accuracy: 0.82 Test accuracy: 0.7896\n",
            "5 Batch accuracy: 0.76 Test accuracy: 0.7968\n",
            "6 Batch accuracy: 0.8 Test accuracy: 0.776\n",
            "7 Batch accuracy: 0.82 Test accuracy: 0.7581\n",
            "8 Batch accuracy: 0.9 Test accuracy: 0.8142\n",
            "9 Batch accuracy: 0.6 Test accuracy: 0.6915\n",
            "10 Batch accuracy: 0.78 Test accuracy: 0.8267\n",
            "11 Batch accuracy: 0.9 Test accuracy: 0.8334\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.8398\n",
            "13 Batch accuracy: 0.82 Test accuracy: 0.8183\n",
            "14 Batch accuracy: 0.8 Test accuracy: 0.843\n",
            "15 Batch accuracy: 0.92 Test accuracy: 0.846\n",
            "16 Batch accuracy: 0.78 Test accuracy: 0.826\n",
            "17 Batch accuracy: 0.82 Test accuracy: 0.8299\n",
            "18 Batch accuracy: 0.84 Test accuracy: 0.8476\n",
            "19 Batch accuracy: 0.86 Test accuracy: 0.8514\n",
            "20 Batch accuracy: 0.84 Test accuracy: 0.8119\n",
            "21 Batch accuracy: 0.88 Test accuracy: 0.829\n",
            "22 Batch accuracy: 0.78 Test accuracy: 0.8402\n",
            "23 Batch accuracy: 0.86 Test accuracy: 0.8478\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.8553\n",
            "25 Batch accuracy: 0.76 Test accuracy: 0.8315\n",
            "26 Batch accuracy: 0.88 Test accuracy: 0.8339\n",
            "27 Batch accuracy: 0.88 Test accuracy: 0.8776\n",
            "28 Batch accuracy: 0.84 Test accuracy: 0.8667\n",
            "29 Batch accuracy: 0.86 Test accuracy: 0.8583\n",
            "30 Batch accuracy: 0.86 Test accuracy: 0.874\n",
            "31 Batch accuracy: 0.92 Test accuracy: 0.8726\n",
            "32 Batch accuracy: 0.88 Test accuracy: 0.8804\n",
            "33 Batch accuracy: 0.88 Test accuracy: 0.8656\n",
            "34 Batch accuracy: 0.86 Test accuracy: 0.8395\n",
            "35 Batch accuracy: 0.88 Test accuracy: 0.865\n",
            "36 Batch accuracy: 0.88 Test accuracy: 0.8673\n",
            "37 Batch accuracy: 0.82 Test accuracy: 0.8524\n",
            "38 Batch accuracy: 0.8 Test accuracy: 0.8347\n",
            "39 Batch accuracy: 0.82 Test accuracy: 0.877\n",
            "40 Batch accuracy: 0.92 Test accuracy: 0.8657\n",
            "41 Batch accuracy: 0.82 Test accuracy: 0.881\n",
            "42 Batch accuracy: 0.84 Test accuracy: 0.8589\n",
            "43 Batch accuracy: 0.88 Test accuracy: 0.8753\n",
            "44 Batch accuracy: 0.84 Test accuracy: 0.8859\n",
            "45 Batch accuracy: 0.9 Test accuracy: 0.8712\n",
            "46 Batch accuracy: 0.86 Test accuracy: 0.869\n",
            "47 Batch accuracy: 0.82 Test accuracy: 0.8643\n",
            "48 Batch accuracy: 0.9 Test accuracy: 0.8693\n",
            "49 Batch accuracy: 0.92 Test accuracy: 0.8565\n",
            "50 Batch accuracy: 0.8 Test accuracy: 0.8866\n",
            "51 Batch accuracy: 0.96 Test accuracy: 0.8775\n",
            "52 Batch accuracy: 0.9 Test accuracy: 0.8685\n",
            "53 Batch accuracy: 0.74 Test accuracy: 0.8609\n",
            "54 Batch accuracy: 0.86 Test accuracy: 0.8633\n",
            "55 Batch accuracy: 0.92 Test accuracy: 0.8693\n",
            "56 Batch accuracy: 0.82 Test accuracy: 0.871\n",
            "57 Batch accuracy: 0.9 Test accuracy: 0.881\n",
            "58 Batch accuracy: 0.84 Test accuracy: 0.8849\n",
            "59 Batch accuracy: 0.9 Test accuracy: 0.8547\n",
            "60 Batch accuracy: 0.88 Test accuracy: 0.8763\n",
            "61 Batch accuracy: 0.88 Test accuracy: 0.8825\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.8704\n",
            "63 Batch accuracy: 0.88 Test accuracy: 0.8854\n",
            "64 Batch accuracy: 0.84 Test accuracy: 0.8656\n",
            "65 Batch accuracy: 0.9 Test accuracy: 0.8631\n",
            "66 Batch accuracy: 0.92 Test accuracy: 0.8702\n",
            "67 Batch accuracy: 0.92 Test accuracy: 0.8812\n",
            "68 Batch accuracy: 0.9 Test accuracy: 0.8789\n",
            "69 Batch accuracy: 0.9 Test accuracy: 0.8849\n",
            "70 Batch accuracy: 0.88 Test accuracy: 0.8887\n",
            "71 Batch accuracy: 0.88 Test accuracy: 0.8795\n",
            "72 Batch accuracy: 0.9 Test accuracy: 0.8821\n",
            "73 Batch accuracy: 0.94 Test accuracy: 0.8834\n",
            "74 Batch accuracy: 0.9 Test accuracy: 0.8834\n",
            "75 Batch accuracy: 0.94 Test accuracy: 0.884\n",
            "76 Batch accuracy: 0.92 Test accuracy: 0.8814\n",
            "77 Batch accuracy: 0.9 Test accuracy: 0.8798\n",
            "78 Batch accuracy: 0.92 Test accuracy: 0.8825\n",
            "79 Batch accuracy: 0.92 Test accuracy: 0.886\n",
            "80 Batch accuracy: 0.9 Test accuracy: 0.8741\n",
            "81 Batch accuracy: 0.8 Test accuracy: 0.8845\n",
            "82 Batch accuracy: 0.94 Test accuracy: 0.8958\n",
            "83 Batch accuracy: 0.88 Test accuracy: 0.9004\n",
            "84 Batch accuracy: 0.9 Test accuracy: 0.8872\n",
            "85 Batch accuracy: 0.82 Test accuracy: 0.8762\n",
            "86 Batch accuracy: 0.9 Test accuracy: 0.885\n",
            "87 Batch accuracy: 0.84 Test accuracy: 0.8654\n",
            "88 Batch accuracy: 0.94 Test accuracy: 0.8849\n",
            "89 Batch accuracy: 0.86 Test accuracy: 0.8693\n",
            "90 Batch accuracy: 0.94 Test accuracy: 0.8902\n",
            "91 Batch accuracy: 0.9 Test accuracy: 0.9053\n",
            "92 Batch accuracy: 0.84 Test accuracy: 0.8824\n",
            "93 Batch accuracy: 0.88 Test accuracy: 0.8821\n",
            "94 Batch accuracy: 0.86 Test accuracy: 0.875\n",
            "95 Batch accuracy: 0.98 Test accuracy: 0.8869\n",
            "96 Batch accuracy: 0.92 Test accuracy: 0.8769\n",
            "97 Batch accuracy: 0.82 Test accuracy: 0.8863\n",
            "98 Batch accuracy: 0.88 Test accuracy: 0.8889\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.8792\n",
            "--- 3070.62 seconds ---\n",
            "0 Batch accuracy: 0.72 Test accuracy: 0.6556\n",
            "1 Batch accuracy: 0.6 Test accuracy: 0.5914\n",
            "2 Batch accuracy: 0.7 Test accuracy: 0.7075\n",
            "3 Batch accuracy: 0.5 Test accuracy: 0.5555\n",
            "4 Batch accuracy: 0.82 Test accuracy: 0.7896\n",
            "5 Batch accuracy: 0.76 Test accuracy: 0.7968\n",
            "6 Batch accuracy: 0.8 Test accuracy: 0.776\n",
            "7 Batch accuracy: 0.82 Test accuracy: 0.7581\n",
            "8 Batch accuracy: 0.9 Test accuracy: 0.8142\n",
            "9 Batch accuracy: 0.6 Test accuracy: 0.6915\n",
            "10 Batch accuracy: 0.78 Test accuracy: 0.8267\n",
            "11 Batch accuracy: 0.9 Test accuracy: 0.8334\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.8398\n",
            "13 Batch accuracy: 0.82 Test accuracy: 0.8183\n",
            "14 Batch accuracy: 0.8 Test accuracy: 0.843\n",
            "15 Batch accuracy: 0.92 Test accuracy: 0.846\n",
            "16 Batch accuracy: 0.78 Test accuracy: 0.826\n",
            "17 Batch accuracy: 0.82 Test accuracy: 0.8299\n",
            "18 Batch accuracy: 0.84 Test accuracy: 0.8476\n",
            "19 Batch accuracy: 0.86 Test accuracy: 0.8514\n",
            "20 Batch accuracy: 0.84 Test accuracy: 0.8119\n",
            "21 Batch accuracy: 0.88 Test accuracy: 0.829\n",
            "22 Batch accuracy: 0.78 Test accuracy: 0.8402\n",
            "23 Batch accuracy: 0.86 Test accuracy: 0.8478\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.8553\n",
            "25 Batch accuracy: 0.76 Test accuracy: 0.8315\n",
            "26 Batch accuracy: 0.88 Test accuracy: 0.8339\n",
            "27 Batch accuracy: 0.88 Test accuracy: 0.8776\n",
            "28 Batch accuracy: 0.84 Test accuracy: 0.8667\n",
            "29 Batch accuracy: 0.86 Test accuracy: 0.8583\n",
            "30 Batch accuracy: 0.86 Test accuracy: 0.874\n",
            "31 Batch accuracy: 0.92 Test accuracy: 0.8726\n",
            "32 Batch accuracy: 0.88 Test accuracy: 0.8804\n",
            "33 Batch accuracy: 0.88 Test accuracy: 0.8656\n",
            "34 Batch accuracy: 0.86 Test accuracy: 0.8395\n",
            "35 Batch accuracy: 0.88 Test accuracy: 0.865\n",
            "36 Batch accuracy: 0.88 Test accuracy: 0.8673\n",
            "37 Batch accuracy: 0.82 Test accuracy: 0.8524\n",
            "38 Batch accuracy: 0.8 Test accuracy: 0.8347\n",
            "39 Batch accuracy: 0.82 Test accuracy: 0.877\n",
            "40 Batch accuracy: 0.92 Test accuracy: 0.8657\n",
            "41 Batch accuracy: 0.82 Test accuracy: 0.881\n",
            "42 Batch accuracy: 0.84 Test accuracy: 0.8589\n",
            "43 Batch accuracy: 0.88 Test accuracy: 0.8753\n",
            "44 Batch accuracy: 0.84 Test accuracy: 0.8859\n",
            "45 Batch accuracy: 0.9 Test accuracy: 0.8712\n",
            "46 Batch accuracy: 0.86 Test accuracy: 0.869\n",
            "47 Batch accuracy: 0.82 Test accuracy: 0.8643\n",
            "48 Batch accuracy: 0.9 Test accuracy: 0.8693\n",
            "49 Batch accuracy: 0.92 Test accuracy: 0.8565\n",
            "50 Batch accuracy: 0.8 Test accuracy: 0.8866\n",
            "51 Batch accuracy: 0.96 Test accuracy: 0.8775\n",
            "52 Batch accuracy: 0.9 Test accuracy: 0.8685\n",
            "53 Batch accuracy: 0.74 Test accuracy: 0.8609\n",
            "54 Batch accuracy: 0.86 Test accuracy: 0.8633\n",
            "55 Batch accuracy: 0.92 Test accuracy: 0.8693\n",
            "56 Batch accuracy: 0.82 Test accuracy: 0.871\n",
            "57 Batch accuracy: 0.9 Test accuracy: 0.881\n",
            "58 Batch accuracy: 0.84 Test accuracy: 0.8849\n",
            "59 Batch accuracy: 0.9 Test accuracy: 0.8547\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60 Batch accuracy: 0.88 Test accuracy: 0.8763\n",
            "61 Batch accuracy: 0.88 Test accuracy: 0.8825\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.8704\n",
            "63 Batch accuracy: 0.88 Test accuracy: 0.8854\n",
            "64 Batch accuracy: 0.84 Test accuracy: 0.8656\n",
            "65 Batch accuracy: 0.9 Test accuracy: 0.8631\n",
            "66 Batch accuracy: 0.92 Test accuracy: 0.8702\n",
            "67 Batch accuracy: 0.92 Test accuracy: 0.8812\n",
            "68 Batch accuracy: 0.9 Test accuracy: 0.8789\n",
            "69 Batch accuracy: 0.9 Test accuracy: 0.8849\n",
            "70 Batch accuracy: 0.88 Test accuracy: 0.8887\n",
            "71 Batch accuracy: 0.88 Test accuracy: 0.8795\n",
            "72 Batch accuracy: 0.9 Test accuracy: 0.8821\n",
            "73 Batch accuracy: 0.94 Test accuracy: 0.8834\n",
            "74 Batch accuracy: 0.9 Test accuracy: 0.8834\n",
            "75 Batch accuracy: 0.94 Test accuracy: 0.884\n",
            "76 Batch accuracy: 0.92 Test accuracy: 0.8814\n",
            "77 Batch accuracy: 0.9 Test accuracy: 0.8798\n",
            "78 Batch accuracy: 0.92 Test accuracy: 0.8825\n",
            "79 Batch accuracy: 0.92 Test accuracy: 0.886\n",
            "80 Batch accuracy: 0.9 Test accuracy: 0.8741\n",
            "81 Batch accuracy: 0.8 Test accuracy: 0.8845\n",
            "82 Batch accuracy: 0.94 Test accuracy: 0.8958\n",
            "83 Batch accuracy: 0.88 Test accuracy: 0.9004\n",
            "84 Batch accuracy: 0.9 Test accuracy: 0.8872\n",
            "85 Batch accuracy: 0.82 Test accuracy: 0.8762\n",
            "86 Batch accuracy: 0.9 Test accuracy: 0.885\n",
            "87 Batch accuracy: 0.84 Test accuracy: 0.8654\n",
            "88 Batch accuracy: 0.94 Test accuracy: 0.8849\n",
            "89 Batch accuracy: 0.86 Test accuracy: 0.8693\n",
            "90 Batch accuracy: 0.94 Test accuracy: 0.8902\n",
            "91 Batch accuracy: 0.9 Test accuracy: 0.9053\n",
            "92 Batch accuracy: 0.84 Test accuracy: 0.8824\n",
            "93 Batch accuracy: 0.88 Test accuracy: 0.8821\n",
            "94 Batch accuracy: 0.86 Test accuracy: 0.875\n",
            "95 Batch accuracy: 0.98 Test accuracy: 0.8869\n",
            "96 Batch accuracy: 0.92 Test accuracy: 0.8769\n",
            "97 Batch accuracy: 0.82 Test accuracy: 0.8863\n",
            "98 Batch accuracy: 0.88 Test accuracy: 0.8889\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.8792\n",
            "--- 3052.23 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U20Mg0qp-pMz",
        "outputId": "d6293b16-3922-4486-c341-8b7d8d5441bd"
      },
      "source": [
        "# run hardware sim 4 times\n",
        "for i in range(4):\n",
        "    imported_device_states = import_data_from_csv(filename='learning_curve_vinod.csv')\n",
        "    run_MLP_simulation(num_epochs_input = 100, \n",
        "                       hardware_simulation_input = True, \n",
        "                       device_states_input = imported_device_states,\n",
        "                       read_noise_mean_input = 0.0,\n",
        "                       read_noise_stddev_input = 0.1,\n",
        "                       device_variation_stddev_input = 0.0,\n",
        "                       device_stuck_on_prob_input = 0.00,\n",
        "                       device_stuck_off_prob_input = 0.00,\n",
        "                       save_results_input = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Batch accuracy: 0.84 Test accuracy: 0.761\n",
            "1 Batch accuracy: 0.86 Test accuracy: 0.8079\n",
            "2 Batch accuracy: 0.88 Test accuracy: 0.8493\n",
            "3 Batch accuracy: 0.84 Test accuracy: 0.823\n",
            "4 Batch accuracy: 0.92 Test accuracy: 0.9038\n",
            "5 Batch accuracy: 0.86 Test accuracy: 0.9098\n",
            "6 Batch accuracy: 0.96 Test accuracy: 0.9185\n",
            "7 Batch accuracy: 0.92 Test accuracy: 0.8956\n",
            "8 Batch accuracy: 0.94 Test accuracy: 0.9088\n",
            "9 Batch accuracy: 0.86 Test accuracy: 0.8886\n",
            "10 Batch accuracy: 0.92 Test accuracy: 0.9233\n",
            "11 Batch accuracy: 0.94 Test accuracy: 0.919\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.917\n",
            "13 Batch accuracy: 0.96 Test accuracy: 0.9239\n",
            "14 Batch accuracy: 0.9 Test accuracy: 0.9272\n",
            "15 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "16 Batch accuracy: 0.94 Test accuracy: 0.9288\n",
            "17 Batch accuracy: 0.96 Test accuracy: 0.9197\n",
            "18 Batch accuracy: 0.9 Test accuracy: 0.9308\n",
            "19 Batch accuracy: 0.88 Test accuracy: 0.9271\n",
            "20 Batch accuracy: 0.96 Test accuracy: 0.9229\n",
            "21 Batch accuracy: 0.92 Test accuracy: 0.9356\n",
            "22 Batch accuracy: 0.94 Test accuracy: 0.9279\n",
            "23 Batch accuracy: 0.96 Test accuracy: 0.9297\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.9353\n",
            "25 Batch accuracy: 0.96 Test accuracy: 0.9387\n",
            "26 Batch accuracy: 1.0 Test accuracy: 0.9218\n",
            "27 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "28 Batch accuracy: 0.94 Test accuracy: 0.9349\n",
            "29 Batch accuracy: 0.96 Test accuracy: 0.9364\n",
            "30 Batch accuracy: 0.98 Test accuracy: 0.9324\n",
            "31 Batch accuracy: 0.94 Test accuracy: 0.935\n",
            "32 Batch accuracy: 1.0 Test accuracy: 0.9399\n",
            "33 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "34 Batch accuracy: 0.98 Test accuracy: 0.935\n",
            "35 Batch accuracy: 0.94 Test accuracy: 0.9466\n",
            "36 Batch accuracy: 0.9 Test accuracy: 0.944\n",
            "37 Batch accuracy: 0.94 Test accuracy: 0.9444\n",
            "38 Batch accuracy: 0.96 Test accuracy: 0.9407\n",
            "39 Batch accuracy: 0.94 Test accuracy: 0.9463\n",
            "40 Batch accuracy: 0.98 Test accuracy: 0.9426\n",
            "41 Batch accuracy: 0.94 Test accuracy: 0.9435\n",
            "42 Batch accuracy: 1.0 Test accuracy: 0.9382\n",
            "43 Batch accuracy: 0.96 Test accuracy: 0.9384\n",
            "44 Batch accuracy: 0.98 Test accuracy: 0.9435\n",
            "45 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "46 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "47 Batch accuracy: 0.94 Test accuracy: 0.9443\n",
            "48 Batch accuracy: 1.0 Test accuracy: 0.9482\n",
            "49 Batch accuracy: 0.96 Test accuracy: 0.9454\n",
            "50 Batch accuracy: 0.98 Test accuracy: 0.9465\n",
            "51 Batch accuracy: 0.98 Test accuracy: 0.946\n",
            "52 Batch accuracy: 0.94 Test accuracy: 0.9357\n",
            "53 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "54 Batch accuracy: 0.98 Test accuracy: 0.9372\n",
            "55 Batch accuracy: 0.96 Test accuracy: 0.9424\n",
            "56 Batch accuracy: 1.0 Test accuracy: 0.9368\n",
            "57 Batch accuracy: 0.94 Test accuracy: 0.9358\n",
            "58 Batch accuracy: 1.0 Test accuracy: 0.9432\n",
            "59 Batch accuracy: 0.96 Test accuracy: 0.9416\n",
            "60 Batch accuracy: 0.9 Test accuracy: 0.9444\n",
            "61 Batch accuracy: 0.98 Test accuracy: 0.9438\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.9366\n",
            "63 Batch accuracy: 0.96 Test accuracy: 0.9392\n",
            "64 Batch accuracy: 0.98 Test accuracy: 0.9374\n",
            "65 Batch accuracy: 0.98 Test accuracy: 0.947\n",
            "66 Batch accuracy: 0.98 Test accuracy: 0.9456\n",
            "67 Batch accuracy: 0.98 Test accuracy: 0.9416\n",
            "68 Batch accuracy: 0.94 Test accuracy: 0.9412\n",
            "69 Batch accuracy: 0.92 Test accuracy: 0.9447\n",
            "70 Batch accuracy: 0.94 Test accuracy: 0.9425\n",
            "71 Batch accuracy: 0.96 Test accuracy: 0.9431\n",
            "72 Batch accuracy: 0.96 Test accuracy: 0.9421\n",
            "73 Batch accuracy: 0.96 Test accuracy: 0.9363\n",
            "74 Batch accuracy: 0.96 Test accuracy: 0.9467\n",
            "75 Batch accuracy: 0.98 Test accuracy: 0.9457\n",
            "76 Batch accuracy: 0.94 Test accuracy: 0.9445\n",
            "77 Batch accuracy: 0.98 Test accuracy: 0.9473\n",
            "78 Batch accuracy: 0.96 Test accuracy: 0.9428\n",
            "79 Batch accuracy: 0.98 Test accuracy: 0.9432\n",
            "80 Batch accuracy: 0.96 Test accuracy: 0.9453\n",
            "81 Batch accuracy: 0.98 Test accuracy: 0.9485\n",
            "82 Batch accuracy: 0.96 Test accuracy: 0.9482\n",
            "83 Batch accuracy: 0.96 Test accuracy: 0.9417\n",
            "84 Batch accuracy: 0.96 Test accuracy: 0.9472\n",
            "85 Batch accuracy: 0.94 Test accuracy: 0.9449\n",
            "86 Batch accuracy: 0.98 Test accuracy: 0.9481\n",
            "87 Batch accuracy: 0.98 Test accuracy: 0.9496\n",
            "88 Batch accuracy: 0.96 Test accuracy: 0.9505\n",
            "89 Batch accuracy: 0.94 Test accuracy: 0.9453\n",
            "90 Batch accuracy: 0.98 Test accuracy: 0.9494\n",
            "91 Batch accuracy: 1.0 Test accuracy: 0.952\n",
            "92 Batch accuracy: 0.96 Test accuracy: 0.9466\n",
            "93 Batch accuracy: 0.94 Test accuracy: 0.9496\n",
            "94 Batch accuracy: 0.94 Test accuracy: 0.944\n",
            "95 Batch accuracy: 1.0 Test accuracy: 0.9475\n",
            "96 Batch accuracy: 0.96 Test accuracy: 0.9516\n",
            "97 Batch accuracy: 0.96 Test accuracy: 0.9425\n",
            "98 Batch accuracy: 0.96 Test accuracy: 0.9457\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.9451\n",
            "--- 3061.78 seconds ---\n",
            "0 Batch accuracy: 0.84 Test accuracy: 0.761\n",
            "1 Batch accuracy: 0.86 Test accuracy: 0.8079\n",
            "2 Batch accuracy: 0.88 Test accuracy: 0.8493\n",
            "3 Batch accuracy: 0.84 Test accuracy: 0.823\n",
            "4 Batch accuracy: 0.92 Test accuracy: 0.9038\n",
            "5 Batch accuracy: 0.86 Test accuracy: 0.9098\n",
            "6 Batch accuracy: 0.96 Test accuracy: 0.9185\n",
            "7 Batch accuracy: 0.92 Test accuracy: 0.8956\n",
            "8 Batch accuracy: 0.94 Test accuracy: 0.9088\n",
            "9 Batch accuracy: 0.86 Test accuracy: 0.8886\n",
            "10 Batch accuracy: 0.92 Test accuracy: 0.9233\n",
            "11 Batch accuracy: 0.94 Test accuracy: 0.919\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.917\n",
            "13 Batch accuracy: 0.96 Test accuracy: 0.9239\n",
            "14 Batch accuracy: 0.9 Test accuracy: 0.9272\n",
            "15 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "16 Batch accuracy: 0.94 Test accuracy: 0.9288\n",
            "17 Batch accuracy: 0.96 Test accuracy: 0.9197\n",
            "18 Batch accuracy: 0.9 Test accuracy: 0.9308\n",
            "19 Batch accuracy: 0.88 Test accuracy: 0.9271\n",
            "20 Batch accuracy: 0.96 Test accuracy: 0.9229\n",
            "21 Batch accuracy: 0.92 Test accuracy: 0.9356\n",
            "22 Batch accuracy: 0.94 Test accuracy: 0.9279\n",
            "23 Batch accuracy: 0.96 Test accuracy: 0.9297\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.9353\n",
            "25 Batch accuracy: 0.96 Test accuracy: 0.9387\n",
            "26 Batch accuracy: 1.0 Test accuracy: 0.9218\n",
            "27 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "28 Batch accuracy: 0.94 Test accuracy: 0.9349\n",
            "29 Batch accuracy: 0.96 Test accuracy: 0.9364\n",
            "30 Batch accuracy: 0.98 Test accuracy: 0.9324\n",
            "31 Batch accuracy: 0.94 Test accuracy: 0.935\n",
            "32 Batch accuracy: 1.0 Test accuracy: 0.9399\n",
            "33 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "34 Batch accuracy: 0.98 Test accuracy: 0.935\n",
            "35 Batch accuracy: 0.94 Test accuracy: 0.9466\n",
            "36 Batch accuracy: 0.9 Test accuracy: 0.944\n",
            "37 Batch accuracy: 0.94 Test accuracy: 0.9444\n",
            "38 Batch accuracy: 0.96 Test accuracy: 0.9407\n",
            "39 Batch accuracy: 0.94 Test accuracy: 0.9463\n",
            "40 Batch accuracy: 0.98 Test accuracy: 0.9426\n",
            "41 Batch accuracy: 0.94 Test accuracy: 0.9435\n",
            "42 Batch accuracy: 1.0 Test accuracy: 0.9382\n",
            "43 Batch accuracy: 0.96 Test accuracy: 0.9384\n",
            "44 Batch accuracy: 0.98 Test accuracy: 0.9435\n",
            "45 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "46 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "47 Batch accuracy: 0.94 Test accuracy: 0.9443\n",
            "48 Batch accuracy: 1.0 Test accuracy: 0.9482\n",
            "49 Batch accuracy: 0.96 Test accuracy: 0.9454\n",
            "50 Batch accuracy: 0.98 Test accuracy: 0.9465\n",
            "51 Batch accuracy: 0.98 Test accuracy: 0.946\n",
            "52 Batch accuracy: 0.94 Test accuracy: 0.9357\n",
            "53 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "54 Batch accuracy: 0.98 Test accuracy: 0.9372\n",
            "55 Batch accuracy: 0.96 Test accuracy: 0.9424\n",
            "56 Batch accuracy: 1.0 Test accuracy: 0.9368\n",
            "57 Batch accuracy: 0.94 Test accuracy: 0.9358\n",
            "58 Batch accuracy: 1.0 Test accuracy: 0.9432\n",
            "59 Batch accuracy: 0.96 Test accuracy: 0.9416\n",
            "60 Batch accuracy: 0.9 Test accuracy: 0.9444\n",
            "61 Batch accuracy: 0.98 Test accuracy: 0.9438\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.9366\n",
            "63 Batch accuracy: 0.96 Test accuracy: 0.9392\n",
            "64 Batch accuracy: 0.98 Test accuracy: 0.9374\n",
            "65 Batch accuracy: 0.98 Test accuracy: 0.947\n",
            "66 Batch accuracy: 0.98 Test accuracy: 0.9456\n",
            "67 Batch accuracy: 0.98 Test accuracy: 0.9416\n",
            "68 Batch accuracy: 0.94 Test accuracy: 0.9412\n",
            "69 Batch accuracy: 0.92 Test accuracy: 0.9447\n",
            "70 Batch accuracy: 0.94 Test accuracy: 0.9425\n",
            "71 Batch accuracy: 0.96 Test accuracy: 0.9431\n",
            "72 Batch accuracy: 0.96 Test accuracy: 0.9421\n",
            "73 Batch accuracy: 0.96 Test accuracy: 0.9363\n",
            "74 Batch accuracy: 0.96 Test accuracy: 0.9467\n",
            "75 Batch accuracy: 0.98 Test accuracy: 0.9457\n",
            "76 Batch accuracy: 0.94 Test accuracy: 0.9445\n",
            "77 Batch accuracy: 0.98 Test accuracy: 0.9473\n",
            "78 Batch accuracy: 0.96 Test accuracy: 0.9428\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79 Batch accuracy: 0.98 Test accuracy: 0.9432\n",
            "80 Batch accuracy: 0.96 Test accuracy: 0.9453\n",
            "81 Batch accuracy: 0.98 Test accuracy: 0.9485\n",
            "82 Batch accuracy: 0.96 Test accuracy: 0.9482\n",
            "83 Batch accuracy: 0.96 Test accuracy: 0.9417\n",
            "84 Batch accuracy: 0.96 Test accuracy: 0.9472\n",
            "85 Batch accuracy: 0.94 Test accuracy: 0.9449\n",
            "86 Batch accuracy: 0.98 Test accuracy: 0.9481\n",
            "87 Batch accuracy: 0.98 Test accuracy: 0.9496\n",
            "88 Batch accuracy: 0.96 Test accuracy: 0.9505\n",
            "89 Batch accuracy: 0.94 Test accuracy: 0.9453\n",
            "90 Batch accuracy: 0.98 Test accuracy: 0.9494\n",
            "91 Batch accuracy: 1.0 Test accuracy: 0.952\n",
            "92 Batch accuracy: 0.96 Test accuracy: 0.9466\n",
            "93 Batch accuracy: 0.94 Test accuracy: 0.9496\n",
            "94 Batch accuracy: 0.94 Test accuracy: 0.944\n",
            "95 Batch accuracy: 1.0 Test accuracy: 0.9475\n",
            "96 Batch accuracy: 0.96 Test accuracy: 0.9516\n",
            "97 Batch accuracy: 0.96 Test accuracy: 0.9425\n",
            "98 Batch accuracy: 0.96 Test accuracy: 0.9457\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.9451\n",
            "--- 3079.70 seconds ---\n",
            "0 Batch accuracy: 0.84 Test accuracy: 0.761\n",
            "1 Batch accuracy: 0.86 Test accuracy: 0.8079\n",
            "2 Batch accuracy: 0.88 Test accuracy: 0.8493\n",
            "3 Batch accuracy: 0.84 Test accuracy: 0.823\n",
            "4 Batch accuracy: 0.92 Test accuracy: 0.9038\n",
            "5 Batch accuracy: 0.86 Test accuracy: 0.9098\n",
            "6 Batch accuracy: 0.96 Test accuracy: 0.9185\n",
            "7 Batch accuracy: 0.92 Test accuracy: 0.8956\n",
            "8 Batch accuracy: 0.94 Test accuracy: 0.9088\n",
            "9 Batch accuracy: 0.86 Test accuracy: 0.8886\n",
            "10 Batch accuracy: 0.92 Test accuracy: 0.9233\n",
            "11 Batch accuracy: 0.94 Test accuracy: 0.919\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.917\n",
            "13 Batch accuracy: 0.96 Test accuracy: 0.9239\n",
            "14 Batch accuracy: 0.9 Test accuracy: 0.9272\n",
            "15 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "16 Batch accuracy: 0.94 Test accuracy: 0.9288\n",
            "17 Batch accuracy: 0.96 Test accuracy: 0.9197\n",
            "18 Batch accuracy: 0.9 Test accuracy: 0.9308\n",
            "19 Batch accuracy: 0.88 Test accuracy: 0.9271\n",
            "20 Batch accuracy: 0.96 Test accuracy: 0.9229\n",
            "21 Batch accuracy: 0.92 Test accuracy: 0.9356\n",
            "22 Batch accuracy: 0.94 Test accuracy: 0.9279\n",
            "23 Batch accuracy: 0.96 Test accuracy: 0.9297\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.9353\n",
            "25 Batch accuracy: 0.96 Test accuracy: 0.9387\n",
            "26 Batch accuracy: 1.0 Test accuracy: 0.9218\n",
            "27 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "28 Batch accuracy: 0.94 Test accuracy: 0.9349\n",
            "29 Batch accuracy: 0.96 Test accuracy: 0.9364\n",
            "30 Batch accuracy: 0.98 Test accuracy: 0.9324\n",
            "31 Batch accuracy: 0.94 Test accuracy: 0.935\n",
            "32 Batch accuracy: 1.0 Test accuracy: 0.9399\n",
            "33 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "34 Batch accuracy: 0.98 Test accuracy: 0.935\n",
            "35 Batch accuracy: 0.94 Test accuracy: 0.9466\n",
            "36 Batch accuracy: 0.9 Test accuracy: 0.944\n",
            "37 Batch accuracy: 0.94 Test accuracy: 0.9444\n",
            "38 Batch accuracy: 0.96 Test accuracy: 0.9407\n",
            "39 Batch accuracy: 0.94 Test accuracy: 0.9463\n",
            "40 Batch accuracy: 0.98 Test accuracy: 0.9426\n",
            "41 Batch accuracy: 0.94 Test accuracy: 0.9435\n",
            "42 Batch accuracy: 1.0 Test accuracy: 0.9382\n",
            "43 Batch accuracy: 0.96 Test accuracy: 0.9384\n",
            "44 Batch accuracy: 0.98 Test accuracy: 0.9435\n",
            "45 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "46 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "47 Batch accuracy: 0.94 Test accuracy: 0.9443\n",
            "48 Batch accuracy: 1.0 Test accuracy: 0.9482\n",
            "49 Batch accuracy: 0.96 Test accuracy: 0.9454\n",
            "50 Batch accuracy: 0.98 Test accuracy: 0.9465\n",
            "51 Batch accuracy: 0.98 Test accuracy: 0.946\n",
            "52 Batch accuracy: 0.94 Test accuracy: 0.9357\n",
            "53 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "54 Batch accuracy: 0.98 Test accuracy: 0.9372\n",
            "55 Batch accuracy: 0.96 Test accuracy: 0.9424\n",
            "56 Batch accuracy: 1.0 Test accuracy: 0.9368\n",
            "57 Batch accuracy: 0.94 Test accuracy: 0.9358\n",
            "58 Batch accuracy: 1.0 Test accuracy: 0.9432\n",
            "59 Batch accuracy: 0.96 Test accuracy: 0.9416\n",
            "60 Batch accuracy: 0.9 Test accuracy: 0.9444\n",
            "61 Batch accuracy: 0.98 Test accuracy: 0.9438\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.9366\n",
            "63 Batch accuracy: 0.96 Test accuracy: 0.9392\n",
            "64 Batch accuracy: 0.98 Test accuracy: 0.9374\n",
            "65 Batch accuracy: 0.98 Test accuracy: 0.947\n",
            "66 Batch accuracy: 0.98 Test accuracy: 0.9456\n",
            "67 Batch accuracy: 0.98 Test accuracy: 0.9416\n",
            "68 Batch accuracy: 0.94 Test accuracy: 0.9412\n",
            "69 Batch accuracy: 0.92 Test accuracy: 0.9447\n",
            "70 Batch accuracy: 0.94 Test accuracy: 0.9425\n",
            "71 Batch accuracy: 0.96 Test accuracy: 0.9431\n",
            "72 Batch accuracy: 0.96 Test accuracy: 0.9421\n",
            "73 Batch accuracy: 0.96 Test accuracy: 0.9363\n",
            "74 Batch accuracy: 0.96 Test accuracy: 0.9467\n",
            "75 Batch accuracy: 0.98 Test accuracy: 0.9457\n",
            "76 Batch accuracy: 0.94 Test accuracy: 0.9445\n",
            "77 Batch accuracy: 0.98 Test accuracy: 0.9473\n",
            "78 Batch accuracy: 0.96 Test accuracy: 0.9428\n",
            "79 Batch accuracy: 0.98 Test accuracy: 0.9432\n",
            "80 Batch accuracy: 0.96 Test accuracy: 0.9453\n",
            "81 Batch accuracy: 0.98 Test accuracy: 0.9485\n",
            "82 Batch accuracy: 0.96 Test accuracy: 0.9482\n",
            "83 Batch accuracy: 0.96 Test accuracy: 0.9417\n",
            "84 Batch accuracy: 0.96 Test accuracy: 0.9472\n",
            "85 Batch accuracy: 0.94 Test accuracy: 0.9449\n",
            "86 Batch accuracy: 0.98 Test accuracy: 0.9481\n",
            "87 Batch accuracy: 0.98 Test accuracy: 0.9496\n",
            "88 Batch accuracy: 0.96 Test accuracy: 0.9505\n",
            "89 Batch accuracy: 0.94 Test accuracy: 0.9453\n",
            "90 Batch accuracy: 0.98 Test accuracy: 0.9494\n",
            "91 Batch accuracy: 1.0 Test accuracy: 0.952\n",
            "92 Batch accuracy: 0.96 Test accuracy: 0.9466\n",
            "93 Batch accuracy: 0.94 Test accuracy: 0.9496\n",
            "94 Batch accuracy: 0.94 Test accuracy: 0.944\n",
            "95 Batch accuracy: 1.0 Test accuracy: 0.9475\n",
            "96 Batch accuracy: 0.96 Test accuracy: 0.9516\n",
            "97 Batch accuracy: 0.96 Test accuracy: 0.9425\n",
            "98 Batch accuracy: 0.96 Test accuracy: 0.9457\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.9451\n",
            "--- 3077.87 seconds ---\n",
            "0 Batch accuracy: 0.84 Test accuracy: 0.761\n",
            "1 Batch accuracy: 0.86 Test accuracy: 0.8079\n",
            "2 Batch accuracy: 0.88 Test accuracy: 0.8493\n",
            "3 Batch accuracy: 0.84 Test accuracy: 0.823\n",
            "4 Batch accuracy: 0.92 Test accuracy: 0.9038\n",
            "5 Batch accuracy: 0.86 Test accuracy: 0.9098\n",
            "6 Batch accuracy: 0.96 Test accuracy: 0.9185\n",
            "7 Batch accuracy: 0.92 Test accuracy: 0.8956\n",
            "8 Batch accuracy: 0.94 Test accuracy: 0.9088\n",
            "9 Batch accuracy: 0.86 Test accuracy: 0.8886\n",
            "10 Batch accuracy: 0.92 Test accuracy: 0.9233\n",
            "11 Batch accuracy: 0.94 Test accuracy: 0.919\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.917\n",
            "13 Batch accuracy: 0.96 Test accuracy: 0.9239\n",
            "14 Batch accuracy: 0.9 Test accuracy: 0.9272\n",
            "15 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "16 Batch accuracy: 0.94 Test accuracy: 0.9288\n",
            "17 Batch accuracy: 0.96 Test accuracy: 0.9197\n",
            "18 Batch accuracy: 0.9 Test accuracy: 0.9308\n",
            "19 Batch accuracy: 0.88 Test accuracy: 0.9271\n",
            "20 Batch accuracy: 0.96 Test accuracy: 0.9229\n",
            "21 Batch accuracy: 0.92 Test accuracy: 0.9356\n",
            "22 Batch accuracy: 0.94 Test accuracy: 0.9279\n",
            "23 Batch accuracy: 0.96 Test accuracy: 0.9297\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.9353\n",
            "25 Batch accuracy: 0.96 Test accuracy: 0.9387\n",
            "26 Batch accuracy: 1.0 Test accuracy: 0.9218\n",
            "27 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "28 Batch accuracy: 0.94 Test accuracy: 0.9349\n",
            "29 Batch accuracy: 0.96 Test accuracy: 0.9364\n",
            "30 Batch accuracy: 0.98 Test accuracy: 0.9324\n",
            "31 Batch accuracy: 0.94 Test accuracy: 0.935\n",
            "32 Batch accuracy: 1.0 Test accuracy: 0.9399\n",
            "33 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "34 Batch accuracy: 0.98 Test accuracy: 0.935\n",
            "35 Batch accuracy: 0.94 Test accuracy: 0.9466\n",
            "36 Batch accuracy: 0.9 Test accuracy: 0.944\n",
            "37 Batch accuracy: 0.94 Test accuracy: 0.9444\n",
            "38 Batch accuracy: 0.96 Test accuracy: 0.9407\n",
            "39 Batch accuracy: 0.94 Test accuracy: 0.9463\n",
            "40 Batch accuracy: 0.98 Test accuracy: 0.9426\n",
            "41 Batch accuracy: 0.94 Test accuracy: 0.9435\n",
            "42 Batch accuracy: 1.0 Test accuracy: 0.9382\n",
            "43 Batch accuracy: 0.96 Test accuracy: 0.9384\n",
            "44 Batch accuracy: 0.98 Test accuracy: 0.9435\n",
            "45 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "46 Batch accuracy: 0.94 Test accuracy: 0.9378\n",
            "47 Batch accuracy: 0.94 Test accuracy: 0.9443\n",
            "48 Batch accuracy: 1.0 Test accuracy: 0.9482\n",
            "49 Batch accuracy: 0.96 Test accuracy: 0.9454\n",
            "50 Batch accuracy: 0.98 Test accuracy: 0.9465\n",
            "51 Batch accuracy: 0.98 Test accuracy: 0.946\n",
            "52 Batch accuracy: 0.94 Test accuracy: 0.9357\n",
            "53 Batch accuracy: 0.94 Test accuracy: 0.9344\n",
            "54 Batch accuracy: 0.98 Test accuracy: 0.9372\n",
            "55 Batch accuracy: 0.96 Test accuracy: 0.9424\n",
            "56 Batch accuracy: 1.0 Test accuracy: 0.9368\n",
            "57 Batch accuracy: 0.94 Test accuracy: 0.9358\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "58 Batch accuracy: 1.0 Test accuracy: 0.9432\n",
            "59 Batch accuracy: 0.96 Test accuracy: 0.9416\n",
            "60 Batch accuracy: 0.9 Test accuracy: 0.9444\n",
            "61 Batch accuracy: 0.98 Test accuracy: 0.9438\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.9366\n",
            "63 Batch accuracy: 0.96 Test accuracy: 0.9392\n",
            "64 Batch accuracy: 0.98 Test accuracy: 0.9374\n",
            "65 Batch accuracy: 0.98 Test accuracy: 0.947\n",
            "66 Batch accuracy: 0.98 Test accuracy: 0.9456\n",
            "67 Batch accuracy: 0.98 Test accuracy: 0.9416\n",
            "68 Batch accuracy: 0.94 Test accuracy: 0.9412\n",
            "69 Batch accuracy: 0.92 Test accuracy: 0.9447\n",
            "70 Batch accuracy: 0.94 Test accuracy: 0.9425\n",
            "71 Batch accuracy: 0.96 Test accuracy: 0.9431\n",
            "72 Batch accuracy: 0.96 Test accuracy: 0.9421\n",
            "73 Batch accuracy: 0.96 Test accuracy: 0.9363\n",
            "74 Batch accuracy: 0.96 Test accuracy: 0.9467\n",
            "75 Batch accuracy: 0.98 Test accuracy: 0.9457\n",
            "76 Batch accuracy: 0.94 Test accuracy: 0.9445\n",
            "77 Batch accuracy: 0.98 Test accuracy: 0.9473\n",
            "78 Batch accuracy: 0.96 Test accuracy: 0.9428\n",
            "79 Batch accuracy: 0.98 Test accuracy: 0.9432\n",
            "80 Batch accuracy: 0.96 Test accuracy: 0.9453\n",
            "81 Batch accuracy: 0.98 Test accuracy: 0.9485\n",
            "82 Batch accuracy: 0.96 Test accuracy: 0.9482\n",
            "83 Batch accuracy: 0.96 Test accuracy: 0.9417\n",
            "84 Batch accuracy: 0.96 Test accuracy: 0.9472\n",
            "85 Batch accuracy: 0.94 Test accuracy: 0.9449\n",
            "86 Batch accuracy: 0.98 Test accuracy: 0.9481\n",
            "87 Batch accuracy: 0.98 Test accuracy: 0.9496\n",
            "88 Batch accuracy: 0.96 Test accuracy: 0.9505\n",
            "89 Batch accuracy: 0.94 Test accuracy: 0.9453\n",
            "90 Batch accuracy: 0.98 Test accuracy: 0.9494\n",
            "91 Batch accuracy: 1.0 Test accuracy: 0.952\n",
            "92 Batch accuracy: 0.96 Test accuracy: 0.9466\n",
            "93 Batch accuracy: 0.94 Test accuracy: 0.9496\n",
            "94 Batch accuracy: 0.94 Test accuracy: 0.944\n",
            "95 Batch accuracy: 1.0 Test accuracy: 0.9475\n",
            "96 Batch accuracy: 0.96 Test accuracy: 0.9516\n",
            "97 Batch accuracy: 0.96 Test accuracy: 0.9425\n",
            "98 Batch accuracy: 0.96 Test accuracy: 0.9457\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.9451\n",
            "--- 3069.41 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "L0Ax4Dbc-pM0",
        "outputId": "cf5f17f7-4f2c-4841-b23a-222d09124c13"
      },
      "source": [
        "imported_device_states = import_data_from_csv(filename='learning_curve_vinod.csv')\n",
        "\n",
        "\n",
        "run_MLP_simulation(num_epochs_input = 100, \n",
        "                   hardware_simulation_input = True, \n",
        "                   device_states_input = imported_device_states,\n",
        "                   read_noise_mean_input = 0.0,\n",
        "                   read_noise_stddev_input = 0.1,\n",
        "                   device_variation_stddev_input = 0.0,\n",
        "                   device_stuck_on_prob_input = 0.00,\n",
        "                   device_stuck_off_prob_input = 0.00,\n",
        "                   save_results_input = True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Batch accuracy: 0.72 Test accuracy: 0.6556\n",
            "1 Batch accuracy: 0.6 Test accuracy: 0.5914\n",
            "2 Batch accuracy: 0.7 Test accuracy: 0.7075\n",
            "3 Batch accuracy: 0.5 Test accuracy: 0.5555\n",
            "4 Batch accuracy: 0.82 Test accuracy: 0.7896\n",
            "5 Batch accuracy: 0.76 Test accuracy: 0.7968\n",
            "6 Batch accuracy: 0.8 Test accuracy: 0.776\n",
            "7 Batch accuracy: 0.82 Test accuracy: 0.7581\n",
            "8 Batch accuracy: 0.9 Test accuracy: 0.8142\n",
            "9 Batch accuracy: 0.6 Test accuracy: 0.6915\n",
            "10 Batch accuracy: 0.78 Test accuracy: 0.8267\n",
            "11 Batch accuracy: 0.9 Test accuracy: 0.8334\n",
            "12 Batch accuracy: 0.84 Test accuracy: 0.8398\n",
            "13 Batch accuracy: 0.82 Test accuracy: 0.8183\n",
            "14 Batch accuracy: 0.8 Test accuracy: 0.843\n",
            "15 Batch accuracy: 0.92 Test accuracy: 0.846\n",
            "16 Batch accuracy: 0.78 Test accuracy: 0.826\n",
            "17 Batch accuracy: 0.82 Test accuracy: 0.8299\n",
            "18 Batch accuracy: 0.84 Test accuracy: 0.8476\n",
            "19 Batch accuracy: 0.86 Test accuracy: 0.8514\n",
            "20 Batch accuracy: 0.84 Test accuracy: 0.8119\n",
            "21 Batch accuracy: 0.88 Test accuracy: 0.829\n",
            "22 Batch accuracy: 0.78 Test accuracy: 0.8402\n",
            "23 Batch accuracy: 0.86 Test accuracy: 0.8478\n",
            "24 Batch accuracy: 0.96 Test accuracy: 0.8553\n",
            "25 Batch accuracy: 0.76 Test accuracy: 0.8315\n",
            "26 Batch accuracy: 0.88 Test accuracy: 0.8339\n",
            "27 Batch accuracy: 0.88 Test accuracy: 0.8776\n",
            "28 Batch accuracy: 0.84 Test accuracy: 0.8667\n",
            "29 Batch accuracy: 0.86 Test accuracy: 0.8583\n",
            "30 Batch accuracy: 0.86 Test accuracy: 0.874\n",
            "31 Batch accuracy: 0.92 Test accuracy: 0.8726\n",
            "32 Batch accuracy: 0.88 Test accuracy: 0.8804\n",
            "33 Batch accuracy: 0.88 Test accuracy: 0.8656\n",
            "34 Batch accuracy: 0.86 Test accuracy: 0.8395\n",
            "35 Batch accuracy: 0.88 Test accuracy: 0.865\n",
            "36 Batch accuracy: 0.88 Test accuracy: 0.8673\n",
            "37 Batch accuracy: 0.82 Test accuracy: 0.8524\n",
            "38 Batch accuracy: 0.8 Test accuracy: 0.8347\n",
            "39 Batch accuracy: 0.82 Test accuracy: 0.877\n",
            "40 Batch accuracy: 0.92 Test accuracy: 0.8657\n",
            "41 Batch accuracy: 0.82 Test accuracy: 0.881\n",
            "42 Batch accuracy: 0.84 Test accuracy: 0.8589\n",
            "43 Batch accuracy: 0.88 Test accuracy: 0.8753\n",
            "44 Batch accuracy: 0.84 Test accuracy: 0.8859\n",
            "45 Batch accuracy: 0.9 Test accuracy: 0.8712\n",
            "46 Batch accuracy: 0.86 Test accuracy: 0.869\n",
            "47 Batch accuracy: 0.82 Test accuracy: 0.8643\n",
            "48 Batch accuracy: 0.9 Test accuracy: 0.8693\n",
            "49 Batch accuracy: 0.92 Test accuracy: 0.8565\n",
            "50 Batch accuracy: 0.8 Test accuracy: 0.8866\n",
            "51 Batch accuracy: 0.96 Test accuracy: 0.8775\n",
            "52 Batch accuracy: 0.9 Test accuracy: 0.8685\n",
            "53 Batch accuracy: 0.74 Test accuracy: 0.8609\n",
            "54 Batch accuracy: 0.86 Test accuracy: 0.8633\n",
            "55 Batch accuracy: 0.92 Test accuracy: 0.8693\n",
            "56 Batch accuracy: 0.82 Test accuracy: 0.871\n",
            "57 Batch accuracy: 0.9 Test accuracy: 0.881\n",
            "58 Batch accuracy: 0.84 Test accuracy: 0.8849\n",
            "59 Batch accuracy: 0.9 Test accuracy: 0.8547\n",
            "60 Batch accuracy: 0.88 Test accuracy: 0.8763\n",
            "61 Batch accuracy: 0.88 Test accuracy: 0.8825\n",
            "62 Batch accuracy: 0.94 Test accuracy: 0.8704\n",
            "63 Batch accuracy: 0.88 Test accuracy: 0.8854\n",
            "64 Batch accuracy: 0.84 Test accuracy: 0.8656\n",
            "65 Batch accuracy: 0.9 Test accuracy: 0.8631\n",
            "66 Batch accuracy: 0.92 Test accuracy: 0.8702\n",
            "67 Batch accuracy: 0.92 Test accuracy: 0.8812\n",
            "68 Batch accuracy: 0.9 Test accuracy: 0.8789\n",
            "69 Batch accuracy: 0.9 Test accuracy: 0.8849\n",
            "70 Batch accuracy: 0.88 Test accuracy: 0.8887\n",
            "71 Batch accuracy: 0.88 Test accuracy: 0.8795\n",
            "72 Batch accuracy: 0.9 Test accuracy: 0.8821\n",
            "73 Batch accuracy: 0.94 Test accuracy: 0.8834\n",
            "74 Batch accuracy: 0.9 Test accuracy: 0.8834\n",
            "75 Batch accuracy: 0.94 Test accuracy: 0.884\n",
            "76 Batch accuracy: 0.92 Test accuracy: 0.8814\n",
            "77 Batch accuracy: 0.9 Test accuracy: 0.8798\n",
            "78 Batch accuracy: 0.92 Test accuracy: 0.8825\n",
            "79 Batch accuracy: 0.92 Test accuracy: 0.886\n",
            "80 Batch accuracy: 0.9 Test accuracy: 0.8741\n",
            "81 Batch accuracy: 0.8 Test accuracy: 0.8845\n",
            "82 Batch accuracy: 0.94 Test accuracy: 0.8958\n",
            "83 Batch accuracy: 0.88 Test accuracy: 0.9004\n",
            "84 Batch accuracy: 0.9 Test accuracy: 0.8872\n",
            "85 Batch accuracy: 0.82 Test accuracy: 0.8762\n",
            "86 Batch accuracy: 0.9 Test accuracy: 0.885\n",
            "87 Batch accuracy: 0.84 Test accuracy: 0.8654\n",
            "88 Batch accuracy: 0.94 Test accuracy: 0.8849\n",
            "89 Batch accuracy: 0.86 Test accuracy: 0.8693\n",
            "90 Batch accuracy: 0.94 Test accuracy: 0.8902\n",
            "91 Batch accuracy: 0.9 Test accuracy: 0.9053\n",
            "92 Batch accuracy: 0.84 Test accuracy: 0.8824\n",
            "93 Batch accuracy: 0.88 Test accuracy: 0.8821\n",
            "94 Batch accuracy: 0.86 Test accuracy: 0.875\n",
            "95 Batch accuracy: 0.98 Test accuracy: 0.8869\n",
            "96 Batch accuracy: 0.92 Test accuracy: 0.8769\n",
            "97 Batch accuracy: 0.82 Test accuracy: 0.8863\n",
            "98 Batch accuracy: 0.88 Test accuracy: 0.8889\n",
            "99 Batch accuracy: 0.94 Test accuracy: 0.8792\n",
            "--- 3071.88 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_rXVNJjl-pM1",
        "outputId": "bd466399-4c62-4e9d-80fe-c636bad5968a"
      },
      "source": [
        "# mock simulation using np.arange for device states\n",
        "run_MLP_simulation(num_epochs_input = 100, \n",
        "                   hardware_simulation_input = False, \n",
        "                   device_states_input = False,\n",
        "                   read_noise_mean_input = 0.0,\n",
        "                   read_noise_stddev_input = 0.0,\n",
        "                   device_variation_stddev_input = 0.0,\n",
        "                   device_stuck_on_prob_input = 0.0,\n",
        "                   device_stuck_off_prob_input = 0.0,\n",
        "                   save_results_input = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Batch accuracy: 0.88 Test accuracy: 0.8849\n",
            "1 Batch accuracy: 0.86 Test accuracy: 0.9082\n",
            "2 Batch accuracy: 0.92 Test accuracy: 0.9206\n",
            "3 Batch accuracy: 0.96 Test accuracy: 0.9269\n",
            "4 Batch accuracy: 1.0 Test accuracy: 0.9298\n",
            "5 Batch accuracy: 0.98 Test accuracy: 0.9327\n",
            "6 Batch accuracy: 0.96 Test accuracy: 0.9368\n",
            "7 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
            "8 Batch accuracy: 0.96 Test accuracy: 0.944\n",
            "9 Batch accuracy: 0.98 Test accuracy: 0.9456\n",
            "10 Batch accuracy: 0.98 Test accuracy: 0.9467\n",
            "11 Batch accuracy: 0.9 Test accuracy: 0.9497\n",
            "12 Batch accuracy: 0.92 Test accuracy: 0.9499\n",
            "13 Batch accuracy: 0.98 Test accuracy: 0.9533\n",
            "14 Batch accuracy: 0.94 Test accuracy: 0.9533\n",
            "15 Batch accuracy: 0.94 Test accuracy: 0.9553\n",
            "16 Batch accuracy: 1.0 Test accuracy: 0.9558\n",
            "17 Batch accuracy: 0.94 Test accuracy: 0.9566\n",
            "18 Batch accuracy: 0.98 Test accuracy: 0.9581\n",
            "19 Batch accuracy: 0.96 Test accuracy: 0.9574\n",
            "20 Batch accuracy: 0.96 Test accuracy: 0.9579\n",
            "21 Batch accuracy: 0.98 Test accuracy: 0.9595\n",
            "22 Batch accuracy: 0.94 Test accuracy: 0.9607\n",
            "23 Batch accuracy: 0.98 Test accuracy: 0.9607\n",
            "24 Batch accuracy: 0.98 Test accuracy: 0.961\n",
            "25 Batch accuracy: 0.98 Test accuracy: 0.9612\n",
            "26 Batch accuracy: 1.0 Test accuracy: 0.9623\n",
            "27 Batch accuracy: 1.0 Test accuracy: 0.9628\n",
            "28 Batch accuracy: 1.0 Test accuracy: 0.9622\n",
            "29 Batch accuracy: 0.98 Test accuracy: 0.9632\n",
            "30 Batch accuracy: 0.98 Test accuracy: 0.9636\n",
            "31 Batch accuracy: 1.0 Test accuracy: 0.9625\n",
            "32 Batch accuracy: 0.92 Test accuracy: 0.9637\n",
            "33 Batch accuracy: 0.96 Test accuracy: 0.9652\n",
            "34 Batch accuracy: 0.96 Test accuracy: 0.9635\n",
            "35 Batch accuracy: 0.96 Test accuracy: 0.9637\n",
            "36 Batch accuracy: 0.98 Test accuracy: 0.9655\n",
            "37 Batch accuracy: 1.0 Test accuracy: 0.9656\n",
            "38 Batch accuracy: 1.0 Test accuracy: 0.9662\n",
            "39 Batch accuracy: 0.98 Test accuracy: 0.9666\n",
            "40 Batch accuracy: 1.0 Test accuracy: 0.966\n",
            "41 Batch accuracy: 0.98 Test accuracy: 0.9665\n",
            "42 Batch accuracy: 0.96 Test accuracy: 0.9666\n",
            "43 Batch accuracy: 0.98 Test accuracy: 0.9681\n",
            "44 Batch accuracy: 1.0 Test accuracy: 0.9677\n",
            "45 Batch accuracy: 0.98 Test accuracy: 0.9666\n",
            "46 Batch accuracy: 0.96 Test accuracy: 0.9675\n",
            "47 Batch accuracy: 1.0 Test accuracy: 0.9675\n",
            "48 Batch accuracy: 1.0 Test accuracy: 0.9682\n",
            "49 Batch accuracy: 1.0 Test accuracy: 0.9683\n",
            "50 Batch accuracy: 0.98 Test accuracy: 0.9678\n",
            "51 Batch accuracy: 0.96 Test accuracy: 0.968\n",
            "52 Batch accuracy: 0.98 Test accuracy: 0.9683\n",
            "53 Batch accuracy: 1.0 Test accuracy: 0.9681\n",
            "54 Batch accuracy: 1.0 Test accuracy: 0.9697\n",
            "55 Batch accuracy: 0.98 Test accuracy: 0.9691\n",
            "56 Batch accuracy: 1.0 Test accuracy: 0.9692\n",
            "57 Batch accuracy: 1.0 Test accuracy: 0.9697\n",
            "58 Batch accuracy: 0.98 Test accuracy: 0.9706\n",
            "59 Batch accuracy: 0.98 Test accuracy: 0.9696\n",
            "60 Batch accuracy: 0.98 Test accuracy: 0.9705\n",
            "61 Batch accuracy: 1.0 Test accuracy: 0.971\n",
            "62 Batch accuracy: 0.98 Test accuracy: 0.9707\n",
            "63 Batch accuracy: 1.0 Test accuracy: 0.97\n",
            "64 Batch accuracy: 1.0 Test accuracy: 0.9703\n",
            "65 Batch accuracy: 1.0 Test accuracy: 0.9712\n",
            "66 Batch accuracy: 1.0 Test accuracy: 0.972\n",
            "67 Batch accuracy: 0.98 Test accuracy: 0.9716\n",
            "68 Batch accuracy: 1.0 Test accuracy: 0.9721\n",
            "69 Batch accuracy: 1.0 Test accuracy: 0.9718\n",
            "70 Batch accuracy: 1.0 Test accuracy: 0.9716\n",
            "71 Batch accuracy: 1.0 Test accuracy: 0.9714\n",
            "72 Batch accuracy: 1.0 Test accuracy: 0.9721\n",
            "73 Batch accuracy: 1.0 Test accuracy: 0.9718\n",
            "74 Batch accuracy: 0.98 Test accuracy: 0.9717\n",
            "75 Batch accuracy: 0.98 Test accuracy: 0.9722\n",
            "76 Batch accuracy: 1.0 Test accuracy: 0.9725\n",
            "77 Batch accuracy: 1.0 Test accuracy: 0.9724\n",
            "78 Batch accuracy: 1.0 Test accuracy: 0.972\n",
            "79 Batch accuracy: 1.0 Test accuracy: 0.9727\n",
            "80 Batch accuracy: 1.0 Test accuracy: 0.9715\n",
            "81 Batch accuracy: 1.0 Test accuracy: 0.9727\n",
            "82 Batch accuracy: 1.0 Test accuracy: 0.9725\n",
            "83 Batch accuracy: 0.98 Test accuracy: 0.9722\n",
            "84 Batch accuracy: 1.0 Test accuracy: 0.973\n",
            "85 Batch accuracy: 0.98 Test accuracy: 0.9727\n",
            "86 Batch accuracy: 1.0 Test accuracy: 0.9723\n",
            "87 Batch accuracy: 1.0 Test accuracy: 0.9724\n",
            "88 Batch accuracy: 1.0 Test accuracy: 0.9728\n",
            "89 Batch accuracy: 0.98 Test accuracy: 0.9729\n",
            "90 Batch accuracy: 1.0 Test accuracy: 0.9728\n",
            "91 Batch accuracy: 1.0 Test accuracy: 0.9727\n",
            "92 Batch accuracy: 1.0 Test accuracy: 0.9727\n",
            "93 Batch accuracy: 1.0 Test accuracy: 0.9733\n",
            "94 Batch accuracy: 1.0 Test accuracy: 0.9722\n",
            "95 Batch accuracy: 1.0 Test accuracy: 0.9734\n",
            "96 Batch accuracy: 1.0 Test accuracy: 0.9734\n",
            "97 Batch accuracy: 1.0 Test accuracy: 0.9724\n",
            "98 Batch accuracy: 1.0 Test accuracy: 0.9724\n",
            "99 Batch accuracy: 1.0 Test accuracy: 0.973\n",
            "--- 254.00 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bm4RZf9-pM2"
      },
      "source": [
        "# Results\n",
        "\n",
        "## software only (~2 mins , 10 sec)\n",
        "- Learning rate = 0.01\n",
        "0 Batch accuracy: 0.88 Test accuracy: 0.8849\n",
        "1 Batch accuracy: 0.86 Test accuracy: 0.9082\n",
        "2 Batch accuracy: 0.92 Test accuracy: 0.9206\n",
        "3 Batch accuracy: 0.96 Test accuracy: 0.9269\n",
        "4 Batch accuracy: 1.0 Test accuracy: 0.9298\n",
        "5 Batch accuracy: 0.98 Test accuracy: 0.9327\n",
        "6 Batch accuracy: 0.96 Test accuracy: 0.9368\n",
        "7 Batch accuracy: 0.96 Test accuracy: 0.9404\n",
        "8 Batch accuracy: 0.96 Test accuracy: 0.944\n",
        "9 Batch accuracy: 0.98 Test accuracy: 0.9456\n",
        "10 Batch accuracy: 0.98 Test accuracy: 0.9467\n",
        "11 Batch accuracy: 0.9 Test accuracy: 0.9497\n",
        "12 Batch accuracy: 0.92 Test accuracy: 0.9499\n",
        "13 Batch accuracy: 0.98 Test accuracy: 0.9533\n",
        "14 Batch accuracy: 0.94 Test accuracy: 0.9533\n",
        "15 Batch accuracy: 0.94 Test accuracy: 0.9553\n",
        "16 Batch accuracy: 1.0 Test accuracy: 0.9558\n",
        "17 Batch accuracy: 0.94 Test accuracy: 0.9566\n",
        "18 Batch accuracy: 0.98 Test accuracy: 0.9581\n",
        "19 Batch accuracy: 0.96 Test accuracy: 0.9574\n",
        "20 Batch accuracy: 0.96 Test accuracy: 0.9579\n",
        "21 Batch accuracy: 0.98 Test accuracy: 0.9595\n",
        "22 Batch accuracy: 0.94 Test accuracy: 0.9607\n",
        "23 Batch accuracy: 0.98 Test accuracy: 0.9607\n",
        "24 Batch accuracy: 0.98 Test accuracy: 0.961\n",
        "25 Batch accuracy: 0.98 Test accuracy: 0.9612\n",
        "26 Batch accuracy: 1.0 Test accuracy: 0.9623\n",
        "27 Batch accuracy: 1.0 Test accuracy: 0.9628\n",
        "28 Batch accuracy: 1.0 Test accuracy: 0.9622\n",
        "29 Batch accuracy: 0.98 Test accuracy: 0.9632\n",
        "30 Batch accuracy: 0.98 Test accuracy: 0.9636\n",
        "31 Batch accuracy: 1.0 Test accuracy: 0.9625\n",
        "32 Batch accuracy: 0.92 Test accuracy: 0.9637\n",
        "33 Batch accuracy: 0.96 Test accuracy: 0.9652\n",
        "34 Batch accuracy: 0.96 Test accuracy: 0.9635\n",
        "35 Batch accuracy: 0.96 Test accuracy: 0.9637\n",
        "36 Batch accuracy: 0.98 Test accuracy: 0.9655\n",
        "37 Batch accuracy: 1.0 Test accuracy: 0.9656\n",
        "38 Batch accuracy: 1.0 Test accuracy: 0.9662\n",
        "39 Batch accuracy: 0.98 Test accuracy: 0.9666\n",
        "40 Batch accuracy: 1.0 Test accuracy: 0.966\n",
        "41 Batch accuracy: 0.98 Test accuracy: 0.9665\n",
        "42 Batch accuracy: 0.96 Test accuracy: 0.9666\n",
        "43 Batch accuracy: 0.98 Test accuracy: 0.9681\n",
        "44 Batch accuracy: 1.0 Test accuracy: 0.9677\n",
        "45 Batch accuracy: 0.98 Test accuracy: 0.9666\n",
        "46 Batch accuracy: 0.96 Test accuracy: 0.9675\n",
        "47 Batch accuracy: 1.0 Test accuracy: 0.9675\n",
        "48 Batch accuracy: 1.0 Test accuracy: 0.9682\n",
        "49 Batch accuracy: 1.0 Test accuracy: 0.9683\n",
        "--- 140.81 seconds ---\n",
        "\n",
        "## software only (~30 secs)\n",
        "- Learning rate = 0.1\n",
        "0 Batch accuracy: 0.94 Test accuracy: 0.9427\n",
        "1 Batch accuracy: 0.98 Test accuracy: 0.9556\n",
        "2 Batch accuracy: 0.98 Test accuracy: 0.9635\n",
        "3 Batch accuracy: 1.0 Test accuracy: 0.9665\n",
        "4 Batch accuracy: 1.0 Test accuracy: 0.965\n",
        "5 Batch accuracy: 1.0 Test accuracy: 0.9678\n",
        "6 Batch accuracy: 1.0 Test accuracy: 0.9699\n",
        "7 Batch accuracy: 1.0 Test accuracy: 0.9722\n",
        "8 Batch accuracy: 1.0 Test accuracy: 0.9727\n",
        "9 Batch accuracy: 1.0 Test accuracy: 0.9718\n",
        "10 Batch accuracy: 1.0 Test accuracy: 0.9746\n",
        "11 Batch accuracy: 0.98 Test accuracy: 0.9745\n",
        "12 Batch accuracy: 1.0 Test accuracy: 0.9765\n",
        "13 Batch accuracy: 1.0 Test accuracy: 0.9765\n",
        "14 Batch accuracy: 1.0 Test accuracy: 0.9762\n",
        "15 Batch accuracy: 1.0 Test accuracy: 0.9753\n",
        "16 Batch accuracy: 1.0 Test accuracy: 0.9754\n",
        "17 Batch accuracy: 1.0 Test accuracy: 0.977\n",
        "18 Batch accuracy: 1.0 Test accuracy: 0.9756\n",
        "19 Batch accuracy: 1.0 Test accuracy: 0.9768\n",
        "20 Batch accuracy: 1.0 Test accuracy: 0.977\n",
        "\n",
        "## hardware ON, but just discrete states (20) (~2 min, 13 s)\n",
        "0 Batch accuracy: 0.92 Test accuracy: 0.933\n",
        "1 Batch accuracy: 0.92 Test accuracy: 0.938\n",
        "2 Batch accuracy: 0.94 Test accuracy: 0.9418\n",
        "3 Batch accuracy: 0.98 Test accuracy: 0.9431\n",
        "4 Batch accuracy: 0.94 Test accuracy: 0.942\n",
        "5 Batch accuracy: 0.96 Test accuracy: 0.9401\n",
        "6 Batch accuracy: 0.92 Test accuracy: 0.9405\n",
        "7 Batch accuracy: 0.96 Test accuracy: 0.9417\n",
        "8 Batch accuracy: 0.92 Test accuracy: 0.9422\n",
        "9 Batch accuracy: 0.96 Test accuracy: 0.9402\n",
        "10 Batch accuracy: 1.0 Test accuracy: 0.9405\n",
        "11 Batch accuracy: 0.92 Test accuracy: 0.9405\n",
        "12 Batch accuracy: 0.96 Test accuracy: 0.9416\n",
        "13 Batch accuracy: 0.94 Test accuracy: 0.9415\n",
        "14 Batch accuracy: 0.98 Test accuracy: 0.9417\n",
        "15 Batch accuracy: 0.98 Test accuracy: 0.9415\n",
        "16 Batch accuracy: 0.96 Test accuracy: 0.9422\n",
        "17 Batch accuracy: 0.96 Test accuracy: 0.9422\n",
        "18 Batch accuracy: 0.88 Test accuracy: 0.9425\n",
        "19 Batch accuracy: 0.98 Test accuracy: 0.942\n",
        "\n",
        "## hardware ON, but just discrete states (100) ( min,  s)\n",
        "0 Batch accuracy: 0.94 Test accuracy: 0.941\n",
        "1 Batch accuracy: 0.96 Test accuracy: 0.9539\n",
        "2 Batch accuracy: 0.98 Test accuracy: 0.9604\n",
        "3 Batch accuracy: 1.0 Test accuracy: 0.9651\n",
        "4 Batch accuracy: 1.0 Test accuracy: 0.9664\n",
        "5 Batch accuracy: 1.0 Test accuracy: 0.9679\n",
        "6 Batch accuracy: 0.98 Test accuracy: 0.9671\n",
        "7 Batch accuracy: 1.0 Test accuracy: 0.971\n",
        "8 Batch accuracy: 0.98 Test accuracy: 0.9705\n",
        "9 Batch accuracy: 1.0 Test accuracy: 0.9709\n",
        "10 Batch accuracy: 1.0 Test accuracy: 0.9711\n",
        "11 Batch accuracy: 0.98 Test accuracy: 0.971\n",
        "12 Batch accuracy: 1.0 Test accuracy: 0.9704\n",
        "13 Batch accuracy: 0.98 Test accuracy: 0.9706\n",
        "14 Batch accuracy: 1.0 Test accuracy: 0.9729\n",
        "15 Batch accuracy: 1.0 Test accuracy: 0.9724\n",
        "16 Batch accuracy: 1.0 Test accuracy: 0.9736\n",
        "\n",
        "## hardware ON with... (1 min 11s)\n",
        "- 20 states\n",
        "- readnoise = 0.0 +/- 0.2\n",
        "- stuckon = stuckoff = 0.05\n",
        "- device_var = 0.1\n",
        "0 Batch accuracy: 0.4 Test accuracy: 0.3264\n",
        "1 Batch accuracy: 0.44 Test accuracy: 0.4225\n",
        "2 Batch accuracy: 0.52 Test accuracy: 0.4578\n",
        "3 Batch accuracy: 0.52 Test accuracy: 0.4802\n",
        "4 Batch accuracy: 0.64 Test accuracy: 0.6497\n",
        "5 Batch accuracy: 0.58 Test accuracy: 0.6118\n",
        "6 Batch accuracy: 0.46 Test accuracy: 0.551\n",
        "7 Batch accuracy: 0.52 Test accuracy: 0.5524\n",
        "--- 71.81 seconds ---\n",
        "\n",
        "## hardware ON with... (1 min 3s)\n",
        "- 20 states\n",
        "- readnoise = 0.0 +/- 0.05\n",
        "- stuckon = stuckoff = 0.05\n",
        "- device_var = 0.1\n",
        "0 Batch accuracy: 0.88 Test accuracy: 0.8143\n",
        "1 Batch accuracy: 0.94 Test accuracy: 0.8872\n",
        "2 Batch accuracy: 0.92 Test accuracy: 0.8669\n",
        "3 Batch accuracy: 0.78 Test accuracy: 0.8651\n",
        "4 Batch accuracy: 0.96 Test accuracy: 0.8995\n",
        "5 Batch accuracy: 0.9 Test accuracy: 0.9091\n",
        "6 Batch accuracy: 0.92 Test accuracy: 0.8873\n",
        "7 Batch accuracy: 0.88 Test accuracy: 0.8694\n",
        "--- 63.78 seconds ---\n",
        "\n",
        "\n",
        "## hardware ON with... (17 mins)\n",
        "- 100 states\n",
        "- readnoise = 0.0 +/- 0.05\n",
        "- stuckon = stuckoff = 0.05\n",
        "- device_var = 0.1\n",
        "0 Batch accuracy: 0.86 Test accuracy: 0.8376\n",
        "1 Batch accuracy: 0.96 Test accuracy: 0.8902\n",
        "2 Batch accuracy: 0.94 Test accuracy: 0.8869\n",
        "3 Batch accuracy: 0.9 Test accuracy: 0.8921\n",
        "4 Batch accuracy: 0.94 Test accuracy: 0.9196\n",
        "5 Batch accuracy: 0.9 Test accuracy: 0.9166\n",
        "6 Batch accuracy: 0.94 Test accuracy: 0.9174\n",
        "7 Batch accuracy: 0.88 Test accuracy: 0.9134\n",
        "8 Batch accuracy: 0.88 Test accuracy: 0.884\n",
        "9 Batch accuracy: 0.88 Test accuracy: 0.9095\n",
        "10 Batch accuracy: 0.92 Test accuracy: 0.913\n",
        "11 Batch accuracy: 0.86 Test accuracy: 0.909\n",
        "12 Batch accuracy: 0.94 Test accuracy: 0.9265\n",
        "13 Batch accuracy: 0.9 Test accuracy: 0.901\n",
        "14 Batch accuracy: 0.92 Test accuracy: 0.9157\n",
        "15 Batch accuracy: 0.92 Test accuracy: 0.8996\n",
        "16 Batch accuracy: 0.9 Test accuracy: 0.9165\n",
        "17 Batch accuracy: 0.92 Test accuracy: 0.917\n",
        "18 Batch accuracy: 0.96 Test accuracy: 0.926\n",
        "19 Batch accuracy: 0.94 Test accuracy: 0.9229\n",
        "20 Batch accuracy: 0.98 Test accuracy: 0.9061\n",
        "21 Batch accuracy: 0.94 Test accuracy: 0.9252\n",
        "22 Batch accuracy: 0.92 Test accuracy: 0.9188\n",
        "23 Batch accuracy: 0.96 Test accuracy: 0.9229\n",
        "24 Batch accuracy: 0.94 Test accuracy: 0.9326\n",
        "25 Batch accuracy: 0.96 Test accuracy: 0.9163\n",
        "26 Batch accuracy: 0.94 Test accuracy: 0.923\n",
        "27 Batch accuracy: 0.92 Test accuracy: 0.9222\n",
        "28 Batch accuracy: 0.94 Test accuracy: 0.926\n",
        "29 Batch accuracy: 0.98 Test accuracy: 0.9132\n",
        "30 Batch accuracy: 0.96 Test accuracy: 0.9141\n",
        "31 Batch accuracy: 0.94 Test accuracy: 0.9229\n",
        "32 Batch accuracy: 0.88 Test accuracy: 0.9223\n",
        "33 Batch accuracy: 0.9 Test accuracy: 0.8704\n",
        "34 Batch accuracy: 0.9 Test accuracy: 0.9216\n",
        "35 Batch accuracy: 0.92 Test accuracy: 0.9069\n",
        "36 Batch accuracy: 0.94 Test accuracy: 0.9095\n",
        "37 Batch accuracy: 0.92 Test accuracy: 0.9306\n",
        "38 Batch accuracy: 0.9 Test accuracy: 0.9147\n",
        "39 Batch accuracy: 0.94 Test accuracy: 0.9339\n",
        "40 Batch accuracy: 0.96 Test accuracy: 0.9148\n",
        "41 Batch accuracy: 0.96 Test accuracy: 0.8807\n",
        "42 Batch accuracy: 0.92 Test accuracy: 0.8752\n",
        "43 Batch accuracy: 0.92 Test accuracy: 0.9108\n",
        "44 Batch accuracy: 0.92 Test accuracy: 0.9234\n",
        "45 Batch accuracy: 0.94 Test accuracy: 0.9276\n",
        "46 Batch accuracy: 0.94 Test accuracy: 0.9113\n",
        "47 Batch accuracy: 0.9 Test accuracy: 0.914\n",
        "48 Batch accuracy: 0.98 Test accuracy: 0.9277\n",
        "49 Batch accuracy: 0.9 Test accuracy: 0.9335\n",
        "--- 995.70 seconds ---\n",
        "\n",
        "## hardware ON with... (14 mins)\n",
        "- 100 states\n",
        "- readnoise = 0.0 +/- 0.00\n",
        "- stuckon = stuckoff = 0.05\n",
        "- device_var = 0.1\n",
        "\n",
        "0 Batch accuracy: 0.92 Test accuracy: 0.9238\n",
        "1 Batch accuracy: 0.92 Test accuracy: 0.9367\n",
        "2 Batch accuracy: 0.96 Test accuracy: 0.9368\n",
        "3 Batch accuracy: 0.96 Test accuracy: 0.9459\n",
        "4 Batch accuracy: 0.98 Test accuracy: 0.9495\n",
        "5 Batch accuracy: 0.98 Test accuracy: 0.9565\n",
        "6 Batch accuracy: 0.9 Test accuracy: 0.9342\n",
        "7 Batch accuracy: 0.98 Test accuracy: 0.9486\n",
        "8 Batch accuracy: 0.96 Test accuracy: 0.9432\n",
        "9 Batch accuracy: 0.96 Test accuracy: 0.948\n",
        "10 Batch accuracy: 1.0 Test accuracy: 0.9513\n",
        "11 Batch accuracy: 0.94 Test accuracy: 0.9572\n",
        "12 Batch accuracy: 1.0 Test accuracy: 0.9436\n",
        "13 Batch accuracy: 0.92 Test accuracy: 0.9293\n",
        "14 Batch accuracy: 0.96 Test accuracy: 0.9586\n",
        "15 Batch accuracy: 1.0 Test accuracy: 0.9583\n",
        "16 Batch accuracy: 0.98 Test accuracy: 0.9644\n",
        "17 Batch accuracy: 1.0 Test accuracy: 0.9469\n",
        "18 Batch accuracy: 0.9 Test accuracy: 0.9589\n",
        "19 Batch accuracy: 0.98 Test accuracy: 0.9617\n",
        "20 Batch accuracy: 0.96 Test accuracy: 0.9519\n",
        "21 Batch accuracy: 0.94 Test accuracy: 0.9536\n",
        "22 Batch accuracy: 0.96 Test accuracy: 0.9654\n",
        "23 Batch accuracy: 0.98 Test accuracy: 0.9594\n",
        "24 Batch accuracy: 0.98 Test accuracy: 0.9655\n",
        "25 Batch accuracy: 1.0 Test accuracy: 0.9624\n",
        "26 Batch accuracy: 0.96 Test accuracy: 0.9626\n",
        "27 Batch accuracy: 1.0 Test accuracy: 0.958\n",
        "28 Batch accuracy: 1.0 Test accuracy: 0.9532\n",
        "29 Batch accuracy: 1.0 Test accuracy: 0.9704\n",
        "30 Batch accuracy: 0.98 Test accuracy: 0.9576\n",
        "31 Batch accuracy: 1.0 Test accuracy: 0.9594\n",
        "32 Batch accuracy: 0.98 Test accuracy: 0.9676\n",
        "33 Batch accuracy: 1.0 Test accuracy: 0.9568\n",
        "34 Batch accuracy: 1.0 Test accuracy: 0.97\n",
        "35 Batch accuracy: 0.98 Test accuracy: 0.9625\n",
        "36 Batch accuracy: 1.0 Test accuracy: 0.9638\n",
        "37 Batch accuracy: 0.98 Test accuracy: 0.9559\n",
        "38 Batch accuracy: 1.0 Test accuracy: 0.9564\n",
        "39 Batch accuracy: 0.98 Test accuracy: 0.9416\n",
        "40 Batch accuracy: 0.98 Test accuracy: 0.9536\n",
        "41 Batch accuracy: 0.98 Test accuracy: 0.9669\n",
        "42 Batch accuracy: 0.96 Test accuracy: 0.9723\n",
        "43 Batch accuracy: 0.94 Test accuracy: 0.9654\n",
        "44 Batch accuracy: 0.96 Test accuracy: 0.9631\n",
        "45 Batch accuracy: 0.98 Test accuracy: 0.9669\n",
        "46 Batch accuracy: 1.0 Test accuracy: 0.9717\n",
        "47 Batch accuracy: 0.94 Test accuracy: 0.9653\n",
        "48 Batch accuracy: 0.92 Test accuracy: 0.9347\n",
        "49 Batch accuracy: 1.0 Test accuracy: 0.9634\n",
        "--- 875.17 seconds ---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx1-XYLt-pM6",
        "outputId": "b20ae610-bbdd-4b1e-e64d-3ff635256a0b"
      },
      "source": [
        "weights_before"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.00363304, -0.16495076, -0.00245212, -0.07429077, -0.0231128 ,\n",
              "       -0.34697148,  0.3885961 ,  0.30065742,  0.22381195, -0.0381159 ,\n",
              "        0.00310417,  0.08535535,  0.17385383,  0.30208942,  0.125374  ,\n",
              "        0.00897076,  0.07525111, -0.29270896, -0.18102363,  0.06648245,\n",
              "       -0.01434219, -0.12452476, -0.23496754,  0.24518795, -0.03454113,\n",
              "        0.09062955,  0.05114428, -0.01170656,  0.31281415,  0.05068856,\n",
              "       -0.07658286, -0.3558821 , -0.02831533,  0.29215947, -0.01215394,\n",
              "        0.05968314,  0.26844263,  0.34673175,  0.00499299,  0.01214231,\n",
              "       -0.26232064, -0.18391348, -0.30076265,  0.08745792,  0.04777403,\n",
              "       -0.30305094,  0.33885407, -0.22074407, -0.01648456,  0.14930668,\n",
              "       -0.10613731, -0.15380175,  0.04764128,  0.1736799 , -0.05961963,\n",
              "       -0.23478894, -0.18598206, -0.05220306, -0.03114807,  0.04526016,\n",
              "       -0.13837756,  0.17210205, -0.11568228, -0.06414939, -0.07839669,\n",
              "       -0.31229424, -0.2896966 ,  0.03144627, -0.03642305, -0.16567579,\n",
              "       -0.00267657,  0.17316784,  0.00085319, -0.09679439, -0.02308435,\n",
              "        0.16394866,  0.01165754,  0.05500915,  0.41136825, -0.05219844,\n",
              "        0.2085114 , -0.07541733, -0.1070393 , -0.01492016,  0.08076164,\n",
              "        0.19692856,  0.13495956, -0.38460404, -0.04849344, -0.08398602,\n",
              "        0.14246887, -0.21932591,  0.06827202, -0.2051726 , -0.17666604,\n",
              "       -0.05961052, -0.10623793, -0.0255966 ,  0.13482282, -0.17893608,\n",
              "        0.09000875, -0.07414095, -0.00147178, -0.3673266 ,  0.08518526,\n",
              "       -0.3438186 , -0.08230692,  0.21740241,  0.13392316, -0.09173317,\n",
              "        0.34868085,  0.06192811,  0.2656322 ,  0.05334428,  0.14007658,\n",
              "        0.2281066 , -0.3195803 ,  0.18029472, -0.19715586, -0.02840302,\n",
              "        0.13200265,  0.1640659 ,  0.08478154,  0.07364658, -0.3171663 ,\n",
              "       -0.11999371,  0.3375892 , -0.00573255, -0.21645758, -0.1885861 ,\n",
              "        0.06762656,  0.218657  ,  0.04552095,  0.3021214 , -0.3293409 ,\n",
              "        0.09390545,  0.15122677, -0.14340286, -0.2328385 , -0.271851  ,\n",
              "        0.11863299,  0.1443909 , -0.32996917, -0.03591542, -0.04326014,\n",
              "        0.07065223, -0.01636403,  0.10281464,  0.05116272,  0.33759323,\n",
              "        0.11180329, -0.27110025,  0.22969015,  0.14410236, -0.30995998,\n",
              "        0.16053978,  0.03548114,  0.17458898,  0.08910751, -0.38312206,\n",
              "        0.20420177, -0.05197211, -0.03291531,  0.20131718, -0.30613896,\n",
              "        0.03595546, -0.12058713,  0.0586332 , -0.11217057,  0.19694291,\n",
              "       -0.17973398, -0.14652523, -0.02917453,  0.26436493, -0.06099458,\n",
              "       -0.11913513, -0.2629287 , -0.19920772, -0.17564017,  0.17017403,\n",
              "       -0.01270065, -0.18048352, -0.16957238,  0.16083811, -0.17279983,\n",
              "       -0.07432749, -0.14277601,  0.30492598,  0.03528479, -0.23299056,\n",
              "       -0.22208396,  0.04902112, -0.09590512,  0.14306852,  0.19182707,\n",
              "       -0.19023907, -0.00794895, -0.12115265, -0.16815071, -0.05340749,\n",
              "       -0.21926986,  0.01095075,  0.0968822 , -0.29020125, -0.02158891,\n",
              "       -0.10390481, -0.20072246,  0.26937482, -0.06449796,  0.08901459,\n",
              "       -0.2591222 ,  0.02090825, -0.02636197, -0.03075243,  0.12408592,\n",
              "       -0.3049613 , -0.13866909,  0.28398675,  0.05102077,  0.01707341,\n",
              "        0.09695832,  0.15275683,  0.02451089, -0.15840153,  0.05042589,\n",
              "       -0.24000023,  0.03005715, -0.2378383 ,  0.10830259,  0.0710686 ,\n",
              "       -0.01086262, -0.00347498,  0.0264352 ,  0.07423522,  0.29181156,\n",
              "       -0.1386595 ,  0.2349203 , -0.0437406 ,  0.19554102,  0.14396428,\n",
              "        0.09926233,  0.07350031, -0.33096662,  0.22308242,  0.17690367,\n",
              "       -0.20106262,  0.00483929, -0.0394629 ,  0.09772117,  0.13834712,\n",
              "       -0.31102046, -0.17354865, -0.12152156, -0.16103064,  0.13679971,\n",
              "        0.07532874,  0.11013555, -0.12267293,  0.09924937, -0.34042314,\n",
              "        0.02201365,  0.27052307,  0.04294404, -0.25432816, -0.19746897,\n",
              "       -0.13402449, -0.23749909,  0.19029996,  0.19579083, -0.26166064,\n",
              "       -0.15412852,  0.17491113, -0.1651232 ,  0.02764448,  0.20055656,\n",
              "       -0.01854535,  0.05692549, -0.08943276,  0.03881437,  0.4106647 ,\n",
              "        0.04369108,  0.03399525,  0.11422517,  0.06415461,  0.3406343 ,\n",
              "        0.0845423 ,  0.05388894,  0.05470451,  0.04703617, -0.09848036,\n",
              "       -0.15698525,  0.07941221, -0.17882024, -0.05065073,  0.05850855,\n",
              "        0.1418438 ,  0.09312636,  0.01073388, -0.05722875, -0.08071069],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "beo9Hh2B-pM9",
        "outputId": "085d09b7-9336-4ba5-ed17-8fcd42374fc2"
      },
      "source": [
        "weights_after"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0. , -0.2, -0. , -0.1, -0. , -0.3,  0.4,  0.3,  0.2, -0. , -0. ,\n",
              "        0.1,  0.2,  0.3,  0.1, -0. ,  0.1, -0.3, -0.2,  0.1, -0. , -0.1,\n",
              "       -0.2,  0.2, -0. ,  0.1,  0.1, -0. ,  0.3,  0.1, -0.1, -0.4, -0. ,\n",
              "        0.3, -0. ,  0.1,  0.3,  0.3, -0. , -0. , -0.3, -0.2, -0.3,  0.1,\n",
              "       -0. , -0.3,  0.3, -0.2, -0. ,  0.1, -0.1, -0.2, -0. ,  0.2, -0.1,\n",
              "       -0.2, -0.2, -0.1, -0. , -0. , -0.1,  0.2, -0.1, -0.1, -0.1, -0.3,\n",
              "       -0.3, -0. , -0. , -0.2, -0. ,  0.2, -0. , -0.1, -0. ,  0.2, -0. ,\n",
              "        0.1,  0.4, -0.1,  0.2, -0.1, -0.1, -0. ,  0.1,  0.2,  0.1, -0.4,\n",
              "       -0. , -0.1,  0.1, -0.2,  0.1, -0.2, -0.2, -0.1, -0.1, -0. ,  0.1,\n",
              "       -0.2,  0.1, -0.1, -0. , -0.4,  0.1, -0.3, -0.1,  0.2,  0.1, -0.1,\n",
              "        0.3,  0.1,  0.3,  0.1,  0.1,  0.2, -0.3,  0.2, -0.2, -0. ,  0.1,\n",
              "        0.2,  0.1,  0.1, -0.3, -0.1,  0.3, -0. , -0.2, -0.2,  0.1,  0.2,\n",
              "       -0. ,  0.3, -0.3,  0.1,  0.2, -0.1, -0.2, -0.3,  0.1,  0.1, -0.3,\n",
              "       -0. , -0. ,  0.1, -0. ,  0.1,  0.1,  0.3,  0.1, -0.3,  0.2,  0.1,\n",
              "       -0.3,  0.2, -0. ,  0.2,  0.1, -0.4,  0.2, -0.1, -0. ,  0.2, -0.3,\n",
              "       -0. , -0.1,  0.1, -0.1,  0.2, -0.2, -0.1, -0. ,  0.3, -0.1, -0.1,\n",
              "       -0.3, -0.2, -0.2,  0.2, -0. , -0.2, -0.2,  0.2, -0.2, -0.1, -0.1,\n",
              "        0.3, -0. , -0.2, -0.2, -0. , -0.1,  0.1,  0.2, -0.2, -0. , -0.1,\n",
              "       -0.2, -0.1, -0.2, -0. ,  0.1, -0.3, -0. , -0.1, -0.2,  0.3, -0.1,\n",
              "        0.1, -0.3, -0. , -0. , -0. ,  0.1, -0.3, -0.1,  0.3,  0.1, -0. ,\n",
              "        0.1,  0.2, -0. , -0.2,  0.1, -0.2, -0. , -0.2,  0.1,  0.1, -0. ,\n",
              "       -0. , -0. ,  0.1,  0.3, -0.1,  0.2, -0. ,  0.2,  0.1,  0.1,  0.1,\n",
              "       -0.3,  0.2,  0.2, -0.2, -0. , -0. ,  0.1,  0.1, -0.3, -0.2, -0.1,\n",
              "       -0.2,  0.1,  0.1,  0.1, -0.1,  0.1, -0.3, -0. ,  0.3, -0. , -0.3,\n",
              "       -0.2, -0.1, -0.2,  0.2,  0.2, -0.3, -0.2,  0.2, -0.2, -0. ,  0.2,\n",
              "       -0. ,  0.1, -0.1, -0. ,  0.4, -0. , -0. ,  0.1,  0.1,  0.3,  0.1,\n",
              "        0.1,  0.1, -0. , -0.1, -0.2,  0.1, -0.2, -0.1,  0.1,  0.1,  0.1,\n",
              "       -0. , -0.1, -0.1], dtype=float32)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYazlfWP-pM-"
      },
      "source": [
        "AlexNet = maxpool lots of layers\n",
        "Vggnet = after alexnet, less intensive convolutions; higher num of params and lower accuracy\n",
        "Resnet = \n",
        "inception = best but lots improve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4oprKOm-pM_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
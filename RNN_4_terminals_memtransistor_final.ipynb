{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "RNN_4_terminals_memtransistor_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrizZhuang/memtransistor_NLP/blob/main/RNN_4_terminals_memtransistor_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "516V8VJij8a7"
      },
      "source": [
        "#**RNN Simulation of Dual gates 4 terminals memtransistor**\n",
        "\n",
        "**Hardware paper**\n",
        "\n",
        "- *Dual-Gated MoS2 Memtransistor Crossbar Array* https://onlinelibrary.wiley.com/doi/abs/10.1002/adfm.202003683\n",
        "\n",
        "**Hardware code with the application of CV**\n",
        "\n",
        "- https://colab.research.google.com/drive/1_zY4qp1u8IZhc_ht4t-iHr2m53j7u2li\n",
        "\n",
        "**RNN Algorithm for sentiment analysis**\n",
        "\n",
        "- https://www.tensorflow.org/text/tutorials/text_classification_rnn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import modules**"
      ],
      "metadata": {
        "id": "9CaH29FmV9Ny"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU0puRjbltix",
        "outputId": "15764594-0f43-482b-9899-6da65ad9312d"
      },
      "source": [
        "# uses tensorflow v2.7.0\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount to google drive to save model and weights\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "48op3hCFP7VL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce5a42eb-25a5-478b-d1a7-39232c5b1ee5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Utils**\n"
      ],
      "metadata": {
        "id": "ge3hMlEKWl0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports data from single column CSV file with possible current/conductance states\n",
        "# return numpy array of approximate states possible using this hardware\n",
        "# this import method is not generalized, but fine-tuned to Vinod's devices\n",
        "def import_data_from_csv(filename):\n",
        "  # import data\n",
        "  imported_device_states = np.genfromtxt(filename, delimiter=',')[1:]\n",
        "\n",
        "  # since data is in ~1 nA, assume maximum precision is ~1 pA\n",
        "  # this will make some states redundant\n",
        "  imported_device_states = np.unique(np.round(np.sort(imported_device_states), decimals=3))\n",
        "\n",
        "  # calculate device states possible\n",
        "  device_states = np.array([])\n",
        "  for i, value in enumerate(imported_device_states):\n",
        "      if i+1 > len(imported_device_states):\n",
        "          break\n",
        "      temp_ls = value - imported_device_states\n",
        "      device_states = np.append(device_states, temp_ls)\n",
        "\n",
        "\n",
        "  # normalize to -1 to 1\n",
        "  device_states = np.unique(np.sort(device_states))\n",
        "  device_states = device_states / np.abs(device_states).max()\n",
        "\n",
        "  # given the large number of states, we can assume some states are almost equivalent\n",
        "  # moreover, once the number of states is > 100, the discreteness doesnt matter\n",
        "  # for simplicity in the simulations, we will simply  round to 2 digits of the calculated states\n",
        "  device_states = np.round(device_states, decimals = 2)\n",
        "  device_states = np.unique(np.sort(device_states))\n",
        "  \n",
        "  return device_states"
      ],
      "metadata": {
        "id": "dF6LPUffWji7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_figure(train_accuracy, test_accuracy):\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(np.arange(len(train_accuracy)), train_accuracy, label = 'train')\n",
        "  plt.plot(np.arange(len(test_accuracy)), test_accuracy, label = 'test')\n",
        "  plt.legend(fontsize=15)\n",
        "  plt.xticks(fontsize=15)\n",
        "  plt.yticks(fontsize=15)\n",
        "  plt.xlabel(\"epoch\", fontsize=15)\n",
        "  plt.ylabel(\"accuracy\", fontsize=15)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "R-Yvlvzsjna_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Construct the final function**"
      ],
      "metadata": {
        "id": "BVNxiqxPj8st"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_RNN_simulation(save_results_input=False,\n",
        "            num_epochs_input=50, \n",
        "            hardware_simulation_input=False, \n",
        "            device_states_input=False,\n",
        "            read_noise_mean_input=0,\n",
        "            read_noise_stddev_input=0,\n",
        "            device_variation_stddev_input=0,\n",
        "            device_stuck_on_prob_input=0,\n",
        "            device_stuck_off_prob_input=0,\n",
        "            plot_fig=True):\n",
        "  \n",
        "  ###################### USER DEFINED PARAMETERS FOR SIMULATION\n",
        "  # whether or not to save results\n",
        "  SAVE_RESULTS = save_results_input\n",
        "  \n",
        "  # number of epochs to test\n",
        "  NUM_EPOCHS = num_epochs_input\n",
        "\n",
        "  # flag which determines whether this is a hardware simulation or purely software\n",
        "  HARDWARE_SIMULATION = hardware_simulation_input\n",
        "\n",
        "  # parameter set by user that gives all the possible normalized weight states\n",
        "  DEVICE_STATES = device_states_input\n",
        "\n",
        "  # parameters for simulating read noise\n",
        "  # user input = read noise mean and standard dev assuming a normal noise function\n",
        "  READ_NOISE_MEAN = read_noise_mean_input\n",
        "  READ_NOISE_STDDEV = read_noise_stddev_input\n",
        "\n",
        "  # parameter for simulating device-to-device variation\n",
        "  # user input =  standard deviation of conductances\n",
        "  DEVICE_VARIATION_STDDEV = device_variation_stddev_input\n",
        "\n",
        "  # parameter for simulating devices that get stuck on Gmax or Gmin states from the start\n",
        "  # user input = probability for a device to get stuck\n",
        "  DEVICE_STUCK_ON_PROB = device_stuck_on_prob_input\n",
        "  DEVICE_STUCK_OFF_PROB = device_stuck_off_prob_input\n",
        "\n",
        "  # for RNN model and training\n",
        "  BUFFER_SIZE = 10000\n",
        "  BATCH_SIZE = 32\n",
        "\n",
        "  # load data\n",
        "  dataset, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)\n",
        "  train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "  train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "  test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  VOCAB_SIZE = 1000\n",
        "  # Maximum size of the vocabulary for this layer. \n",
        "  # This should only be specified when adapting a vocabulary or when setting pad_to_max_tokens=True. \n",
        "  encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE, name = 'encoder')\n",
        "  # adapt: Fits the state of the preprocessing layer to the data being passed.\n",
        "  encoder.adapt(train_dataset.map(lambda text, label: text))\n",
        "\n",
        "  vocab = np.array(encoder.get_vocabulary()) \n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=32,\n",
        "        name='embedding',\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.LSTM(32, name='lstm'),\n",
        "    tf.keras.layers.Dense(32, activation='relu', name='dense1'),\n",
        "    tf.keras.layers.Dense(1, name='dense2')\n",
        "  ])\n",
        "\n",
        "  plot_time = time.time()\n",
        "  plot_dir = '/content/drive/MyDrive/RNN_model_plot/'+str(plot_time)+'model.png'\n",
        "  tf.keras.utils.plot_model(model, to_file=plot_dir, show_shapes=True, show_layer_names=True)\n",
        "\n",
        "  # 1. keras.layers.preprocessing.index_lookup.VocabWeightHandler - not trainable\n",
        "  # 2. 'embedding/embeddings:0' shape=(1000, 32)\n",
        "  # 3. 'lstm/lstm_cell/kernel:0' shape=(32, 256)\n",
        "  # 4. 'lstm/lstm_cell/recurrent_kernel:0' shape=(32, 256)\n",
        "  # 5. 'lstm/lstm_cell/bias:0' shape=(256,)\n",
        "  # 6. 'dense/kernel:0' shape=(32, 32)\n",
        "  # 7. 'dense/bias:0' shape=(32,)\n",
        "  # 8. 'dense_1/kernel:0' shape=(32, 1)\n",
        "  # 9. 'dense_1/bias:0' shape=(1,)\n",
        "  model_weights = model.trainable_variables # len(weights) = 8\n",
        "\n",
        "  g_min_value = np.min(np.abs(DEVICE_STATES))\n",
        "  g_max_value = np.max(np.abs(DEVICE_STATES))\n",
        "      \n",
        "  # to make this notebook's output stable across runs\n",
        "  def reset_graph(seed=42):\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "  # create matrix to simulate device-to-device variation by creating clipping the weights\n",
        "  # and simulate devices being stuck-on-open and stuck-on-close \n",
        "  def initialize_variation_stuck_mat(shape):\n",
        "    # VARIATION\n",
        "    wp_max = np.ones(shape=shape) - np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape)) # max. is smaller than 1\n",
        "    wp_min = np.zeros(shape=shape) + np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape)) # min. is larger than 0\n",
        "\n",
        "    wm_max = np.ones(shape=shape) - np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape)) # max. is smaller than 1\n",
        "    wm_min = np.zeros(shape=shape) + np.abs(np.random.normal(0, DEVICE_VARIATION_STDDEV, shape)) # min. is larger than 0\n",
        "\n",
        "    # STUCK\n",
        "    stuck_prob = [DEVICE_STUCK_OFF_PROB, 1 - DEVICE_STUCK_ON_PROB - DEVICE_STUCK_OFF_PROB, DEVICE_STUCK_ON_PROB]\n",
        "    w_p_stuck = np.random.choice([-1, 0, 1], size=shape, p=stuck_prob) \n",
        "    w_m_stuck = np.random.choice([-1, 0, 1], size=shape, p=stuck_prob)\n",
        "\n",
        "    # if device is stuck OFF\n",
        "    wp_max = wp_max + (w_p_stuck == -1) * (wp_min - wp_max)\n",
        "    wm_max = wm_max + (w_m_stuck == -1) * (wm_min - wm_max)\n",
        "\n",
        "    # if device is stuck ON\n",
        "    wp_min = wp_min + (w_p_stuck == 1) * (wp_max - wp_min)\n",
        "    wm_min = wm_min + (w_m_stuck == 1) * (wm_max - wm_min)\n",
        "\n",
        "\n",
        "    # PUTTING TOGETHER CLIPPING MATRIX\n",
        "    # numpy.clip(a, a_min, a_max) \n",
        "    # Clip (limit) the values in an array.\n",
        "    # Given an interval, values outside the interval are clipped to the interval edges\n",
        "    lower_lim = np.clip(wp_min - wm_max, -g_max_value, -g_min_value)\n",
        "    upper_lim = np.clip(wp_max - wm_min, g_min_value, g_max_value)\n",
        "\n",
        "    #print('Lower lim: ' + str(lower_lim))\n",
        "    #print('Upper lim: ' + str(upper_lim))\n",
        "\n",
        "    return [lower_lim, upper_lim]\n",
        "\n",
        "  # weight update with a discrete number of states and (optional) add read noise\n",
        "  def discrete_weight_update(value, read_noise_mean=0, read_noise_stddev=0):\n",
        "      if read_noise_stddev != 0:\n",
        "          value += np.random.normal(read_noise_mean, read_noise_stddev)\n",
        "      absolute_difference_function = lambda list_value : abs(list_value - value)\n",
        "      return min(DEVICE_STATES, key=absolute_difference_function)\n",
        "  v_discrete_weight_update = np.vectorize(discrete_weight_update)\n",
        "\n",
        "  # function puts together all the parts\n",
        "  # 1. Device variation\n",
        "  # 2. Stuck-on/off \n",
        "  # 3. Discrete number of weight states\n",
        "  # Input = software weights matrix, Output = hardware weights matrix\n",
        "  def simulate_hardware_weight_update(weights_mat, var_stuck_mat):\n",
        "\n",
        "    # initialize variation and stuck matrix if not initialized\n",
        "    if type(weights_mat) is not np.array:\n",
        "      weights_mat = np.array(weights_mat)\n",
        "\n",
        "    if type(var_stuck_mat) is not np.ndarray:\n",
        "        var_stuck_mat = initialize_variation_stuck_mat(weights_mat.shape)\n",
        "\n",
        "    # simulate weight variation and stuck on open/close\n",
        "    weights_mat = weights_mat.clip(var_stuck_mat[0], var_stuck_mat[1])\n",
        "\n",
        "    # simulate discrete states\n",
        "    weights_mat = v_discrete_weight_update(weights_mat, read_noise_mean = READ_NOISE_MEAN,\n",
        "                          read_noise_stddev = READ_NOISE_STDDEV)\n",
        "\n",
        "    return weights_mat\n",
        "\n",
        "  # reset default tf graph before running sim\n",
        "  reset_graph()\n",
        "\n",
        "  # define weight update ops\n",
        "  var_stuck_mat = [False, False, False, False, False, False, False, False]\n",
        "  weights = np.zeros([1, 8])[0].tolist()\n",
        "  new_weights = np.zeros([1, 8])[0].tolist()\n",
        "  weight_update_op = np.zeros([1, 8])[0].tolist()\n",
        "  weight_layers = [\"embedding/embeddings:0\", \"lstm/lstm_cell/kernel:0\", \"lstm/lstm_cell/recurrent_kernel:0\", \"lstm/lstm_cell/bias:0\",\n",
        "            \"dense1/kernel:0\", \"dense1/bias:0\", \"dense2/kernel:0\", \"dense2/bias:0\"]\n",
        "\n",
        "  train_accuracy_ls = []\n",
        "  train_loss_ls = []\n",
        "\n",
        "  test_accuracy_ls = []\n",
        "  test_loss_ls = []\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  # train the model weights\n",
        "  for i in range(NUM_EPOCHS):\n",
        "    # mark the time\n",
        "    start_time = time.time()\n",
        "    start_datetime  = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "    print(\"Training the \"+str(i+1)+\"th epoch!\")\n",
        "\n",
        "    history = model.fit(train_dataset, epochs=1,\n",
        "            validation_data=test_dataset,\n",
        "            validation_steps=30)\n",
        "    \n",
        "    train_accuracy_ls.append(history.history['accuracy'][0])\n",
        "    train_loss_ls.append(history.history['loss'][0])\n",
        "    test_accuracy_ls.append(history.history['val_accuracy'][0])\n",
        "    test_loss_ls.append(history.history['val_loss'][0])\n",
        "\n",
        "    if HARDWARE_SIMULATION:\n",
        "\n",
        "      # obtain the original weights\n",
        "      weights = model.trainable_variables\n",
        "\n",
        "      # update the weights cosidering the hardware\n",
        "      new_weights = []\n",
        "      for i, weight in enumerate(weights):\n",
        "        new_weights.append(simulate_hardware_weight_update(weight, var_stuck_mat[i]))\n",
        "\n",
        "      model.layers[1].set_weights([new_weights[0]])\n",
        "      model.layers[2].set_weights([new_weights[1], new_weights[2], new_weights[3]])\n",
        "      model.layers[3].set_weights([new_weights[4], new_weights[5]])\n",
        "      model.layers[4].set_weights([new_weights[6], new_weights[7]])\n",
        "\n",
        "    # save the results for current epoch\n",
        "    if SAVE_RESULTS:\n",
        "      file_name = 'model_' + str(start_datetime) + '_' + str(NUM_EPOCHS)\n",
        "      model.save('/content/drive/MyDrive/RNN_memtrainsistor_ckpts_final/'+file_name)\n",
        "      print(\"Save results in file \"+file_name+\" successfully!\\n\")\n",
        "\n",
        "  # save the final result\n",
        "  if SAVE_RESULTS:\n",
        "    file_name = 'final_model_' + '_' + str(NUM_EPOCHS)\n",
        "    model.save('/content/drive/MyDrive/RNN_memtrainsistor_ckpts_final/'+file_name)\n",
        "    print(\"Save results in file \"+file_name+\" successfully!\\n\")\n",
        "\n",
        "  if plot_fig:\n",
        "    plot_figure(train_accuracy_ls, test_accuracy_ls)\n",
        "\n",
        "  return model, train_accuracy_ls, test_accuracy_ls"
      ],
      "metadata": {
        "id": "ZmSz16qvkPER"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the 1st learning curve from vinod\n",
        "DEVICE_STATES = import_data_from_csv('/content/drive/MyDrive/learing_curves_csv/learning_curve_1.csv')\n",
        "model, train_accuracy_ls_mem, test_accuracy_ls_mem = run_RNN_simulation(save_results_input=True,\n",
        "            num_epochs_input=30, \n",
        "            hardware_simulation_input=True, \n",
        "            device_states_input=DEVICE_STATES,\n",
        "            read_noise_mean_input=0,\n",
        "            read_noise_stddev_input=0.1,\n",
        "            device_variation_stddev_input=0,\n",
        "            device_stuck_on_prob_input=0,\n",
        "            device_stuck_off_prob_input=0,\n",
        "            plot_fig=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoxTzY0Tk2Ze",
        "outputId": "ff66e1fd-2cec-4eb7-883d-59eec7f366bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the 1th epoch!\n",
            " 63/782 [=>............................] - ETA: 6:40 - loss: 0.6932 - accuracy: 0.5084"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aTXocjw8lgRQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}